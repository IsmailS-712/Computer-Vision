{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XRxHiKdGHiT"
      },
      "source": [
        "# Coursework 2: Image segmentation\n",
        "\n",
        "In this coursework you will develop and train a convolutional neural network for brain tumour image segmentation. Please read both the text and the code in this notebook to get an idea what you are expected to implement. Pay attention to the missing code blocks that look like this:\n",
        "\n",
        "```\n",
        "### Insert your code ###\n",
        "...\n",
        "### End of your code ###\n",
        "```\n",
        "\n",
        "## What to do?\n",
        "\n",
        "* Complete and run the code using `jupyter-lab` or `jupyter-notebook` to get the results.\n",
        "\n",
        "* Export (File | Save and Export Notebook As...) the notebook as a PDF file, which contains your code, results and answers, and upload the PDF file onto [Scientia](https://scientia.doc.ic.ac.uk).\n",
        "\n",
        "* Instead of clicking the Export button, you can also run the following command instead: `jupyter nbconvert coursework.ipynb --to pdf`\n",
        "\n",
        "* If Jupyter complains about some problems in exporting, it is likely that pandoc (https://pandoc.org/installing.html) or latex is not installed, or their paths have not been included. You can install the relevant libraries and retry.\n",
        "\n",
        "* If Jupyter-lab does not work for you at the end, you can use Google Colab to write the code and export the PDF file.\n",
        "\n",
        "## Dependencies\n",
        "\n",
        "You need to install Jupyter-Lab (https://jupyterlab.readthedocs.io/en/stable/getting_started/installation.html) and other libraries used in this coursework, such as by running the command:\n",
        "`pip3 install [package_name]`\n",
        "\n",
        "## GPU resource\n",
        "\n",
        "The coursework is developed to be able to run on CPU, as all images have been pre-processed to be 2D and of a smaller size, compared to original 3D volumes.\n",
        "\n",
        "However, to save training time, you may want to use GPU. In that case, you can run this notebook on Google Colab. On Google Colab, go to the menu, Runtime - Change runtime type, and select **GPU** as the hardware acceleartor. At the end, please still export everything and submit as a PDF file on Scientia.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Eq1KWmR3HWYV"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "# These libraries should be sufficient for this tutorial.\n",
        "# However, if any other library is needed, please install by yourself.\n",
        "import tarfile\n",
        "import imageio\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4TX-CXBHW4c"
      },
      "source": [
        "## 1. Download and visualise the imaging dataset.\n",
        "\n",
        "The dataset is curated from the brain imaging dataset in [Medical Decathlon Challenge](http://medicaldecathlon.com/). To save the storage and reduce the computational cost for this tutorial, we extract 2D image slices from T1-Gd contrast enhanced 3D brain volumes and downsample the images.\n",
        "\n",
        "The dataset consists of a training set and a test set. Each image is of dimension 120 x 120, with a corresponding label map of the same dimension. There are four number of classes in the label map:\n",
        "\n",
        "- 0: background\n",
        "- 1: edema\n",
        "- 2: non-enhancing tumour\n",
        "- 3: enhancing tumour"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mt93oQ8xZkE9",
        "outputId": "7ec4f28c-4629-4044-a827-c010bf443a7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-25 21:17:52--  https://www.dropbox.com/s/zmytk2yu284af6t/Task01_BrainTumour_2D.tar.gz\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6016:18::a27d:112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/zmytk2yu284af6t/Task01_BrainTumour_2D.tar.gz [following]\n",
            "--2024-02-25 21:17:52--  https://www.dropbox.com/s/raw/zmytk2yu284af6t/Task01_BrainTumour_2D.tar.gz\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc1a351e1e2f411b7339f7cd5a82.dl.dropboxusercontent.com/cd/0/inline/CN_e4za27PcdRXlmHLlKCW1ANGGNru7v84JPXiZYXMfJutLjgZqJB5-523pEpd5LWpwzOjO_4jV8d5LuPqtYUgFeynPs8K8OINZbDUVWP4zUgyLQL693IYGGoNmNtyrY4c0/file# [following]\n",
            "--2024-02-25 21:17:52--  https://uc1a351e1e2f411b7339f7cd5a82.dl.dropboxusercontent.com/cd/0/inline/CN_e4za27PcdRXlmHLlKCW1ANGGNru7v84JPXiZYXMfJutLjgZqJB5-523pEpd5LWpwzOjO_4jV8d5LuPqtYUgFeynPs8K8OINZbDUVWP4zUgyLQL693IYGGoNmNtyrY4c0/file\n",
            "Resolving uc1a351e1e2f411b7339f7cd5a82.dl.dropboxusercontent.com (uc1a351e1e2f411b7339f7cd5a82.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\n",
            "Connecting to uc1a351e1e2f411b7339f7cd5a82.dl.dropboxusercontent.com (uc1a351e1e2f411b7339f7cd5a82.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/CN-eWya5yE6SvI8YhBmuZ2BCNAxDoCmKD4zMOamRO4IHfx8I2YshlcR4qqnlEJDknHQS6JCEickK5CSSgxEWWiARjJQff5Tz94x51xKhSPNnVKS4TwJollzSjHU1q1E9eCtF8Nrckht-iG_GV9F4kPnGxwE9wMWZI8s0ERljptCDlXebJcN_x-QY-jRvMnj0i7xnEtntw6AImBsYaMOW2yCXAO51COT5pWwXBT0GrtT0gZ361j_CJ8JPRbBxXn5Gb7J_68zg5gxaiJIag321jSwNos8G6TagP_cy4ZQ6eypP5FUUfdchivke8WOEeTm0vqldiubDXRC2NCraxrEiEf0yD7k9CNMiYya_UQw8Z_TbCw/file [following]\n",
            "--2024-02-25 21:17:53--  https://uc1a351e1e2f411b7339f7cd5a82.dl.dropboxusercontent.com/cd/0/inline2/CN-eWya5yE6SvI8YhBmuZ2BCNAxDoCmKD4zMOamRO4IHfx8I2YshlcR4qqnlEJDknHQS6JCEickK5CSSgxEWWiARjJQff5Tz94x51xKhSPNnVKS4TwJollzSjHU1q1E9eCtF8Nrckht-iG_GV9F4kPnGxwE9wMWZI8s0ERljptCDlXebJcN_x-QY-jRvMnj0i7xnEtntw6AImBsYaMOW2yCXAO51COT5pWwXBT0GrtT0gZ361j_CJ8JPRbBxXn5Gb7J_68zg5gxaiJIag321jSwNos8G6TagP_cy4ZQ6eypP5FUUfdchivke8WOEeTm0vqldiubDXRC2NCraxrEiEf0yD7k9CNMiYya_UQw8Z_TbCw/file\n",
            "Reusing existing connection to uc1a351e1e2f411b7339f7cd5a82.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9251149 (8.8M) [application/octet-stream]\n",
            "Saving to: ‘Task01_BrainTumour_2D.tar.gz’\n",
            "\n",
            "Task01_BrainTumour_ 100%[===================>]   8.82M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-02-25 21:17:53 (91.4 MB/s) - ‘Task01_BrainTumour_2D.tar.gz’ saved [9251149/9251149]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download the dataset\n",
        "!wget https://www.dropbox.com/s/zmytk2yu284af6t/Task01_BrainTumour_2D.tar.gz\n",
        "\n",
        "# Unzip the '.tar.gz' file to the current directory\n",
        "datafile = tarfile.open('Task01_BrainTumour_2D.tar.gz')\n",
        "datafile.extractall()\n",
        "datafile.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu_BTL0x6o5a"
      },
      "source": [
        "## Visualise a random set of 4 training images along with their label maps.\n",
        "\n",
        "Suggested colour map for brain MR image:\n",
        "```\n",
        "cmap = 'gray'\n",
        "```\n",
        "\n",
        "Suggested colour map for segmentation map:\n",
        "```\n",
        "cmap = colors.ListedColormap(['black', 'green', 'blue', 'red'])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3fgubCRC6m4k",
        "outputId": "2f1d5b31-7c91-4a00-82b6-6221f37a699e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading training images and labels\n",
            "Training images and labels loaded\n",
            "Plotting images and label maps\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1800 with 8 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visualization complete\n"
          ]
        }
      ],
      "source": [
        "### Insert your code ###\n",
        "train_image_dir = './Task01_BrainTumour_2D/training_images/'\n",
        "train_label_dir = './Task01_BrainTumour_2D/training_labels/'\n",
        "\n",
        "print(\"Loading training images and labels\")\n",
        "\n",
        "# Load images and labels using list comprehension\n",
        "train_images = [np.array(Image.open(os.path.join(train_image_dir, filename)))\n",
        "                for filename in os.listdir(train_image_dir) if filename.endswith('.png')]\n",
        "train_labels = [np.array(Image.open(os.path.join(train_label_dir, filename)))\n",
        "                for filename in os.listdir(train_label_dir) if filename.endswith('.png')]\n",
        "\n",
        "print(\"Training images and labels loaded\")\n",
        "\n",
        "# Defining color maps for visualization.\n",
        "cmap_brain_mr = 'gray'\n",
        "cmap_segmentation = colors.ListedColormap(['black', 'green', 'blue', 'red'])\n",
        "\n",
        "# Plot the images and their label maps.\n",
        "print(\"Plotting images and label maps\")\n",
        "\n",
        "fig, axes = plt.subplots(4, 2, figsize=(12, 18))\n",
        "\n",
        "rand_image = np.random.choice(len(train_images), 4, replace=False)\n",
        "\n",
        "for i, idx in enumerate(rand_image):\n",
        "    image = train_images[idx]\n",
        "    label_map = train_labels[idx]\n",
        "\n",
        "    # Plotting the training image.\n",
        "    axes[i, 0].imshow(image, cmap=cmap_brain_mr)\n",
        "    axes[i, 0].axis('off')\n",
        "    axes[i, 0].set_title('Training Image')\n",
        "\n",
        "    # Plotting the label map.\n",
        "    axes[i, 1].imshow(label_map, cmap=cmap_segmentation, vmin=0, vmax=3)\n",
        "    axes[i, 1].axis('off')\n",
        "    axes[i, 1].set_title('Label/Segmentation Map')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Visualization complete\")\n",
        "### End of your code ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xWGT3KaML-D"
      },
      "source": [
        "## 2. Implement a dataset class.\n",
        "\n",
        "It can read the imaging dataset and get items, pairs of images and label maps, as training batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6p6wFZ3na5z9"
      },
      "outputs": [],
      "source": [
        "def normalise_intensity(image, thres_roi=1.0):\n",
        "    \"\"\" Normalise the image intensity by the mean and standard deviation \"\"\"\n",
        "    # Ensure image is a numpy array\n",
        "    image = np.array(image)\n",
        "    # ROI defines the image foreground\n",
        "    val_l = np.percentile(image, thres_roi)\n",
        "    roi = (image >= val_l)\n",
        "    mu, sigma = np.mean(image[roi]), np.std(image[roi])\n",
        "    eps = 1e-6\n",
        "    image2 = (image - mu) / (sigma + eps)\n",
        "    return image2\n",
        "\n",
        "\n",
        "class BrainImageSet(Dataset):\n",
        "    \"\"\" Brain image set \"\"\"\n",
        "    def __init__(self, image_path, label_path='', deploy=False):\n",
        "        self.image_path = image_path\n",
        "        self.deploy = deploy\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "\n",
        "        image_names = sorted(os.listdir(image_path))\n",
        "        for image_name in image_names:\n",
        "            # Read the image\n",
        "            image = imageio.imread(os.path.join(image_path, image_name))\n",
        "            self.images += [image]\n",
        "\n",
        "            # Read the label map\n",
        "            if not self.deploy:\n",
        "                label_name = os.path.join(label_path, image_name)\n",
        "                label = imageio.imread(label_name)\n",
        "                self.labels += [label]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get an image and perform intensity normalisation\n",
        "        # Dimension: XY\n",
        "        image = normalise_intensity(self.images[idx])\n",
        "\n",
        "        # Get its label map\n",
        "        # Dimension: XY\n",
        "        label = self.labels[idx]\n",
        "        return image, label\n",
        "\n",
        "    def get_random_batch(self, batch_size):\n",
        "        # Get a batch of paired images and label maps\n",
        "        # Dimension of images: NCXY\n",
        "        # Dimension of labels: NXY\n",
        "        images, labels = [], []\n",
        "\n",
        "        ### Insert your code ###\n",
        "        rand_batch = np.random.choice(len(self), batch_size, replace=False)\n",
        "\n",
        "        for idx in rand_batch:\n",
        "            image, label = self[idx]\n",
        "            images.append(image)\n",
        "            labels.append(label)\n",
        "        ### End of your code ###\n",
        "        #print(images.shape)\n",
        "        return images, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa4ZpawDNmwu"
      },
      "source": [
        "## 3. Build a U-net architecture.\n",
        "\n",
        "You will implement a U-net architecture. If you are not familiar with U-net, please read this paper:\n",
        "\n",
        "[1] Olaf Ronneberger et al. [U-Net: Convolutional networks for biomedical image segmentation](https://link.springer.com/chapter/10.1007/978-3-319-24574-4_28). MICCAI, 2015.\n",
        "\n",
        "For the first convolutional layer, you can start with 16 filters. We have implemented the encoder path. Please complete the decoder path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IMPmBZVGb1aI"
      },
      "outputs": [],
      "source": [
        "\"\"\" U-net \"\"\"\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, input_channel=1, output_channel=1, num_filter=16):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        # BatchNorm: by default during training this layer keeps running estimates\n",
        "        # of its computed mean and variance, which are then used for normalization\n",
        "        # during evaluation.\n",
        "\n",
        "        # Encoder path\n",
        "        n = num_filter  # 16\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(input_channel, n, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(n),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(n),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        n *= 2  # 32\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(int(n / 2), n, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(n),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(n),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        n *= 2  # 64\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(int(n / 2), n, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(n),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(n),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        n *= 2  # 128\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(int(n / 2), n, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(n),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(n),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Decoder path\n",
        "        ### Insert your code ###\n",
        "        self.upconv3 = nn.ConvTranspose2d(n, n // 2, kernel_size=4, stride=2, padding=1)\n",
        "        self.conv3d = nn.Sequential(\n",
        "            nn.Conv2d(n, n // 2, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(n // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(n // 2, n // 2, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(n // 2),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        n //= 2  # 64\n",
        "        self.upconv2 = nn.ConvTranspose2d(n, n // 2, kernel_size=4, stride=2, padding=1)\n",
        "        self.conv2d = nn.Sequential(\n",
        "            nn.Conv2d(n, n // 2, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(n // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(n // 2, n // 2, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(n // 2),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        n //= 2  # 32\n",
        "        self.upconv1 = nn.ConvTranspose2d(n, n // 2, kernel_size=4, stride=2, padding=1)\n",
        "        self.conv1d = nn.Sequential(\n",
        "            nn.Conv2d(n, n // 2, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(n // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(n // 2, n // 2, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(n // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(n // 2, output_channel, kernel_size=1)  # Output segmentation map\n",
        "        )\n",
        "        ### End of your code ###\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Use the convolutional operators defined above to build the U-net\n",
        "        # The encoder part is already done for you.\n",
        "        # You need to complete the decoder part.\n",
        "        # Encoder\n",
        "        x1 = self.conv1(x)\n",
        "        conv1_skip = x1\n",
        "        #print(x1.size())\n",
        "\n",
        "        x2 = self.conv2(x1)\n",
        "        conv2_skip = x2\n",
        "        #print(x2.size())\n",
        "\n",
        "        x3 = self.conv3(x2)\n",
        "        conv3_skip = x3\n",
        "        #print(x3.size())\n",
        "\n",
        "        x4 = self.conv4(x3)\n",
        "        #print(x4.size())\n",
        "\n",
        "        # Decoder\n",
        "        ### Insert your code ###\n",
        "        x = self.upconv3(x4)\n",
        "        #print(x.size())\n",
        "        #print(x3.size())\n",
        "        x = torch.cat([x, x3], dim=1)\n",
        "        #print(x.size())\n",
        "        x = self.conv3d(x)\n",
        "\n",
        "        x = self.upconv2(x)\n",
        "        x = torch.cat([x, x2], dim=1)\n",
        "        x = self.conv2d(x)\n",
        "\n",
        "        x = self.upconv1(x)\n",
        "        x = torch.cat([x, x1], dim=1)\n",
        "        x = self.conv1d(x)\n",
        "        ### End of your code ###\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcNWZS08d47P"
      },
      "source": [
        "## 4. Train the segmentation model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaGGkKQndIaR",
        "outputId": "3044f20c-e699-45c6-94a3-5bfed39e5b4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-0055689bb296>:25: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  image = imageio.imread(os.path.join(image_path, image_name))\n",
            "<ipython-input-5-0055689bb296>:31: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  label = imageio.imread(label_name)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Training [5052/10000]: Loss: 0.018\n",
            "Training [5053/10000]: Loss: 0.016\n",
            "Training [5054/10000]: Loss: 0.017\n",
            "Training [5055/10000]: Loss: 0.013\n",
            "Training [5056/10000]: Loss: 0.023\n",
            "Training [5057/10000]: Loss: 0.018\n",
            "Training [5058/10000]: Loss: 0.015\n",
            "Training [5059/10000]: Loss: 0.016\n",
            "Training [5060/10000]: Loss: 0.016\n",
            "Training [5061/10000]: Loss: 0.010\n",
            "Training [5062/10000]: Loss: 0.011\n",
            "Training [5063/10000]: Loss: 0.018\n",
            "Training [5064/10000]: Loss: 0.013\n",
            "Training [5065/10000]: Loss: 0.014\n",
            "Training [5066/10000]: Loss: 0.012\n",
            "Training [5067/10000]: Loss: 0.013\n",
            "Training [5068/10000]: Loss: 0.021\n",
            "Training [5069/10000]: Loss: 0.012\n",
            "Training [5070/10000]: Loss: 0.012\n",
            "Training [5071/10000]: Loss: 0.010\n",
            "Training [5072/10000]: Loss: 0.018\n",
            "Training [5073/10000]: Loss: 0.023\n",
            "Training [5074/10000]: Loss: 0.017\n",
            "Training [5075/10000]: Loss: 0.017\n",
            "Training [5076/10000]: Loss: 0.016\n",
            "Training [5077/10000]: Loss: 0.012\n",
            "Training [5078/10000]: Loss: 0.016\n",
            "Training [5079/10000]: Loss: 0.016\n",
            "Training [5080/10000]: Loss: 0.014\n",
            "Training [5081/10000]: Loss: 0.011\n",
            "Training [5082/10000]: Loss: 0.024\n",
            "Training [5083/10000]: Loss: 0.023\n",
            "Training [5084/10000]: Loss: 0.014\n",
            "Training [5085/10000]: Loss: 0.016\n",
            "Training [5086/10000]: Loss: 0.021\n",
            "Training [5087/10000]: Loss: 0.013\n",
            "Training [5088/10000]: Loss: 0.014\n",
            "Training [5089/10000]: Loss: 0.022\n",
            "Training [5090/10000]: Loss: 0.016\n",
            "Training [5091/10000]: Loss: 0.015\n",
            "Training [5092/10000]: Loss: 0.011\n",
            "Training [5093/10000]: Loss: 0.015\n",
            "Training [5094/10000]: Loss: 0.013\n",
            "Training [5095/10000]: Loss: 0.010\n",
            "Training [5096/10000]: Loss: 0.022\n",
            "Training [5097/10000]: Loss: 0.015\n",
            "Training [5098/10000]: Loss: 0.019\n",
            "Training [5099/10000]: Loss: 0.013\n",
            "Training [5100/10000]: Loss: 0.018\n",
            "Test Loss: 0.053\n",
            "Training [5101/10000]: Loss: 0.016\n",
            "Training [5102/10000]: Loss: 0.022\n",
            "Training [5103/10000]: Loss: 0.022\n",
            "Training [5104/10000]: Loss: 0.015\n",
            "Training [5105/10000]: Loss: 0.014\n",
            "Training [5106/10000]: Loss: 0.012\n",
            "Training [5107/10000]: Loss: 0.016\n",
            "Training [5108/10000]: Loss: 0.017\n",
            "Training [5109/10000]: Loss: 0.017\n",
            "Training [5110/10000]: Loss: 0.013\n",
            "Training [5111/10000]: Loss: 0.016\n",
            "Training [5112/10000]: Loss: 0.026\n",
            "Training [5113/10000]: Loss: 0.019\n",
            "Training [5114/10000]: Loss: 0.019\n",
            "Training [5115/10000]: Loss: 0.014\n",
            "Training [5116/10000]: Loss: 0.014\n",
            "Training [5117/10000]: Loss: 0.027\n",
            "Training [5118/10000]: Loss: 0.017\n",
            "Training [5119/10000]: Loss: 0.016\n",
            "Training [5120/10000]: Loss: 0.014\n",
            "Training [5121/10000]: Loss: 0.016\n",
            "Training [5122/10000]: Loss: 0.017\n",
            "Training [5123/10000]: Loss: 0.016\n",
            "Training [5124/10000]: Loss: 0.014\n",
            "Training [5125/10000]: Loss: 0.013\n",
            "Training [5126/10000]: Loss: 0.014\n",
            "Training [5127/10000]: Loss: 0.017\n",
            "Training [5128/10000]: Loss: 0.016\n",
            "Training [5129/10000]: Loss: 0.017\n",
            "Training [5130/10000]: Loss: 0.019\n",
            "Training [5131/10000]: Loss: 0.012\n",
            "Training [5132/10000]: Loss: 0.015\n",
            "Training [5133/10000]: Loss: 0.017\n",
            "Training [5134/10000]: Loss: 0.013\n",
            "Training [5135/10000]: Loss: 0.009\n",
            "Training [5136/10000]: Loss: 0.023\n",
            "Training [5137/10000]: Loss: 0.014\n",
            "Training [5138/10000]: Loss: 0.024\n",
            "Training [5139/10000]: Loss: 0.010\n",
            "Training [5140/10000]: Loss: 0.015\n",
            "Training [5141/10000]: Loss: 0.015\n",
            "Training [5142/10000]: Loss: 0.016\n",
            "Training [5143/10000]: Loss: 0.014\n",
            "Training [5144/10000]: Loss: 0.012\n",
            "Training [5145/10000]: Loss: 0.014\n",
            "Training [5146/10000]: Loss: 0.027\n",
            "Training [5147/10000]: Loss: 0.015\n",
            "Training [5148/10000]: Loss: 0.017\n",
            "Training [5149/10000]: Loss: 0.014\n",
            "Training [5150/10000]: Loss: 0.014\n",
            "Training [5151/10000]: Loss: 0.013\n",
            "Training [5152/10000]: Loss: 0.011\n",
            "Training [5153/10000]: Loss: 0.015\n",
            "Training [5154/10000]: Loss: 0.012\n",
            "Training [5155/10000]: Loss: 0.014\n",
            "Training [5156/10000]: Loss: 0.017\n",
            "Training [5157/10000]: Loss: 0.018\n",
            "Training [5158/10000]: Loss: 0.015\n",
            "Training [5159/10000]: Loss: 0.017\n",
            "Training [5160/10000]: Loss: 0.016\n",
            "Training [5161/10000]: Loss: 0.016\n",
            "Training [5162/10000]: Loss: 0.016\n",
            "Training [5163/10000]: Loss: 0.015\n",
            "Training [5164/10000]: Loss: 0.013\n",
            "Training [5165/10000]: Loss: 0.022\n",
            "Training [5166/10000]: Loss: 0.019\n",
            "Training [5167/10000]: Loss: 0.016\n",
            "Training [5168/10000]: Loss: 0.015\n",
            "Training [5169/10000]: Loss: 0.012\n",
            "Training [5170/10000]: Loss: 0.012\n",
            "Training [5171/10000]: Loss: 0.012\n",
            "Training [5172/10000]: Loss: 0.007\n",
            "Training [5173/10000]: Loss: 0.020\n",
            "Training [5174/10000]: Loss: 0.014\n",
            "Training [5175/10000]: Loss: 0.009\n",
            "Training [5176/10000]: Loss: 0.021\n",
            "Training [5177/10000]: Loss: 0.021\n",
            "Training [5178/10000]: Loss: 0.020\n",
            "Training [5179/10000]: Loss: 0.014\n",
            "Training [5180/10000]: Loss: 0.017\n",
            "Training [5181/10000]: Loss: 0.021\n",
            "Training [5182/10000]: Loss: 0.018\n",
            "Training [5183/10000]: Loss: 0.015\n",
            "Training [5184/10000]: Loss: 0.013\n",
            "Training [5185/10000]: Loss: 0.013\n",
            "Training [5186/10000]: Loss: 0.014\n",
            "Training [5187/10000]: Loss: 0.012\n",
            "Training [5188/10000]: Loss: 0.017\n",
            "Training [5189/10000]: Loss: 0.015\n",
            "Training [5190/10000]: Loss: 0.015\n",
            "Training [5191/10000]: Loss: 0.016\n",
            "Training [5192/10000]: Loss: 0.016\n",
            "Training [5193/10000]: Loss: 0.013\n",
            "Training [5194/10000]: Loss: 0.022\n",
            "Training [5195/10000]: Loss: 0.019\n",
            "Training [5196/10000]: Loss: 0.017\n",
            "Training [5197/10000]: Loss: 0.011\n",
            "Training [5198/10000]: Loss: 0.018\n",
            "Training [5199/10000]: Loss: 0.017\n",
            "Training [5200/10000]: Loss: 0.017\n",
            "Test Loss: 0.052\n",
            "Training [5201/10000]: Loss: 0.018\n",
            "Training [5202/10000]: Loss: 0.013\n",
            "Training [5203/10000]: Loss: 0.016\n",
            "Training [5204/10000]: Loss: 0.013\n",
            "Training [5205/10000]: Loss: 0.021\n",
            "Training [5206/10000]: Loss: 0.018\n",
            "Training [5207/10000]: Loss: 0.015\n",
            "Training [5208/10000]: Loss: 0.015\n",
            "Training [5209/10000]: Loss: 0.014\n",
            "Training [5210/10000]: Loss: 0.012\n",
            "Training [5211/10000]: Loss: 0.013\n",
            "Training [5212/10000]: Loss: 0.018\n",
            "Training [5213/10000]: Loss: 0.009\n",
            "Training [5214/10000]: Loss: 0.010\n",
            "Training [5215/10000]: Loss: 0.017\n",
            "Training [5216/10000]: Loss: 0.010\n",
            "Training [5217/10000]: Loss: 0.015\n",
            "Training [5218/10000]: Loss: 0.015\n",
            "Training [5219/10000]: Loss: 0.017\n",
            "Training [5220/10000]: Loss: 0.012\n",
            "Training [5221/10000]: Loss: 0.017\n",
            "Training [5222/10000]: Loss: 0.010\n",
            "Training [5223/10000]: Loss: 0.015\n",
            "Training [5224/10000]: Loss: 0.014\n",
            "Training [5225/10000]: Loss: 0.020\n",
            "Training [5226/10000]: Loss: 0.016\n",
            "Training [5227/10000]: Loss: 0.009\n",
            "Training [5228/10000]: Loss: 0.013\n",
            "Training [5229/10000]: Loss: 0.016\n",
            "Training [5230/10000]: Loss: 0.010\n",
            "Training [5231/10000]: Loss: 0.018\n",
            "Training [5232/10000]: Loss: 0.010\n",
            "Training [5233/10000]: Loss: 0.016\n",
            "Training [5234/10000]: Loss: 0.013\n",
            "Training [5235/10000]: Loss: 0.016\n",
            "Training [5236/10000]: Loss: 0.016\n",
            "Training [5237/10000]: Loss: 0.019\n",
            "Training [5238/10000]: Loss: 0.015\n",
            "Training [5239/10000]: Loss: 0.012\n",
            "Training [5240/10000]: Loss: 0.013\n",
            "Training [5241/10000]: Loss: 0.015\n",
            "Training [5242/10000]: Loss: 0.012\n",
            "Training [5243/10000]: Loss: 0.013\n",
            "Training [5244/10000]: Loss: 0.013\n",
            "Training [5245/10000]: Loss: 0.019\n",
            "Training [5246/10000]: Loss: 0.021\n",
            "Training [5247/10000]: Loss: 0.022\n",
            "Training [5248/10000]: Loss: 0.020\n",
            "Training [5249/10000]: Loss: 0.016\n",
            "Training [5250/10000]: Loss: 0.014\n",
            "Training [5251/10000]: Loss: 0.016\n",
            "Training [5252/10000]: Loss: 0.014\n",
            "Training [5253/10000]: Loss: 0.019\n",
            "Training [5254/10000]: Loss: 0.019\n",
            "Training [5255/10000]: Loss: 0.011\n",
            "Training [5256/10000]: Loss: 0.008\n",
            "Training [5257/10000]: Loss: 0.008\n",
            "Training [5258/10000]: Loss: 0.021\n",
            "Training [5259/10000]: Loss: 0.012\n",
            "Training [5260/10000]: Loss: 0.011\n",
            "Training [5261/10000]: Loss: 0.014\n",
            "Training [5262/10000]: Loss: 0.018\n",
            "Training [5263/10000]: Loss: 0.020\n",
            "Training [5264/10000]: Loss: 0.020\n",
            "Training [5265/10000]: Loss: 0.008\n",
            "Training [5266/10000]: Loss: 0.011\n",
            "Training [5267/10000]: Loss: 0.017\n",
            "Training [5268/10000]: Loss: 0.017\n",
            "Training [5269/10000]: Loss: 0.024\n",
            "Training [5270/10000]: Loss: 0.009\n",
            "Training [5271/10000]: Loss: 0.018\n",
            "Training [5272/10000]: Loss: 0.021\n",
            "Training [5273/10000]: Loss: 0.009\n",
            "Training [5274/10000]: Loss: 0.015\n",
            "Training [5275/10000]: Loss: 0.015\n",
            "Training [5276/10000]: Loss: 0.018\n",
            "Training [5277/10000]: Loss: 0.019\n",
            "Training [5278/10000]: Loss: 0.017\n",
            "Training [5279/10000]: Loss: 0.014\n",
            "Training [5280/10000]: Loss: 0.011\n",
            "Training [5281/10000]: Loss: 0.013\n",
            "Training [5282/10000]: Loss: 0.018\n",
            "Training [5283/10000]: Loss: 0.020\n",
            "Training [5284/10000]: Loss: 0.024\n",
            "Training [5285/10000]: Loss: 0.011\n",
            "Training [5286/10000]: Loss: 0.012\n",
            "Training [5287/10000]: Loss: 0.014\n",
            "Training [5288/10000]: Loss: 0.014\n",
            "Training [5289/10000]: Loss: 0.020\n",
            "Training [5290/10000]: Loss: 0.017\n",
            "Training [5291/10000]: Loss: 0.012\n",
            "Training [5292/10000]: Loss: 0.014\n",
            "Training [5293/10000]: Loss: 0.015\n",
            "Training [5294/10000]: Loss: 0.021\n",
            "Training [5295/10000]: Loss: 0.019\n",
            "Training [5296/10000]: Loss: 0.020\n",
            "Training [5297/10000]: Loss: 0.013\n",
            "Training [5298/10000]: Loss: 0.014\n",
            "Training [5299/10000]: Loss: 0.014\n",
            "Training [5300/10000]: Loss: 0.011\n",
            "Test Loss: 0.053\n",
            "Training [5301/10000]: Loss: 0.013\n",
            "Training [5302/10000]: Loss: 0.016\n",
            "Training [5303/10000]: Loss: 0.022\n",
            "Training [5304/10000]: Loss: 0.007\n",
            "Training [5305/10000]: Loss: 0.013\n",
            "Training [5306/10000]: Loss: 0.013\n",
            "Training [5307/10000]: Loss: 0.012\n",
            "Training [5308/10000]: Loss: 0.010\n",
            "Training [5309/10000]: Loss: 0.018\n",
            "Training [5310/10000]: Loss: 0.016\n",
            "Training [5311/10000]: Loss: 0.011\n",
            "Training [5312/10000]: Loss: 0.017\n",
            "Training [5313/10000]: Loss: 0.013\n",
            "Training [5314/10000]: Loss: 0.009\n",
            "Training [5315/10000]: Loss: 0.020\n",
            "Training [5316/10000]: Loss: 0.025\n",
            "Training [5317/10000]: Loss: 0.014\n",
            "Training [5318/10000]: Loss: 0.016\n",
            "Training [5319/10000]: Loss: 0.021\n",
            "Training [5320/10000]: Loss: 0.027\n",
            "Training [5321/10000]: Loss: 0.014\n",
            "Training [5322/10000]: Loss: 0.017\n",
            "Training [5323/10000]: Loss: 0.014\n",
            "Training [5324/10000]: Loss: 0.019\n",
            "Training [5325/10000]: Loss: 0.015\n",
            "Training [5326/10000]: Loss: 0.012\n",
            "Training [5327/10000]: Loss: 0.017\n",
            "Training [5328/10000]: Loss: 0.016\n",
            "Training [5329/10000]: Loss: 0.015\n",
            "Training [5330/10000]: Loss: 0.011\n",
            "Training [5331/10000]: Loss: 0.017\n",
            "Training [5332/10000]: Loss: 0.016\n",
            "Training [5333/10000]: Loss: 0.019\n",
            "Training [5334/10000]: Loss: 0.020\n",
            "Training [5335/10000]: Loss: 0.012\n",
            "Training [5336/10000]: Loss: 0.011\n",
            "Training [5337/10000]: Loss: 0.015\n",
            "Training [5338/10000]: Loss: 0.017\n",
            "Training [5339/10000]: Loss: 0.021\n",
            "Training [5340/10000]: Loss: 0.018\n",
            "Training [5341/10000]: Loss: 0.015\n",
            "Training [5342/10000]: Loss: 0.011\n",
            "Training [5343/10000]: Loss: 0.008\n",
            "Training [5344/10000]: Loss: 0.009\n",
            "Training [5345/10000]: Loss: 0.015\n",
            "Training [5346/10000]: Loss: 0.014\n",
            "Training [5347/10000]: Loss: 0.017\n",
            "Training [5348/10000]: Loss: 0.015\n",
            "Training [5349/10000]: Loss: 0.018\n",
            "Training [5350/10000]: Loss: 0.009\n",
            "Training [5351/10000]: Loss: 0.018\n",
            "Training [5352/10000]: Loss: 0.010\n",
            "Training [5353/10000]: Loss: 0.014\n",
            "Training [5354/10000]: Loss: 0.021\n",
            "Training [5355/10000]: Loss: 0.015\n",
            "Training [5356/10000]: Loss: 0.014\n",
            "Training [5357/10000]: Loss: 0.013\n",
            "Training [5358/10000]: Loss: 0.010\n",
            "Training [5359/10000]: Loss: 0.019\n",
            "Training [5360/10000]: Loss: 0.016\n",
            "Training [5361/10000]: Loss: 0.013\n",
            "Training [5362/10000]: Loss: 0.020\n",
            "Training [5363/10000]: Loss: 0.014\n",
            "Training [5364/10000]: Loss: 0.012\n",
            "Training [5365/10000]: Loss: 0.010\n",
            "Training [5366/10000]: Loss: 0.012\n",
            "Training [5367/10000]: Loss: 0.016\n",
            "Training [5368/10000]: Loss: 0.012\n",
            "Training [5369/10000]: Loss: 0.022\n",
            "Training [5370/10000]: Loss: 0.013\n",
            "Training [5371/10000]: Loss: 0.015\n",
            "Training [5372/10000]: Loss: 0.017\n",
            "Training [5373/10000]: Loss: 0.015\n",
            "Training [5374/10000]: Loss: 0.019\n",
            "Training [5375/10000]: Loss: 0.016\n",
            "Training [5376/10000]: Loss: 0.014\n",
            "Training [5377/10000]: Loss: 0.013\n",
            "Training [5378/10000]: Loss: 0.013\n",
            "Training [5379/10000]: Loss: 0.012\n",
            "Training [5380/10000]: Loss: 0.020\n",
            "Training [5381/10000]: Loss: 0.007\n",
            "Training [5382/10000]: Loss: 0.017\n",
            "Training [5383/10000]: Loss: 0.011\n",
            "Training [5384/10000]: Loss: 0.020\n",
            "Training [5385/10000]: Loss: 0.013\n",
            "Training [5386/10000]: Loss: 0.012\n",
            "Training [5387/10000]: Loss: 0.018\n",
            "Training [5388/10000]: Loss: 0.018\n",
            "Training [5389/10000]: Loss: 0.008\n",
            "Training [5390/10000]: Loss: 0.019\n",
            "Training [5391/10000]: Loss: 0.012\n",
            "Training [5392/10000]: Loss: 0.013\n",
            "Training [5393/10000]: Loss: 0.013\n",
            "Training [5394/10000]: Loss: 0.014\n",
            "Training [5395/10000]: Loss: 0.016\n",
            "Training [5396/10000]: Loss: 0.012\n",
            "Training [5397/10000]: Loss: 0.010\n",
            "Training [5398/10000]: Loss: 0.016\n",
            "Training [5399/10000]: Loss: 0.012\n",
            "Training [5400/10000]: Loss: 0.009\n",
            "Test Loss: 0.050\n",
            "Training [5401/10000]: Loss: 0.019\n",
            "Training [5402/10000]: Loss: 0.012\n",
            "Training [5403/10000]: Loss: 0.013\n",
            "Training [5404/10000]: Loss: 0.018\n",
            "Training [5405/10000]: Loss: 0.022\n",
            "Training [5406/10000]: Loss: 0.012\n",
            "Training [5407/10000]: Loss: 0.018\n",
            "Training [5408/10000]: Loss: 0.016\n",
            "Training [5409/10000]: Loss: 0.013\n",
            "Training [5410/10000]: Loss: 0.012\n",
            "Training [5411/10000]: Loss: 0.014\n",
            "Training [5412/10000]: Loss: 0.015\n",
            "Training [5413/10000]: Loss: 0.019\n",
            "Training [5414/10000]: Loss: 0.018\n",
            "Training [5415/10000]: Loss: 0.017\n",
            "Training [5416/10000]: Loss: 0.015\n",
            "Training [5417/10000]: Loss: 0.015\n",
            "Training [5418/10000]: Loss: 0.015\n",
            "Training [5419/10000]: Loss: 0.017\n",
            "Training [5420/10000]: Loss: 0.011\n",
            "Training [5421/10000]: Loss: 0.016\n",
            "Training [5422/10000]: Loss: 0.020\n",
            "Training [5423/10000]: Loss: 0.012\n",
            "Training [5424/10000]: Loss: 0.017\n",
            "Training [5425/10000]: Loss: 0.015\n",
            "Training [5426/10000]: Loss: 0.020\n",
            "Training [5427/10000]: Loss: 0.012\n",
            "Training [5428/10000]: Loss: 0.014\n",
            "Training [5429/10000]: Loss: 0.022\n",
            "Training [5430/10000]: Loss: 0.019\n",
            "Training [5431/10000]: Loss: 0.024\n",
            "Training [5432/10000]: Loss: 0.020\n",
            "Training [5433/10000]: Loss: 0.027\n",
            "Training [5434/10000]: Loss: 0.009\n",
            "Training [5435/10000]: Loss: 0.020\n",
            "Training [5436/10000]: Loss: 0.019\n",
            "Training [5437/10000]: Loss: 0.021\n",
            "Training [5438/10000]: Loss: 0.007\n",
            "Training [5439/10000]: Loss: 0.012\n",
            "Training [5440/10000]: Loss: 0.013\n",
            "Training [5441/10000]: Loss: 0.018\n",
            "Training [5442/10000]: Loss: 0.015\n",
            "Training [5443/10000]: Loss: 0.018\n",
            "Training [5444/10000]: Loss: 0.010\n",
            "Training [5445/10000]: Loss: 0.008\n",
            "Training [5446/10000]: Loss: 0.015\n",
            "Training [5447/10000]: Loss: 0.015\n",
            "Training [5448/10000]: Loss: 0.020\n",
            "Training [5449/10000]: Loss: 0.019\n",
            "Training [5450/10000]: Loss: 0.019\n",
            "Training [5451/10000]: Loss: 0.018\n",
            "Training [5452/10000]: Loss: 0.016\n",
            "Training [5453/10000]: Loss: 0.015\n",
            "Training [5454/10000]: Loss: 0.014\n",
            "Training [5455/10000]: Loss: 0.014\n",
            "Training [5456/10000]: Loss: 0.030\n",
            "Training [5457/10000]: Loss: 0.014\n",
            "Training [5458/10000]: Loss: 0.017\n",
            "Training [5459/10000]: Loss: 0.013\n",
            "Training [5460/10000]: Loss: 0.017\n",
            "Training [5461/10000]: Loss: 0.018\n",
            "Training [5462/10000]: Loss: 0.012\n",
            "Training [5463/10000]: Loss: 0.013\n",
            "Training [5464/10000]: Loss: 0.016\n",
            "Training [5465/10000]: Loss: 0.010\n",
            "Training [5466/10000]: Loss: 0.013\n",
            "Training [5467/10000]: Loss: 0.009\n",
            "Training [5468/10000]: Loss: 0.009\n",
            "Training [5469/10000]: Loss: 0.019\n",
            "Training [5470/10000]: Loss: 0.018\n",
            "Training [5471/10000]: Loss: 0.009\n",
            "Training [5472/10000]: Loss: 0.014\n",
            "Training [5473/10000]: Loss: 0.018\n",
            "Training [5474/10000]: Loss: 0.017\n",
            "Training [5475/10000]: Loss: 0.013\n",
            "Training [5476/10000]: Loss: 0.020\n",
            "Training [5477/10000]: Loss: 0.015\n",
            "Training [5478/10000]: Loss: 0.014\n",
            "Training [5479/10000]: Loss: 0.010\n",
            "Training [5480/10000]: Loss: 0.011\n",
            "Training [5481/10000]: Loss: 0.010\n",
            "Training [5482/10000]: Loss: 0.008\n",
            "Training [5483/10000]: Loss: 0.020\n",
            "Training [5484/10000]: Loss: 0.011\n",
            "Training [5485/10000]: Loss: 0.018\n",
            "Training [5486/10000]: Loss: 0.018\n",
            "Training [5487/10000]: Loss: 0.017\n",
            "Training [5488/10000]: Loss: 0.013\n",
            "Training [5489/10000]: Loss: 0.018\n",
            "Training [5490/10000]: Loss: 0.009\n",
            "Training [5491/10000]: Loss: 0.017\n",
            "Training [5492/10000]: Loss: 0.007\n",
            "Training [5493/10000]: Loss: 0.017\n",
            "Training [5494/10000]: Loss: 0.008\n",
            "Training [5495/10000]: Loss: 0.016\n",
            "Training [5496/10000]: Loss: 0.013\n",
            "Training [5497/10000]: Loss: 0.017\n",
            "Training [5498/10000]: Loss: 0.014\n",
            "Training [5499/10000]: Loss: 0.016\n",
            "Training [5500/10000]: Loss: 0.015\n",
            "Test Loss: 0.052\n",
            "Training [5501/10000]: Loss: 0.015\n",
            "Training [5502/10000]: Loss: 0.011\n",
            "Training [5503/10000]: Loss: 0.014\n",
            "Training [5504/10000]: Loss: 0.017\n",
            "Training [5505/10000]: Loss: 0.014\n",
            "Training [5506/10000]: Loss: 0.014\n",
            "Training [5507/10000]: Loss: 0.018\n",
            "Training [5508/10000]: Loss: 0.016\n",
            "Training [5509/10000]: Loss: 0.018\n",
            "Training [5510/10000]: Loss: 0.016\n",
            "Training [5511/10000]: Loss: 0.013\n",
            "Training [5512/10000]: Loss: 0.012\n",
            "Training [5513/10000]: Loss: 0.013\n",
            "Training [5514/10000]: Loss: 0.010\n",
            "Training [5515/10000]: Loss: 0.012\n",
            "Training [5516/10000]: Loss: 0.025\n",
            "Training [5517/10000]: Loss: 0.010\n",
            "Training [5518/10000]: Loss: 0.024\n",
            "Training [5519/10000]: Loss: 0.014\n",
            "Training [5520/10000]: Loss: 0.018\n",
            "Training [5521/10000]: Loss: 0.013\n",
            "Training [5522/10000]: Loss: 0.012\n",
            "Training [5523/10000]: Loss: 0.013\n",
            "Training [5524/10000]: Loss: 0.022\n",
            "Training [5525/10000]: Loss: 0.014\n",
            "Training [5526/10000]: Loss: 0.016\n",
            "Training [5527/10000]: Loss: 0.021\n",
            "Training [5528/10000]: Loss: 0.012\n",
            "Training [5529/10000]: Loss: 0.014\n",
            "Training [5530/10000]: Loss: 0.007\n",
            "Training [5531/10000]: Loss: 0.011\n",
            "Training [5532/10000]: Loss: 0.014\n",
            "Training [5533/10000]: Loss: 0.019\n",
            "Training [5534/10000]: Loss: 0.019\n",
            "Training [5535/10000]: Loss: 0.013\n",
            "Training [5536/10000]: Loss: 0.012\n",
            "Training [5537/10000]: Loss: 0.017\n",
            "Training [5538/10000]: Loss: 0.009\n",
            "Training [5539/10000]: Loss: 0.012\n",
            "Training [5540/10000]: Loss: 0.008\n",
            "Training [5541/10000]: Loss: 0.012\n",
            "Training [5542/10000]: Loss: 0.014\n",
            "Training [5543/10000]: Loss: 0.012\n",
            "Training [5544/10000]: Loss: 0.014\n",
            "Training [5545/10000]: Loss: 0.015\n",
            "Training [5546/10000]: Loss: 0.021\n",
            "Training [5547/10000]: Loss: 0.019\n",
            "Training [5548/10000]: Loss: 0.017\n",
            "Training [5549/10000]: Loss: 0.016\n",
            "Training [5550/10000]: Loss: 0.015\n",
            "Training [5551/10000]: Loss: 0.012\n",
            "Training [5552/10000]: Loss: 0.012\n",
            "Training [5553/10000]: Loss: 0.015\n",
            "Training [5554/10000]: Loss: 0.015\n",
            "Training [5555/10000]: Loss: 0.012\n",
            "Training [5556/10000]: Loss: 0.010\n",
            "Training [5557/10000]: Loss: 0.020\n",
            "Training [5558/10000]: Loss: 0.011\n",
            "Training [5559/10000]: Loss: 0.014\n",
            "Training [5560/10000]: Loss: 0.011\n",
            "Training [5561/10000]: Loss: 0.014\n",
            "Training [5562/10000]: Loss: 0.012\n",
            "Training [5563/10000]: Loss: 0.015\n",
            "Training [5564/10000]: Loss: 0.022\n",
            "Training [5565/10000]: Loss: 0.016\n",
            "Training [5566/10000]: Loss: 0.020\n",
            "Training [5567/10000]: Loss: 0.014\n",
            "Training [5568/10000]: Loss: 0.013\n",
            "Training [5569/10000]: Loss: 0.017\n",
            "Training [5570/10000]: Loss: 0.010\n",
            "Training [5571/10000]: Loss: 0.012\n",
            "Training [5572/10000]: Loss: 0.011\n",
            "Training [5573/10000]: Loss: 0.016\n",
            "Training [5574/10000]: Loss: 0.018\n",
            "Training [5575/10000]: Loss: 0.014\n",
            "Training [5576/10000]: Loss: 0.013\n",
            "Training [5577/10000]: Loss: 0.023\n",
            "Training [5578/10000]: Loss: 0.009\n",
            "Training [5579/10000]: Loss: 0.016\n",
            "Training [5580/10000]: Loss: 0.017\n",
            "Training [5581/10000]: Loss: 0.010\n",
            "Training [5582/10000]: Loss: 0.022\n",
            "Training [5583/10000]: Loss: 0.011\n",
            "Training [5584/10000]: Loss: 0.014\n",
            "Training [5585/10000]: Loss: 0.018\n",
            "Training [5586/10000]: Loss: 0.013\n",
            "Training [5587/10000]: Loss: 0.012\n",
            "Training [5588/10000]: Loss: 0.015\n",
            "Training [5589/10000]: Loss: 0.017\n",
            "Training [5590/10000]: Loss: 0.010\n",
            "Training [5591/10000]: Loss: 0.011\n",
            "Training [5592/10000]: Loss: 0.011\n",
            "Training [5593/10000]: Loss: 0.015\n",
            "Training [5594/10000]: Loss: 0.015\n",
            "Training [5595/10000]: Loss: 0.015\n",
            "Training [5596/10000]: Loss: 0.014\n",
            "Training [5597/10000]: Loss: 0.018\n",
            "Training [5598/10000]: Loss: 0.015\n",
            "Training [5599/10000]: Loss: 0.015\n",
            "Training [5600/10000]: Loss: 0.012\n",
            "Test Loss: 0.050\n",
            "Training [5601/10000]: Loss: 0.016\n",
            "Training [5602/10000]: Loss: 0.013\n",
            "Training [5603/10000]: Loss: 0.015\n",
            "Training [5604/10000]: Loss: 0.011\n",
            "Training [5605/10000]: Loss: 0.016\n",
            "Training [5606/10000]: Loss: 0.015\n",
            "Training [5607/10000]: Loss: 0.011\n",
            "Training [5608/10000]: Loss: 0.016\n",
            "Training [5609/10000]: Loss: 0.015\n",
            "Training [5610/10000]: Loss: 0.014\n",
            "Training [5611/10000]: Loss: 0.008\n",
            "Training [5612/10000]: Loss: 0.016\n",
            "Training [5613/10000]: Loss: 0.015\n",
            "Training [5614/10000]: Loss: 0.013\n",
            "Training [5615/10000]: Loss: 0.011\n",
            "Training [5616/10000]: Loss: 0.011\n",
            "Training [5617/10000]: Loss: 0.018\n",
            "Training [5618/10000]: Loss: 0.013\n",
            "Training [5619/10000]: Loss: 0.013\n",
            "Training [5620/10000]: Loss: 0.019\n",
            "Training [5621/10000]: Loss: 0.012\n",
            "Training [5622/10000]: Loss: 0.009\n",
            "Training [5623/10000]: Loss: 0.012\n",
            "Training [5624/10000]: Loss: 0.019\n",
            "Training [5625/10000]: Loss: 0.017\n",
            "Training [5626/10000]: Loss: 0.010\n",
            "Training [5627/10000]: Loss: 0.012\n",
            "Training [5628/10000]: Loss: 0.013\n",
            "Training [5629/10000]: Loss: 0.020\n",
            "Training [5630/10000]: Loss: 0.016\n",
            "Training [5631/10000]: Loss: 0.014\n",
            "Training [5632/10000]: Loss: 0.012\n",
            "Training [5633/10000]: Loss: 0.015\n",
            "Training [5634/10000]: Loss: 0.015\n",
            "Training [5635/10000]: Loss: 0.014\n",
            "Training [5636/10000]: Loss: 0.013\n",
            "Training [5637/10000]: Loss: 0.015\n",
            "Training [5638/10000]: Loss: 0.013\n",
            "Training [5639/10000]: Loss: 0.011\n",
            "Training [5640/10000]: Loss: 0.010\n",
            "Training [5641/10000]: Loss: 0.014\n",
            "Training [5642/10000]: Loss: 0.017\n",
            "Training [5643/10000]: Loss: 0.018\n",
            "Training [5644/10000]: Loss: 0.014\n",
            "Training [5645/10000]: Loss: 0.015\n",
            "Training [5646/10000]: Loss: 0.009\n",
            "Training [5647/10000]: Loss: 0.015\n",
            "Training [5648/10000]: Loss: 0.013\n",
            "Training [5649/10000]: Loss: 0.011\n",
            "Training [5650/10000]: Loss: 0.012\n",
            "Training [5651/10000]: Loss: 0.008\n",
            "Training [5652/10000]: Loss: 0.012\n",
            "Training [5653/10000]: Loss: 0.012\n",
            "Training [5654/10000]: Loss: 0.018\n",
            "Training [5655/10000]: Loss: 0.025\n",
            "Training [5656/10000]: Loss: 0.013\n",
            "Training [5657/10000]: Loss: 0.024\n",
            "Training [5658/10000]: Loss: 0.018\n",
            "Training [5659/10000]: Loss: 0.014\n",
            "Training [5660/10000]: Loss: 0.010\n",
            "Training [5661/10000]: Loss: 0.015\n",
            "Training [5662/10000]: Loss: 0.018\n",
            "Training [5663/10000]: Loss: 0.014\n",
            "Training [5664/10000]: Loss: 0.018\n",
            "Training [5665/10000]: Loss: 0.010\n",
            "Training [5666/10000]: Loss: 0.017\n",
            "Training [5667/10000]: Loss: 0.014\n",
            "Training [5668/10000]: Loss: 0.017\n",
            "Training [5669/10000]: Loss: 0.011\n",
            "Training [5670/10000]: Loss: 0.014\n",
            "Training [5671/10000]: Loss: 0.014\n",
            "Training [5672/10000]: Loss: 0.016\n",
            "Training [5673/10000]: Loss: 0.016\n",
            "Training [5674/10000]: Loss: 0.014\n",
            "Training [5675/10000]: Loss: 0.014\n",
            "Training [5676/10000]: Loss: 0.015\n",
            "Training [5677/10000]: Loss: 0.017\n",
            "Training [5678/10000]: Loss: 0.018\n",
            "Training [5679/10000]: Loss: 0.013\n",
            "Training [5680/10000]: Loss: 0.013\n",
            "Training [5681/10000]: Loss: 0.011\n",
            "Training [5682/10000]: Loss: 0.015\n",
            "Training [5683/10000]: Loss: 0.019\n",
            "Training [5684/10000]: Loss: 0.013\n",
            "Training [5685/10000]: Loss: 0.015\n",
            "Training [5686/10000]: Loss: 0.015\n",
            "Training [5687/10000]: Loss: 0.011\n",
            "Training [5688/10000]: Loss: 0.015\n",
            "Training [5689/10000]: Loss: 0.016\n",
            "Training [5690/10000]: Loss: 0.016\n",
            "Training [5691/10000]: Loss: 0.019\n",
            "Training [5692/10000]: Loss: 0.014\n",
            "Training [5693/10000]: Loss: 0.016\n",
            "Training [5694/10000]: Loss: 0.013\n",
            "Training [5695/10000]: Loss: 0.011\n",
            "Training [5696/10000]: Loss: 0.017\n",
            "Training [5697/10000]: Loss: 0.011\n",
            "Training [5698/10000]: Loss: 0.016\n",
            "Training [5699/10000]: Loss: 0.018\n",
            "Training [5700/10000]: Loss: 0.011\n",
            "Test Loss: 0.060\n",
            "Training [5701/10000]: Loss: 0.013\n",
            "Training [5702/10000]: Loss: 0.020\n",
            "Training [5703/10000]: Loss: 0.014\n",
            "Training [5704/10000]: Loss: 0.009\n",
            "Training [5705/10000]: Loss: 0.015\n",
            "Training [5706/10000]: Loss: 0.013\n",
            "Training [5707/10000]: Loss: 0.014\n",
            "Training [5708/10000]: Loss: 0.014\n",
            "Training [5709/10000]: Loss: 0.014\n",
            "Training [5710/10000]: Loss: 0.015\n",
            "Training [5711/10000]: Loss: 0.021\n",
            "Training [5712/10000]: Loss: 0.017\n",
            "Training [5713/10000]: Loss: 0.012\n",
            "Training [5714/10000]: Loss: 0.015\n",
            "Training [5715/10000]: Loss: 0.011\n",
            "Training [5716/10000]: Loss: 0.016\n",
            "Training [5717/10000]: Loss: 0.013\n",
            "Training [5718/10000]: Loss: 0.017\n",
            "Training [5719/10000]: Loss: 0.017\n",
            "Training [5720/10000]: Loss: 0.016\n",
            "Training [5721/10000]: Loss: 0.010\n",
            "Training [5722/10000]: Loss: 0.015\n",
            "Training [5723/10000]: Loss: 0.014\n",
            "Training [5724/10000]: Loss: 0.019\n",
            "Training [5725/10000]: Loss: 0.014\n",
            "Training [5726/10000]: Loss: 0.015\n",
            "Training [5727/10000]: Loss: 0.015\n",
            "Training [5728/10000]: Loss: 0.012\n",
            "Training [5729/10000]: Loss: 0.015\n",
            "Training [5730/10000]: Loss: 0.019\n",
            "Training [5731/10000]: Loss: 0.005\n",
            "Training [5732/10000]: Loss: 0.013\n",
            "Training [5733/10000]: Loss: 0.013\n",
            "Training [5734/10000]: Loss: 0.012\n",
            "Training [5735/10000]: Loss: 0.024\n",
            "Training [5736/10000]: Loss: 0.015\n",
            "Training [5737/10000]: Loss: 0.016\n",
            "Training [5738/10000]: Loss: 0.011\n",
            "Training [5739/10000]: Loss: 0.020\n",
            "Training [5740/10000]: Loss: 0.018\n",
            "Training [5741/10000]: Loss: 0.016\n",
            "Training [5742/10000]: Loss: 0.012\n",
            "Training [5743/10000]: Loss: 0.011\n",
            "Training [5744/10000]: Loss: 0.011\n",
            "Training [5745/10000]: Loss: 0.017\n",
            "Training [5746/10000]: Loss: 0.015\n",
            "Training [5747/10000]: Loss: 0.016\n",
            "Training [5748/10000]: Loss: 0.019\n",
            "Training [5749/10000]: Loss: 0.015\n",
            "Training [5750/10000]: Loss: 0.021\n",
            "Training [5751/10000]: Loss: 0.010\n",
            "Training [5752/10000]: Loss: 0.014\n",
            "Training [5753/10000]: Loss: 0.012\n",
            "Training [5754/10000]: Loss: 0.015\n",
            "Training [5755/10000]: Loss: 0.012\n",
            "Training [5756/10000]: Loss: 0.016\n",
            "Training [5757/10000]: Loss: 0.012\n",
            "Training [5758/10000]: Loss: 0.014\n",
            "Training [5759/10000]: Loss: 0.023\n",
            "Training [5760/10000]: Loss: 0.012\n",
            "Training [5761/10000]: Loss: 0.011\n",
            "Training [5762/10000]: Loss: 0.008\n",
            "Training [5763/10000]: Loss: 0.016\n",
            "Training [5764/10000]: Loss: 0.013\n",
            "Training [5765/10000]: Loss: 0.015\n",
            "Training [5766/10000]: Loss: 0.015\n",
            "Training [5767/10000]: Loss: 0.014\n",
            "Training [5768/10000]: Loss: 0.009\n",
            "Training [5769/10000]: Loss: 0.018\n",
            "Training [5770/10000]: Loss: 0.010\n",
            "Training [5771/10000]: Loss: 0.016\n",
            "Training [5772/10000]: Loss: 0.010\n",
            "Training [5773/10000]: Loss: 0.016\n",
            "Training [5774/10000]: Loss: 0.011\n",
            "Training [5775/10000]: Loss: 0.015\n",
            "Training [5776/10000]: Loss: 0.019\n",
            "Training [5777/10000]: Loss: 0.008\n",
            "Training [5778/10000]: Loss: 0.012\n",
            "Training [5779/10000]: Loss: 0.014\n",
            "Training [5780/10000]: Loss: 0.015\n",
            "Training [5781/10000]: Loss: 0.009\n",
            "Training [5782/10000]: Loss: 0.014\n",
            "Training [5783/10000]: Loss: 0.015\n",
            "Training [5784/10000]: Loss: 0.019\n",
            "Training [5785/10000]: Loss: 0.016\n",
            "Training [5786/10000]: Loss: 0.013\n",
            "Training [5787/10000]: Loss: 0.013\n",
            "Training [5788/10000]: Loss: 0.019\n",
            "Training [5789/10000]: Loss: 0.016\n",
            "Training [5790/10000]: Loss: 0.021\n",
            "Training [5791/10000]: Loss: 0.012\n",
            "Training [5792/10000]: Loss: 0.014\n",
            "Training [5793/10000]: Loss: 0.015\n",
            "Training [5794/10000]: Loss: 0.008\n",
            "Training [5795/10000]: Loss: 0.013\n",
            "Training [5796/10000]: Loss: 0.015\n",
            "Training [5797/10000]: Loss: 0.013\n",
            "Training [5798/10000]: Loss: 0.012\n",
            "Training [5799/10000]: Loss: 0.014\n",
            "Training [5800/10000]: Loss: 0.016\n",
            "Test Loss: 0.052\n",
            "Training [5801/10000]: Loss: 0.012\n",
            "Training [5802/10000]: Loss: 0.010\n",
            "Training [5803/10000]: Loss: 0.019\n",
            "Training [5804/10000]: Loss: 0.009\n",
            "Training [5805/10000]: Loss: 0.010\n",
            "Training [5806/10000]: Loss: 0.017\n",
            "Training [5807/10000]: Loss: 0.014\n",
            "Training [5808/10000]: Loss: 0.019\n",
            "Training [5809/10000]: Loss: 0.013\n",
            "Training [5810/10000]: Loss: 0.015\n",
            "Training [5811/10000]: Loss: 0.013\n",
            "Training [5812/10000]: Loss: 0.012\n",
            "Training [5813/10000]: Loss: 0.012\n",
            "Training [5814/10000]: Loss: 0.011\n",
            "Training [5815/10000]: Loss: 0.015\n",
            "Training [5816/10000]: Loss: 0.021\n",
            "Training [5817/10000]: Loss: 0.013\n",
            "Training [5818/10000]: Loss: 0.012\n",
            "Training [5819/10000]: Loss: 0.014\n",
            "Training [5820/10000]: Loss: 0.017\n",
            "Training [5821/10000]: Loss: 0.017\n",
            "Training [5822/10000]: Loss: 0.011\n",
            "Training [5823/10000]: Loss: 0.008\n",
            "Training [5824/10000]: Loss: 0.014\n",
            "Training [5825/10000]: Loss: 0.013\n",
            "Training [5826/10000]: Loss: 0.007\n",
            "Training [5827/10000]: Loss: 0.017\n",
            "Training [5828/10000]: Loss: 0.016\n",
            "Training [5829/10000]: Loss: 0.019\n",
            "Training [5830/10000]: Loss: 0.013\n",
            "Training [5831/10000]: Loss: 0.011\n",
            "Training [5832/10000]: Loss: 0.011\n",
            "Training [5833/10000]: Loss: 0.012\n",
            "Training [5834/10000]: Loss: 0.014\n",
            "Training [5835/10000]: Loss: 0.022\n",
            "Training [5836/10000]: Loss: 0.011\n",
            "Training [5837/10000]: Loss: 0.012\n",
            "Training [5838/10000]: Loss: 0.014\n",
            "Training [5839/10000]: Loss: 0.010\n",
            "Training [5840/10000]: Loss: 0.013\n",
            "Training [5841/10000]: Loss: 0.015\n",
            "Training [5842/10000]: Loss: 0.016\n",
            "Training [5843/10000]: Loss: 0.008\n",
            "Training [5844/10000]: Loss: 0.014\n",
            "Training [5845/10000]: Loss: 0.014\n",
            "Training [5846/10000]: Loss: 0.017\n",
            "Training [5847/10000]: Loss: 0.014\n",
            "Training [5848/10000]: Loss: 0.014\n",
            "Training [5849/10000]: Loss: 0.015\n",
            "Training [5850/10000]: Loss: 0.016\n",
            "Training [5851/10000]: Loss: 0.013\n",
            "Training [5852/10000]: Loss: 0.015\n",
            "Training [5853/10000]: Loss: 0.016\n",
            "Training [5854/10000]: Loss: 0.012\n",
            "Training [5855/10000]: Loss: 0.010\n",
            "Training [5856/10000]: Loss: 0.012\n",
            "Training [5857/10000]: Loss: 0.018\n",
            "Training [5858/10000]: Loss: 0.014\n",
            "Training [5859/10000]: Loss: 0.013\n",
            "Training [5860/10000]: Loss: 0.012\n",
            "Training [5861/10000]: Loss: 0.013\n",
            "Training [5862/10000]: Loss: 0.015\n",
            "Training [5863/10000]: Loss: 0.014\n",
            "Training [5864/10000]: Loss: 0.011\n",
            "Training [5865/10000]: Loss: 0.013\n",
            "Training [5866/10000]: Loss: 0.012\n",
            "Training [5867/10000]: Loss: 0.010\n",
            "Training [5868/10000]: Loss: 0.011\n",
            "Training [5869/10000]: Loss: 0.017\n",
            "Training [5870/10000]: Loss: 0.014\n",
            "Training [5871/10000]: Loss: 0.015\n",
            "Training [5872/10000]: Loss: 0.013\n",
            "Training [5873/10000]: Loss: 0.017\n",
            "Training [5874/10000]: Loss: 0.014\n",
            "Training [5875/10000]: Loss: 0.018\n",
            "Training [5876/10000]: Loss: 0.015\n",
            "Training [5877/10000]: Loss: 0.017\n",
            "Training [5878/10000]: Loss: 0.017\n",
            "Training [5879/10000]: Loss: 0.010\n",
            "Training [5880/10000]: Loss: 0.018\n",
            "Training [5881/10000]: Loss: 0.020\n",
            "Training [5882/10000]: Loss: 0.009\n",
            "Training [5883/10000]: Loss: 0.013\n",
            "Training [5884/10000]: Loss: 0.020\n",
            "Training [5885/10000]: Loss: 0.013\n",
            "Training [5886/10000]: Loss: 0.015\n",
            "Training [5887/10000]: Loss: 0.013\n",
            "Training [5888/10000]: Loss: 0.013\n",
            "Training [5889/10000]: Loss: 0.016\n",
            "Training [5890/10000]: Loss: 0.011\n",
            "Training [5891/10000]: Loss: 0.016\n",
            "Training [5892/10000]: Loss: 0.019\n",
            "Training [5893/10000]: Loss: 0.015\n",
            "Training [5894/10000]: Loss: 0.014\n",
            "Training [5895/10000]: Loss: 0.015\n",
            "Training [5896/10000]: Loss: 0.010\n",
            "Training [5897/10000]: Loss: 0.008\n",
            "Training [5898/10000]: Loss: 0.013\n",
            "Training [5899/10000]: Loss: 0.013\n",
            "Training [5900/10000]: Loss: 0.011\n",
            "Test Loss: 0.056\n",
            "Training [5901/10000]: Loss: 0.015\n",
            "Training [5902/10000]: Loss: 0.010\n",
            "Training [5903/10000]: Loss: 0.012\n",
            "Training [5904/10000]: Loss: 0.015\n",
            "Training [5905/10000]: Loss: 0.017\n",
            "Training [5906/10000]: Loss: 0.018\n",
            "Training [5907/10000]: Loss: 0.019\n",
            "Training [5908/10000]: Loss: 0.015\n",
            "Training [5909/10000]: Loss: 0.015\n",
            "Training [5910/10000]: Loss: 0.013\n",
            "Training [5911/10000]: Loss: 0.018\n",
            "Training [5912/10000]: Loss: 0.012\n",
            "Training [5913/10000]: Loss: 0.015\n",
            "Training [5914/10000]: Loss: 0.011\n",
            "Training [5915/10000]: Loss: 0.017\n",
            "Training [5916/10000]: Loss: 0.008\n",
            "Training [5917/10000]: Loss: 0.009\n",
            "Training [5918/10000]: Loss: 0.013\n",
            "Training [5919/10000]: Loss: 0.022\n",
            "Training [5920/10000]: Loss: 0.017\n",
            "Training [5921/10000]: Loss: 0.014\n",
            "Training [5922/10000]: Loss: 0.011\n",
            "Training [5923/10000]: Loss: 0.013\n",
            "Training [5924/10000]: Loss: 0.018\n",
            "Training [5925/10000]: Loss: 0.011\n",
            "Training [5926/10000]: Loss: 0.008\n",
            "Training [5927/10000]: Loss: 0.006\n",
            "Training [5928/10000]: Loss: 0.017\n",
            "Training [5929/10000]: Loss: 0.020\n",
            "Training [5930/10000]: Loss: 0.016\n",
            "Training [5931/10000]: Loss: 0.008\n",
            "Training [5932/10000]: Loss: 0.023\n",
            "Training [5933/10000]: Loss: 0.014\n",
            "Training [5934/10000]: Loss: 0.010\n",
            "Training [5935/10000]: Loss: 0.018\n",
            "Training [5936/10000]: Loss: 0.016\n",
            "Training [5937/10000]: Loss: 0.011\n",
            "Training [5938/10000]: Loss: 0.008\n",
            "Training [5939/10000]: Loss: 0.014\n",
            "Training [5940/10000]: Loss: 0.013\n",
            "Training [5941/10000]: Loss: 0.014\n",
            "Training [5942/10000]: Loss: 0.013\n",
            "Training [5943/10000]: Loss: 0.013\n",
            "Training [5944/10000]: Loss: 0.016\n",
            "Training [5945/10000]: Loss: 0.011\n",
            "Training [5946/10000]: Loss: 0.015\n",
            "Training [5947/10000]: Loss: 0.018\n",
            "Training [5948/10000]: Loss: 0.012\n",
            "Training [5949/10000]: Loss: 0.013\n",
            "Training [5950/10000]: Loss: 0.019\n",
            "Training [5951/10000]: Loss: 0.012\n",
            "Training [5952/10000]: Loss: 0.014\n",
            "Training [5953/10000]: Loss: 0.011\n",
            "Training [5954/10000]: Loss: 0.021\n",
            "Training [5955/10000]: Loss: 0.014\n",
            "Training [5956/10000]: Loss: 0.013\n",
            "Training [5957/10000]: Loss: 0.011\n",
            "Training [5958/10000]: Loss: 0.010\n",
            "Training [5959/10000]: Loss: 0.014\n",
            "Training [5960/10000]: Loss: 0.014\n",
            "Training [5961/10000]: Loss: 0.014\n",
            "Training [5962/10000]: Loss: 0.013\n",
            "Training [5963/10000]: Loss: 0.014\n",
            "Training [5964/10000]: Loss: 0.011\n",
            "Training [5965/10000]: Loss: 0.018\n",
            "Training [5966/10000]: Loss: 0.013\n",
            "Training [5967/10000]: Loss: 0.011\n",
            "Training [5968/10000]: Loss: 0.014\n",
            "Training [5969/10000]: Loss: 0.014\n",
            "Training [5970/10000]: Loss: 0.014\n",
            "Training [5971/10000]: Loss: 0.014\n",
            "Training [5972/10000]: Loss: 0.012\n",
            "Training [5973/10000]: Loss: 0.019\n",
            "Training [5974/10000]: Loss: 0.015\n",
            "Training [5975/10000]: Loss: 0.018\n",
            "Training [5976/10000]: Loss: 0.010\n",
            "Training [5977/10000]: Loss: 0.013\n",
            "Training [5978/10000]: Loss: 0.015\n",
            "Training [5979/10000]: Loss: 0.013\n",
            "Training [5980/10000]: Loss: 0.016\n",
            "Training [5981/10000]: Loss: 0.013\n",
            "Training [5982/10000]: Loss: 0.008\n",
            "Training [5983/10000]: Loss: 0.009\n",
            "Training [5984/10000]: Loss: 0.010\n",
            "Training [5985/10000]: Loss: 0.009\n",
            "Training [5986/10000]: Loss: 0.011\n",
            "Training [5987/10000]: Loss: 0.014\n",
            "Training [5988/10000]: Loss: 0.013\n",
            "Training [5989/10000]: Loss: 0.014\n",
            "Training [5990/10000]: Loss: 0.013\n",
            "Training [5991/10000]: Loss: 0.011\n",
            "Training [5992/10000]: Loss: 0.008\n",
            "Training [5993/10000]: Loss: 0.018\n",
            "Training [5994/10000]: Loss: 0.017\n",
            "Training [5995/10000]: Loss: 0.009\n",
            "Training [5996/10000]: Loss: 0.007\n",
            "Training [5997/10000]: Loss: 0.015\n",
            "Training [5998/10000]: Loss: 0.018\n",
            "Training [5999/10000]: Loss: 0.009\n",
            "Training [6000/10000]: Loss: 0.016\n",
            "Test Loss: 0.052\n",
            "Training [6001/10000]: Loss: 0.015\n",
            "Training [6002/10000]: Loss: 0.010\n",
            "Training [6003/10000]: Loss: 0.012\n",
            "Training [6004/10000]: Loss: 0.015\n",
            "Training [6005/10000]: Loss: 0.015\n",
            "Training [6006/10000]: Loss: 0.012\n",
            "Training [6007/10000]: Loss: 0.009\n",
            "Training [6008/10000]: Loss: 0.012\n",
            "Training [6009/10000]: Loss: 0.011\n",
            "Training [6010/10000]: Loss: 0.012\n",
            "Training [6011/10000]: Loss: 0.014\n",
            "Training [6012/10000]: Loss: 0.014\n",
            "Training [6013/10000]: Loss: 0.013\n",
            "Training [6014/10000]: Loss: 0.011\n",
            "Training [6015/10000]: Loss: 0.013\n",
            "Training [6016/10000]: Loss: 0.009\n",
            "Training [6017/10000]: Loss: 0.010\n",
            "Training [6018/10000]: Loss: 0.012\n",
            "Training [6019/10000]: Loss: 0.013\n",
            "Training [6020/10000]: Loss: 0.016\n",
            "Training [6021/10000]: Loss: 0.013\n",
            "Training [6022/10000]: Loss: 0.017\n",
            "Training [6023/10000]: Loss: 0.022\n",
            "Training [6024/10000]: Loss: 0.010\n",
            "Training [6025/10000]: Loss: 0.009\n",
            "Training [6026/10000]: Loss: 0.010\n",
            "Training [6027/10000]: Loss: 0.010\n",
            "Training [6028/10000]: Loss: 0.011\n",
            "Training [6029/10000]: Loss: 0.011\n",
            "Training [6030/10000]: Loss: 0.014\n",
            "Training [6031/10000]: Loss: 0.017\n",
            "Training [6032/10000]: Loss: 0.013\n",
            "Training [6033/10000]: Loss: 0.013\n",
            "Training [6034/10000]: Loss: 0.018\n",
            "Training [6035/10000]: Loss: 0.021\n",
            "Training [6036/10000]: Loss: 0.015\n",
            "Training [6037/10000]: Loss: 0.011\n",
            "Training [6038/10000]: Loss: 0.014\n",
            "Training [6039/10000]: Loss: 0.012\n",
            "Training [6040/10000]: Loss: 0.015\n",
            "Training [6041/10000]: Loss: 0.012\n",
            "Training [6042/10000]: Loss: 0.016\n",
            "Training [6043/10000]: Loss: 0.010\n",
            "Training [6044/10000]: Loss: 0.014\n",
            "Training [6045/10000]: Loss: 0.016\n",
            "Training [6046/10000]: Loss: 0.014\n",
            "Training [6047/10000]: Loss: 0.010\n",
            "Training [6048/10000]: Loss: 0.011\n",
            "Training [6049/10000]: Loss: 0.016\n",
            "Training [6050/10000]: Loss: 0.012\n",
            "Training [6051/10000]: Loss: 0.015\n",
            "Training [6052/10000]: Loss: 0.012\n",
            "Training [6053/10000]: Loss: 0.010\n",
            "Training [6054/10000]: Loss: 0.014\n",
            "Training [6055/10000]: Loss: 0.015\n",
            "Training [6056/10000]: Loss: 0.015\n",
            "Training [6057/10000]: Loss: 0.011\n",
            "Training [6058/10000]: Loss: 0.014\n",
            "Training [6059/10000]: Loss: 0.008\n",
            "Training [6060/10000]: Loss: 0.016\n",
            "Training [6061/10000]: Loss: 0.014\n",
            "Training [6062/10000]: Loss: 0.013\n",
            "Training [6063/10000]: Loss: 0.014\n",
            "Training [6064/10000]: Loss: 0.012\n",
            "Training [6065/10000]: Loss: 0.015\n",
            "Training [6066/10000]: Loss: 0.021\n",
            "Training [6067/10000]: Loss: 0.013\n",
            "Training [6068/10000]: Loss: 0.013\n",
            "Training [6069/10000]: Loss: 0.010\n",
            "Training [6070/10000]: Loss: 0.016\n",
            "Training [6071/10000]: Loss: 0.012\n",
            "Training [6072/10000]: Loss: 0.013\n",
            "Training [6073/10000]: Loss: 0.015\n",
            "Training [6074/10000]: Loss: 0.007\n",
            "Training [6075/10000]: Loss: 0.013\n",
            "Training [6076/10000]: Loss: 0.009\n",
            "Training [6077/10000]: Loss: 0.018\n",
            "Training [6078/10000]: Loss: 0.019\n",
            "Training [6079/10000]: Loss: 0.013\n",
            "Training [6080/10000]: Loss: 0.015\n",
            "Training [6081/10000]: Loss: 0.014\n",
            "Training [6082/10000]: Loss: 0.014\n",
            "Training [6083/10000]: Loss: 0.014\n",
            "Training [6084/10000]: Loss: 0.009\n",
            "Training [6085/10000]: Loss: 0.014\n",
            "Training [6086/10000]: Loss: 0.012\n",
            "Training [6087/10000]: Loss: 0.013\n",
            "Training [6088/10000]: Loss: 0.014\n",
            "Training [6089/10000]: Loss: 0.016\n",
            "Training [6090/10000]: Loss: 0.011\n",
            "Training [6091/10000]: Loss: 0.015\n",
            "Training [6092/10000]: Loss: 0.012\n",
            "Training [6093/10000]: Loss: 0.009\n",
            "Training [6094/10000]: Loss: 0.016\n",
            "Training [6095/10000]: Loss: 0.010\n",
            "Training [6096/10000]: Loss: 0.015\n",
            "Training [6097/10000]: Loss: 0.009\n",
            "Training [6098/10000]: Loss: 0.013\n",
            "Training [6099/10000]: Loss: 0.021\n",
            "Training [6100/10000]: Loss: 0.021\n",
            "Test Loss: 0.066\n",
            "Training [6101/10000]: Loss: 0.013\n",
            "Training [6102/10000]: Loss: 0.016\n",
            "Training [6103/10000]: Loss: 0.011\n",
            "Training [6104/10000]: Loss: 0.016\n",
            "Training [6105/10000]: Loss: 0.017\n",
            "Training [6106/10000]: Loss: 0.013\n",
            "Training [6107/10000]: Loss: 0.017\n",
            "Training [6108/10000]: Loss: 0.017\n",
            "Training [6109/10000]: Loss: 0.011\n",
            "Training [6110/10000]: Loss: 0.011\n",
            "Training [6111/10000]: Loss: 0.014\n",
            "Training [6112/10000]: Loss: 0.013\n",
            "Training [6113/10000]: Loss: 0.016\n",
            "Training [6114/10000]: Loss: 0.015\n",
            "Training [6115/10000]: Loss: 0.013\n",
            "Training [6116/10000]: Loss: 0.012\n",
            "Training [6117/10000]: Loss: 0.017\n",
            "Training [6118/10000]: Loss: 0.014\n",
            "Training [6119/10000]: Loss: 0.014\n",
            "Training [6120/10000]: Loss: 0.015\n",
            "Training [6121/10000]: Loss: 0.012\n",
            "Training [6122/10000]: Loss: 0.010\n",
            "Training [6123/10000]: Loss: 0.009\n",
            "Training [6124/10000]: Loss: 0.012\n",
            "Training [6125/10000]: Loss: 0.016\n",
            "Training [6126/10000]: Loss: 0.010\n",
            "Training [6127/10000]: Loss: 0.008\n",
            "Training [6128/10000]: Loss: 0.013\n",
            "Training [6129/10000]: Loss: 0.009\n",
            "Training [6130/10000]: Loss: 0.012\n",
            "Training [6131/10000]: Loss: 0.013\n",
            "Training [6132/10000]: Loss: 0.011\n",
            "Training [6133/10000]: Loss: 0.023\n",
            "Training [6134/10000]: Loss: 0.011\n",
            "Training [6135/10000]: Loss: 0.016\n",
            "Training [6136/10000]: Loss: 0.008\n",
            "Training [6137/10000]: Loss: 0.013\n",
            "Training [6138/10000]: Loss: 0.014\n",
            "Training [6139/10000]: Loss: 0.018\n",
            "Training [6140/10000]: Loss: 0.013\n",
            "Training [6141/10000]: Loss: 0.014\n",
            "Training [6142/10000]: Loss: 0.018\n",
            "Training [6143/10000]: Loss: 0.024\n",
            "Training [6144/10000]: Loss: 0.009\n",
            "Training [6145/10000]: Loss: 0.020\n",
            "Training [6146/10000]: Loss: 0.012\n",
            "Training [6147/10000]: Loss: 0.016\n",
            "Training [6148/10000]: Loss: 0.016\n",
            "Training [6149/10000]: Loss: 0.009\n",
            "Training [6150/10000]: Loss: 0.017\n",
            "Training [6151/10000]: Loss: 0.007\n",
            "Training [6152/10000]: Loss: 0.014\n",
            "Training [6153/10000]: Loss: 0.017\n",
            "Training [6154/10000]: Loss: 0.013\n",
            "Training [6155/10000]: Loss: 0.013\n",
            "Training [6156/10000]: Loss: 0.010\n",
            "Training [6157/10000]: Loss: 0.013\n",
            "Training [6158/10000]: Loss: 0.010\n",
            "Training [6159/10000]: Loss: 0.015\n",
            "Training [6160/10000]: Loss: 0.011\n",
            "Training [6161/10000]: Loss: 0.016\n",
            "Training [6162/10000]: Loss: 0.013\n",
            "Training [6163/10000]: Loss: 0.011\n",
            "Training [6164/10000]: Loss: 0.015\n",
            "Training [6165/10000]: Loss: 0.011\n",
            "Training [6166/10000]: Loss: 0.012\n",
            "Training [6167/10000]: Loss: 0.012\n",
            "Training [6168/10000]: Loss: 0.011\n",
            "Training [6169/10000]: Loss: 0.016\n",
            "Training [6170/10000]: Loss: 0.013\n",
            "Training [6171/10000]: Loss: 0.008\n",
            "Training [6172/10000]: Loss: 0.011\n",
            "Training [6173/10000]: Loss: 0.009\n",
            "Training [6174/10000]: Loss: 0.012\n",
            "Training [6175/10000]: Loss: 0.016\n",
            "Training [6176/10000]: Loss: 0.012\n",
            "Training [6177/10000]: Loss: 0.013\n",
            "Training [6178/10000]: Loss: 0.007\n",
            "Training [6179/10000]: Loss: 0.018\n",
            "Training [6180/10000]: Loss: 0.012\n",
            "Training [6181/10000]: Loss: 0.017\n",
            "Training [6182/10000]: Loss: 0.017\n",
            "Training [6183/10000]: Loss: 0.012\n",
            "Training [6184/10000]: Loss: 0.014\n",
            "Training [6185/10000]: Loss: 0.016\n",
            "Training [6186/10000]: Loss: 0.018\n",
            "Training [6187/10000]: Loss: 0.016\n",
            "Training [6188/10000]: Loss: 0.016\n",
            "Training [6189/10000]: Loss: 0.018\n",
            "Training [6190/10000]: Loss: 0.011\n",
            "Training [6191/10000]: Loss: 0.014\n",
            "Training [6192/10000]: Loss: 0.017\n",
            "Training [6193/10000]: Loss: 0.012\n",
            "Training [6194/10000]: Loss: 0.012\n",
            "Training [6195/10000]: Loss: 0.009\n",
            "Training [6196/10000]: Loss: 0.006\n",
            "Training [6197/10000]: Loss: 0.010\n",
            "Training [6198/10000]: Loss: 0.009\n",
            "Training [6199/10000]: Loss: 0.017\n",
            "Training [6200/10000]: Loss: 0.017\n",
            "Test Loss: 0.055\n",
            "Training [6201/10000]: Loss: 0.009\n",
            "Training [6202/10000]: Loss: 0.016\n",
            "Training [6203/10000]: Loss: 0.014\n",
            "Training [6204/10000]: Loss: 0.013\n",
            "Training [6205/10000]: Loss: 0.014\n",
            "Training [6206/10000]: Loss: 0.012\n",
            "Training [6207/10000]: Loss: 0.010\n",
            "Training [6208/10000]: Loss: 0.014\n",
            "Training [6209/10000]: Loss: 0.012\n",
            "Training [6210/10000]: Loss: 0.013\n",
            "Training [6211/10000]: Loss: 0.009\n",
            "Training [6212/10000]: Loss: 0.012\n",
            "Training [6213/10000]: Loss: 0.014\n",
            "Training [6214/10000]: Loss: 0.008\n",
            "Training [6215/10000]: Loss: 0.020\n",
            "Training [6216/10000]: Loss: 0.014\n",
            "Training [6217/10000]: Loss: 0.013\n",
            "Training [6218/10000]: Loss: 0.012\n",
            "Training [6219/10000]: Loss: 0.012\n",
            "Training [6220/10000]: Loss: 0.010\n",
            "Training [6221/10000]: Loss: 0.013\n",
            "Training [6222/10000]: Loss: 0.017\n",
            "Training [6223/10000]: Loss: 0.014\n",
            "Training [6224/10000]: Loss: 0.014\n",
            "Training [6225/10000]: Loss: 0.016\n",
            "Training [6226/10000]: Loss: 0.013\n",
            "Training [6227/10000]: Loss: 0.012\n",
            "Training [6228/10000]: Loss: 0.016\n",
            "Training [6229/10000]: Loss: 0.012\n",
            "Training [6230/10000]: Loss: 0.016\n",
            "Training [6231/10000]: Loss: 0.017\n",
            "Training [6232/10000]: Loss: 0.011\n",
            "Training [6233/10000]: Loss: 0.014\n",
            "Training [6234/10000]: Loss: 0.011\n",
            "Training [6235/10000]: Loss: 0.007\n",
            "Training [6236/10000]: Loss: 0.016\n",
            "Training [6237/10000]: Loss: 0.011\n",
            "Training [6238/10000]: Loss: 0.009\n",
            "Training [6239/10000]: Loss: 0.015\n",
            "Training [6240/10000]: Loss: 0.014\n",
            "Training [6241/10000]: Loss: 0.014\n",
            "Training [6242/10000]: Loss: 0.014\n",
            "Training [6243/10000]: Loss: 0.011\n",
            "Training [6244/10000]: Loss: 0.012\n",
            "Training [6245/10000]: Loss: 0.012\n",
            "Training [6246/10000]: Loss: 0.011\n",
            "Training [6247/10000]: Loss: 0.012\n",
            "Training [6248/10000]: Loss: 0.012\n",
            "Training [6249/10000]: Loss: 0.011\n",
            "Training [6250/10000]: Loss: 0.014\n",
            "Training [6251/10000]: Loss: 0.013\n",
            "Training [6252/10000]: Loss: 0.009\n",
            "Training [6253/10000]: Loss: 0.008\n",
            "Training [6254/10000]: Loss: 0.010\n",
            "Training [6255/10000]: Loss: 0.009\n",
            "Training [6256/10000]: Loss: 0.012\n",
            "Training [6257/10000]: Loss: 0.010\n",
            "Training [6258/10000]: Loss: 0.008\n",
            "Training [6259/10000]: Loss: 0.008\n",
            "Training [6260/10000]: Loss: 0.013\n",
            "Training [6261/10000]: Loss: 0.011\n",
            "Training [6262/10000]: Loss: 0.013\n",
            "Training [6263/10000]: Loss: 0.012\n",
            "Training [6264/10000]: Loss: 0.012\n",
            "Training [6265/10000]: Loss: 0.016\n",
            "Training [6266/10000]: Loss: 0.013\n",
            "Training [6267/10000]: Loss: 0.009\n",
            "Training [6268/10000]: Loss: 0.011\n",
            "Training [6269/10000]: Loss: 0.014\n",
            "Training [6270/10000]: Loss: 0.013\n",
            "Training [6271/10000]: Loss: 0.009\n",
            "Training [6272/10000]: Loss: 0.017\n",
            "Training [6273/10000]: Loss: 0.019\n",
            "Training [6274/10000]: Loss: 0.012\n",
            "Training [6275/10000]: Loss: 0.017\n",
            "Training [6276/10000]: Loss: 0.010\n",
            "Training [6277/10000]: Loss: 0.014\n",
            "Training [6278/10000]: Loss: 0.014\n",
            "Training [6279/10000]: Loss: 0.016\n",
            "Training [6280/10000]: Loss: 0.013\n",
            "Training [6281/10000]: Loss: 0.008\n",
            "Training [6282/10000]: Loss: 0.018\n",
            "Training [6283/10000]: Loss: 0.009\n",
            "Training [6284/10000]: Loss: 0.012\n",
            "Training [6285/10000]: Loss: 0.008\n",
            "Training [6286/10000]: Loss: 0.010\n",
            "Training [6287/10000]: Loss: 0.013\n",
            "Training [6288/10000]: Loss: 0.016\n",
            "Training [6289/10000]: Loss: 0.018\n",
            "Training [6290/10000]: Loss: 0.008\n",
            "Training [6291/10000]: Loss: 0.014\n",
            "Training [6292/10000]: Loss: 0.012\n",
            "Training [6293/10000]: Loss: 0.018\n",
            "Training [6294/10000]: Loss: 0.016\n",
            "Training [6295/10000]: Loss: 0.017\n",
            "Training [6296/10000]: Loss: 0.010\n",
            "Training [6297/10000]: Loss: 0.011\n",
            "Training [6298/10000]: Loss: 0.012\n",
            "Training [6299/10000]: Loss: 0.009\n",
            "Training [6300/10000]: Loss: 0.016\n",
            "Test Loss: 0.055\n",
            "Training [6301/10000]: Loss: 0.014\n",
            "Training [6302/10000]: Loss: 0.017\n",
            "Training [6303/10000]: Loss: 0.016\n",
            "Training [6304/10000]: Loss: 0.013\n",
            "Training [6305/10000]: Loss: 0.011\n",
            "Training [6306/10000]: Loss: 0.013\n",
            "Training [6307/10000]: Loss: 0.012\n",
            "Training [6308/10000]: Loss: 0.010\n",
            "Training [6309/10000]: Loss: 0.019\n",
            "Training [6310/10000]: Loss: 0.010\n",
            "Training [6311/10000]: Loss: 0.019\n",
            "Training [6312/10000]: Loss: 0.015\n",
            "Training [6313/10000]: Loss: 0.010\n",
            "Training [6314/10000]: Loss: 0.013\n",
            "Training [6315/10000]: Loss: 0.012\n",
            "Training [6316/10000]: Loss: 0.012\n",
            "Training [6317/10000]: Loss: 0.019\n",
            "Training [6318/10000]: Loss: 0.015\n",
            "Training [6319/10000]: Loss: 0.014\n",
            "Training [6320/10000]: Loss: 0.007\n",
            "Training [6321/10000]: Loss: 0.011\n",
            "Training [6322/10000]: Loss: 0.008\n",
            "Training [6323/10000]: Loss: 0.012\n",
            "Training [6324/10000]: Loss: 0.010\n",
            "Training [6325/10000]: Loss: 0.012\n",
            "Training [6326/10000]: Loss: 0.017\n",
            "Training [6327/10000]: Loss: 0.013\n",
            "Training [6328/10000]: Loss: 0.021\n",
            "Training [6329/10000]: Loss: 0.011\n",
            "Training [6330/10000]: Loss: 0.014\n",
            "Training [6331/10000]: Loss: 0.008\n",
            "Training [6332/10000]: Loss: 0.009\n",
            "Training [6333/10000]: Loss: 0.015\n",
            "Training [6334/10000]: Loss: 0.014\n",
            "Training [6335/10000]: Loss: 0.019\n",
            "Training [6336/10000]: Loss: 0.011\n",
            "Training [6337/10000]: Loss: 0.012\n",
            "Training [6338/10000]: Loss: 0.011\n",
            "Training [6339/10000]: Loss: 0.013\n",
            "Training [6340/10000]: Loss: 0.017\n",
            "Training [6341/10000]: Loss: 0.012\n",
            "Training [6342/10000]: Loss: 0.016\n",
            "Training [6343/10000]: Loss: 0.014\n",
            "Training [6344/10000]: Loss: 0.011\n",
            "Training [6345/10000]: Loss: 0.009\n",
            "Training [6346/10000]: Loss: 0.009\n",
            "Training [6347/10000]: Loss: 0.018\n",
            "Training [6348/10000]: Loss: 0.011\n",
            "Training [6349/10000]: Loss: 0.010\n",
            "Training [6350/10000]: Loss: 0.013\n",
            "Training [6351/10000]: Loss: 0.008\n",
            "Training [6352/10000]: Loss: 0.012\n",
            "Training [6353/10000]: Loss: 0.009\n",
            "Training [6354/10000]: Loss: 0.012\n",
            "Training [6355/10000]: Loss: 0.014\n",
            "Training [6356/10000]: Loss: 0.015\n",
            "Training [6357/10000]: Loss: 0.019\n",
            "Training [6358/10000]: Loss: 0.012\n",
            "Training [6359/10000]: Loss: 0.009\n",
            "Training [6360/10000]: Loss: 0.013\n",
            "Training [6361/10000]: Loss: 0.012\n",
            "Training [6362/10000]: Loss: 0.013\n",
            "Training [6363/10000]: Loss: 0.011\n",
            "Training [6364/10000]: Loss: 0.012\n",
            "Training [6365/10000]: Loss: 0.014\n",
            "Training [6366/10000]: Loss: 0.011\n",
            "Training [6367/10000]: Loss: 0.015\n",
            "Training [6368/10000]: Loss: 0.009\n",
            "Training [6369/10000]: Loss: 0.012\n",
            "Training [6370/10000]: Loss: 0.013\n",
            "Training [6371/10000]: Loss: 0.014\n",
            "Training [6372/10000]: Loss: 0.014\n",
            "Training [6373/10000]: Loss: 0.013\n",
            "Training [6374/10000]: Loss: 0.010\n",
            "Training [6375/10000]: Loss: 0.012\n",
            "Training [6376/10000]: Loss: 0.012\n",
            "Training [6377/10000]: Loss: 0.015\n",
            "Training [6378/10000]: Loss: 0.009\n",
            "Training [6379/10000]: Loss: 0.009\n",
            "Training [6380/10000]: Loss: 0.013\n",
            "Training [6381/10000]: Loss: 0.016\n",
            "Training [6382/10000]: Loss: 0.011\n",
            "Training [6383/10000]: Loss: 0.024\n",
            "Training [6384/10000]: Loss: 0.013\n",
            "Training [6385/10000]: Loss: 0.020\n",
            "Training [6386/10000]: Loss: 0.019\n",
            "Training [6387/10000]: Loss: 0.015\n",
            "Training [6388/10000]: Loss: 0.014\n",
            "Training [6389/10000]: Loss: 0.010\n",
            "Training [6390/10000]: Loss: 0.019\n",
            "Training [6391/10000]: Loss: 0.008\n",
            "Training [6392/10000]: Loss: 0.011\n",
            "Training [6393/10000]: Loss: 0.010\n",
            "Training [6394/10000]: Loss: 0.011\n",
            "Training [6395/10000]: Loss: 0.015\n",
            "Training [6396/10000]: Loss: 0.011\n",
            "Training [6397/10000]: Loss: 0.010\n",
            "Training [6398/10000]: Loss: 0.017\n",
            "Training [6399/10000]: Loss: 0.010\n",
            "Training [6400/10000]: Loss: 0.013\n",
            "Test Loss: 0.056\n",
            "Training [6401/10000]: Loss: 0.013\n",
            "Training [6402/10000]: Loss: 0.013\n",
            "Training [6403/10000]: Loss: 0.009\n",
            "Training [6404/10000]: Loss: 0.012\n",
            "Training [6405/10000]: Loss: 0.013\n",
            "Training [6406/10000]: Loss: 0.012\n",
            "Training [6407/10000]: Loss: 0.011\n",
            "Training [6408/10000]: Loss: 0.017\n",
            "Training [6409/10000]: Loss: 0.012\n",
            "Training [6410/10000]: Loss: 0.010\n",
            "Training [6411/10000]: Loss: 0.009\n",
            "Training [6412/10000]: Loss: 0.017\n",
            "Training [6413/10000]: Loss: 0.012\n",
            "Training [6414/10000]: Loss: 0.010\n",
            "Training [6415/10000]: Loss: 0.016\n",
            "Training [6416/10000]: Loss: 0.009\n",
            "Training [6417/10000]: Loss: 0.008\n",
            "Training [6418/10000]: Loss: 0.014\n",
            "Training [6419/10000]: Loss: 0.014\n",
            "Training [6420/10000]: Loss: 0.018\n",
            "Training [6421/10000]: Loss: 0.018\n",
            "Training [6422/10000]: Loss: 0.016\n",
            "Training [6423/10000]: Loss: 0.010\n",
            "Training [6424/10000]: Loss: 0.020\n",
            "Training [6425/10000]: Loss: 0.019\n",
            "Training [6426/10000]: Loss: 0.013\n",
            "Training [6427/10000]: Loss: 0.004\n",
            "Training [6428/10000]: Loss: 0.012\n",
            "Training [6429/10000]: Loss: 0.013\n",
            "Training [6430/10000]: Loss: 0.011\n",
            "Training [6431/10000]: Loss: 0.012\n",
            "Training [6432/10000]: Loss: 0.013\n",
            "Training [6433/10000]: Loss: 0.011\n",
            "Training [6434/10000]: Loss: 0.014\n",
            "Training [6435/10000]: Loss: 0.013\n",
            "Training [6436/10000]: Loss: 0.015\n",
            "Training [6437/10000]: Loss: 0.015\n",
            "Training [6438/10000]: Loss: 0.012\n",
            "Training [6439/10000]: Loss: 0.014\n",
            "Training [6440/10000]: Loss: 0.011\n",
            "Training [6441/10000]: Loss: 0.018\n",
            "Training [6442/10000]: Loss: 0.016\n",
            "Training [6443/10000]: Loss: 0.011\n",
            "Training [6444/10000]: Loss: 0.017\n",
            "Training [6445/10000]: Loss: 0.012\n",
            "Training [6446/10000]: Loss: 0.011\n",
            "Training [6447/10000]: Loss: 0.015\n",
            "Training [6448/10000]: Loss: 0.012\n",
            "Training [6449/10000]: Loss: 0.017\n",
            "Training [6450/10000]: Loss: 0.012\n",
            "Training [6451/10000]: Loss: 0.011\n",
            "Training [6452/10000]: Loss: 0.012\n",
            "Training [6453/10000]: Loss: 0.014\n",
            "Training [6454/10000]: Loss: 0.012\n",
            "Training [6455/10000]: Loss: 0.013\n",
            "Training [6456/10000]: Loss: 0.007\n",
            "Training [6457/10000]: Loss: 0.012\n",
            "Training [6458/10000]: Loss: 0.013\n",
            "Training [6459/10000]: Loss: 0.010\n",
            "Training [6460/10000]: Loss: 0.013\n",
            "Training [6461/10000]: Loss: 0.009\n",
            "Training [6462/10000]: Loss: 0.014\n",
            "Training [6463/10000]: Loss: 0.011\n",
            "Training [6464/10000]: Loss: 0.012\n",
            "Training [6465/10000]: Loss: 0.010\n",
            "Training [6466/10000]: Loss: 0.022\n",
            "Training [6467/10000]: Loss: 0.008\n",
            "Training [6468/10000]: Loss: 0.017\n",
            "Training [6469/10000]: Loss: 0.006\n",
            "Training [6470/10000]: Loss: 0.015\n",
            "Training [6471/10000]: Loss: 0.012\n",
            "Training [6472/10000]: Loss: 0.012\n",
            "Training [6473/10000]: Loss: 0.010\n",
            "Training [6474/10000]: Loss: 0.015\n",
            "Training [6475/10000]: Loss: 0.023\n",
            "Training [6476/10000]: Loss: 0.013\n",
            "Training [6477/10000]: Loss: 0.015\n",
            "Training [6478/10000]: Loss: 0.010\n",
            "Training [6479/10000]: Loss: 0.011\n",
            "Training [6480/10000]: Loss: 0.013\n",
            "Training [6481/10000]: Loss: 0.008\n",
            "Training [6482/10000]: Loss: 0.016\n",
            "Training [6483/10000]: Loss: 0.009\n",
            "Training [6484/10000]: Loss: 0.012\n",
            "Training [6485/10000]: Loss: 0.015\n",
            "Training [6486/10000]: Loss: 0.009\n",
            "Training [6487/10000]: Loss: 0.015\n",
            "Training [6488/10000]: Loss: 0.007\n",
            "Training [6489/10000]: Loss: 0.014\n",
            "Training [6490/10000]: Loss: 0.010\n",
            "Training [6491/10000]: Loss: 0.014\n",
            "Training [6492/10000]: Loss: 0.009\n",
            "Training [6493/10000]: Loss: 0.012\n",
            "Training [6494/10000]: Loss: 0.014\n",
            "Training [6495/10000]: Loss: 0.011\n",
            "Training [6496/10000]: Loss: 0.009\n",
            "Training [6497/10000]: Loss: 0.012\n",
            "Training [6498/10000]: Loss: 0.016\n",
            "Training [6499/10000]: Loss: 0.012\n",
            "Training [6500/10000]: Loss: 0.013\n",
            "Test Loss: 0.054\n",
            "Training [6501/10000]: Loss: 0.015\n",
            "Training [6502/10000]: Loss: 0.016\n",
            "Training [6503/10000]: Loss: 0.016\n",
            "Training [6504/10000]: Loss: 0.011\n",
            "Training [6505/10000]: Loss: 0.010\n",
            "Training [6506/10000]: Loss: 0.014\n",
            "Training [6507/10000]: Loss: 0.012\n",
            "Training [6508/10000]: Loss: 0.015\n",
            "Training [6509/10000]: Loss: 0.011\n",
            "Training [6510/10000]: Loss: 0.009\n",
            "Training [6511/10000]: Loss: 0.012\n",
            "Training [6512/10000]: Loss: 0.016\n",
            "Training [6513/10000]: Loss: 0.013\n",
            "Training [6514/10000]: Loss: 0.016\n",
            "Training [6515/10000]: Loss: 0.008\n",
            "Training [6516/10000]: Loss: 0.019\n",
            "Training [6517/10000]: Loss: 0.014\n",
            "Training [6518/10000]: Loss: 0.013\n",
            "Training [6519/10000]: Loss: 0.009\n",
            "Training [6520/10000]: Loss: 0.014\n",
            "Training [6521/10000]: Loss: 0.016\n",
            "Training [6522/10000]: Loss: 0.014\n",
            "Training [6523/10000]: Loss: 0.016\n",
            "Training [6524/10000]: Loss: 0.012\n",
            "Training [6525/10000]: Loss: 0.015\n",
            "Training [6526/10000]: Loss: 0.016\n",
            "Training [6527/10000]: Loss: 0.008\n",
            "Training [6528/10000]: Loss: 0.013\n",
            "Training [6529/10000]: Loss: 0.016\n",
            "Training [6530/10000]: Loss: 0.015\n",
            "Training [6531/10000]: Loss: 0.013\n",
            "Training [6532/10000]: Loss: 0.018\n",
            "Training [6533/10000]: Loss: 0.009\n",
            "Training [6534/10000]: Loss: 0.012\n",
            "Training [6535/10000]: Loss: 0.016\n",
            "Training [6536/10000]: Loss: 0.018\n",
            "Training [6537/10000]: Loss: 0.015\n",
            "Training [6538/10000]: Loss: 0.015\n",
            "Training [6539/10000]: Loss: 0.012\n",
            "Training [6540/10000]: Loss: 0.011\n",
            "Training [6541/10000]: Loss: 0.014\n",
            "Training [6542/10000]: Loss: 0.015\n",
            "Training [6543/10000]: Loss: 0.011\n",
            "Training [6544/10000]: Loss: 0.011\n",
            "Training [6545/10000]: Loss: 0.014\n",
            "Training [6546/10000]: Loss: 0.009\n",
            "Training [6547/10000]: Loss: 0.010\n",
            "Training [6548/10000]: Loss: 0.010\n",
            "Training [6549/10000]: Loss: 0.011\n",
            "Training [6550/10000]: Loss: 0.012\n",
            "Training [6551/10000]: Loss: 0.012\n",
            "Training [6552/10000]: Loss: 0.011\n",
            "Training [6553/10000]: Loss: 0.007\n",
            "Training [6554/10000]: Loss: 0.014\n",
            "Training [6555/10000]: Loss: 0.014\n",
            "Training [6556/10000]: Loss: 0.011\n",
            "Training [6557/10000]: Loss: 0.007\n",
            "Training [6558/10000]: Loss: 0.012\n",
            "Training [6559/10000]: Loss: 0.014\n",
            "Training [6560/10000]: Loss: 0.008\n",
            "Training [6561/10000]: Loss: 0.015\n",
            "Training [6562/10000]: Loss: 0.017\n",
            "Training [6563/10000]: Loss: 0.014\n",
            "Training [6564/10000]: Loss: 0.017\n",
            "Training [6565/10000]: Loss: 0.017\n",
            "Training [6566/10000]: Loss: 0.014\n",
            "Training [6567/10000]: Loss: 0.008\n",
            "Training [6568/10000]: Loss: 0.010\n",
            "Training [6569/10000]: Loss: 0.013\n",
            "Training [6570/10000]: Loss: 0.015\n",
            "Training [6571/10000]: Loss: 0.012\n",
            "Training [6572/10000]: Loss: 0.009\n",
            "Training [6573/10000]: Loss: 0.019\n",
            "Training [6574/10000]: Loss: 0.014\n",
            "Training [6575/10000]: Loss: 0.011\n",
            "Training [6576/10000]: Loss: 0.014\n",
            "Training [6577/10000]: Loss: 0.010\n",
            "Training [6578/10000]: Loss: 0.014\n",
            "Training [6579/10000]: Loss: 0.015\n",
            "Training [6580/10000]: Loss: 0.011\n",
            "Training [6581/10000]: Loss: 0.012\n",
            "Training [6582/10000]: Loss: 0.011\n",
            "Training [6583/10000]: Loss: 0.009\n",
            "Training [6584/10000]: Loss: 0.015\n",
            "Training [6585/10000]: Loss: 0.009\n",
            "Training [6586/10000]: Loss: 0.009\n",
            "Training [6587/10000]: Loss: 0.011\n",
            "Training [6588/10000]: Loss: 0.009\n",
            "Training [6589/10000]: Loss: 0.015\n",
            "Training [6590/10000]: Loss: 0.011\n",
            "Training [6591/10000]: Loss: 0.018\n",
            "Training [6592/10000]: Loss: 0.017\n",
            "Training [6593/10000]: Loss: 0.014\n",
            "Training [6594/10000]: Loss: 0.018\n",
            "Training [6595/10000]: Loss: 0.012\n",
            "Training [6596/10000]: Loss: 0.013\n",
            "Training [6597/10000]: Loss: 0.011\n",
            "Training [6598/10000]: Loss: 0.015\n",
            "Training [6599/10000]: Loss: 0.010\n",
            "Training [6600/10000]: Loss: 0.013\n",
            "Test Loss: 0.060\n",
            "Training [6601/10000]: Loss: 0.014\n",
            "Training [6602/10000]: Loss: 0.013\n",
            "Training [6603/10000]: Loss: 0.013\n",
            "Training [6604/10000]: Loss: 0.012\n",
            "Training [6605/10000]: Loss: 0.015\n",
            "Training [6606/10000]: Loss: 0.013\n",
            "Training [6607/10000]: Loss: 0.012\n",
            "Training [6608/10000]: Loss: 0.017\n",
            "Training [6609/10000]: Loss: 0.012\n",
            "Training [6610/10000]: Loss: 0.013\n",
            "Training [6611/10000]: Loss: 0.007\n",
            "Training [6612/10000]: Loss: 0.019\n",
            "Training [6613/10000]: Loss: 0.009\n",
            "Training [6614/10000]: Loss: 0.008\n",
            "Training [6615/10000]: Loss: 0.012\n",
            "Training [6616/10000]: Loss: 0.009\n",
            "Training [6617/10000]: Loss: 0.012\n",
            "Training [6618/10000]: Loss: 0.015\n",
            "Training [6619/10000]: Loss: 0.016\n",
            "Training [6620/10000]: Loss: 0.013\n",
            "Training [6621/10000]: Loss: 0.011\n",
            "Training [6622/10000]: Loss: 0.016\n",
            "Training [6623/10000]: Loss: 0.017\n",
            "Training [6624/10000]: Loss: 0.009\n",
            "Training [6625/10000]: Loss: 0.008\n",
            "Training [6626/10000]: Loss: 0.019\n",
            "Training [6627/10000]: Loss: 0.014\n",
            "Training [6628/10000]: Loss: 0.013\n",
            "Training [6629/10000]: Loss: 0.008\n",
            "Training [6630/10000]: Loss: 0.013\n",
            "Training [6631/10000]: Loss: 0.012\n",
            "Training [6632/10000]: Loss: 0.013\n",
            "Training [6633/10000]: Loss: 0.018\n",
            "Training [6634/10000]: Loss: 0.008\n",
            "Training [6635/10000]: Loss: 0.015\n",
            "Training [6636/10000]: Loss: 0.011\n",
            "Training [6637/10000]: Loss: 0.013\n",
            "Training [6638/10000]: Loss: 0.013\n",
            "Training [6639/10000]: Loss: 0.015\n",
            "Training [6640/10000]: Loss: 0.012\n",
            "Training [6641/10000]: Loss: 0.012\n",
            "Training [6642/10000]: Loss: 0.010\n",
            "Training [6643/10000]: Loss: 0.008\n",
            "Training [6644/10000]: Loss: 0.011\n",
            "Training [6645/10000]: Loss: 0.010\n",
            "Training [6646/10000]: Loss: 0.016\n",
            "Training [6647/10000]: Loss: 0.014\n",
            "Training [6648/10000]: Loss: 0.015\n",
            "Training [6649/10000]: Loss: 0.015\n",
            "Training [6650/10000]: Loss: 0.013\n",
            "Training [6651/10000]: Loss: 0.009\n",
            "Training [6652/10000]: Loss: 0.012\n",
            "Training [6653/10000]: Loss: 0.012\n",
            "Training [6654/10000]: Loss: 0.014\n",
            "Training [6655/10000]: Loss: 0.016\n",
            "Training [6656/10000]: Loss: 0.010\n",
            "Training [6657/10000]: Loss: 0.014\n",
            "Training [6658/10000]: Loss: 0.016\n",
            "Training [6659/10000]: Loss: 0.010\n",
            "Training [6660/10000]: Loss: 0.011\n",
            "Training [6661/10000]: Loss: 0.014\n",
            "Training [6662/10000]: Loss: 0.017\n",
            "Training [6663/10000]: Loss: 0.015\n",
            "Training [6664/10000]: Loss: 0.016\n",
            "Training [6665/10000]: Loss: 0.015\n",
            "Training [6666/10000]: Loss: 0.010\n",
            "Training [6667/10000]: Loss: 0.013\n",
            "Training [6668/10000]: Loss: 0.014\n",
            "Training [6669/10000]: Loss: 0.013\n",
            "Training [6670/10000]: Loss: 0.015\n",
            "Training [6671/10000]: Loss: 0.014\n",
            "Training [6672/10000]: Loss: 0.015\n",
            "Training [6673/10000]: Loss: 0.013\n",
            "Training [6674/10000]: Loss: 0.014\n",
            "Training [6675/10000]: Loss: 0.006\n",
            "Training [6676/10000]: Loss: 0.016\n",
            "Training [6677/10000]: Loss: 0.013\n",
            "Training [6678/10000]: Loss: 0.012\n",
            "Training [6679/10000]: Loss: 0.014\n",
            "Training [6680/10000]: Loss: 0.020\n",
            "Training [6681/10000]: Loss: 0.010\n",
            "Training [6682/10000]: Loss: 0.015\n",
            "Training [6683/10000]: Loss: 0.012\n",
            "Training [6684/10000]: Loss: 0.013\n",
            "Training [6685/10000]: Loss: 0.010\n",
            "Training [6686/10000]: Loss: 0.013\n",
            "Training [6687/10000]: Loss: 0.015\n",
            "Training [6688/10000]: Loss: 0.010\n",
            "Training [6689/10000]: Loss: 0.008\n",
            "Training [6690/10000]: Loss: 0.016\n",
            "Training [6691/10000]: Loss: 0.011\n",
            "Training [6692/10000]: Loss: 0.017\n",
            "Training [6693/10000]: Loss: 0.013\n",
            "Training [6694/10000]: Loss: 0.009\n",
            "Training [6695/10000]: Loss: 0.011\n",
            "Training [6696/10000]: Loss: 0.011\n",
            "Training [6697/10000]: Loss: 0.009\n",
            "Training [6698/10000]: Loss: 0.016\n",
            "Training [6699/10000]: Loss: 0.009\n",
            "Training [6700/10000]: Loss: 0.015\n",
            "Test Loss: 0.060\n",
            "Training [6701/10000]: Loss: 0.010\n",
            "Training [6702/10000]: Loss: 0.012\n",
            "Training [6703/10000]: Loss: 0.011\n",
            "Training [6704/10000]: Loss: 0.011\n",
            "Training [6705/10000]: Loss: 0.019\n",
            "Training [6706/10000]: Loss: 0.014\n",
            "Training [6707/10000]: Loss: 0.015\n",
            "Training [6708/10000]: Loss: 0.011\n",
            "Training [6709/10000]: Loss: 0.011\n",
            "Training [6710/10000]: Loss: 0.012\n",
            "Training [6711/10000]: Loss: 0.017\n",
            "Training [6712/10000]: Loss: 0.015\n",
            "Training [6713/10000]: Loss: 0.008\n",
            "Training [6714/10000]: Loss: 0.011\n",
            "Training [6715/10000]: Loss: 0.013\n",
            "Training [6716/10000]: Loss: 0.009\n",
            "Training [6717/10000]: Loss: 0.017\n",
            "Training [6718/10000]: Loss: 0.008\n",
            "Training [6719/10000]: Loss: 0.013\n",
            "Training [6720/10000]: Loss: 0.013\n",
            "Training [6721/10000]: Loss: 0.011\n",
            "Training [6722/10000]: Loss: 0.016\n",
            "Training [6723/10000]: Loss: 0.010\n",
            "Training [6724/10000]: Loss: 0.012\n",
            "Training [6725/10000]: Loss: 0.011\n",
            "Training [6726/10000]: Loss: 0.014\n",
            "Training [6727/10000]: Loss: 0.012\n",
            "Training [6728/10000]: Loss: 0.015\n",
            "Training [6729/10000]: Loss: 0.015\n",
            "Training [6730/10000]: Loss: 0.016\n",
            "Training [6731/10000]: Loss: 0.012\n",
            "Training [6732/10000]: Loss: 0.013\n",
            "Training [6733/10000]: Loss: 0.013\n",
            "Training [6734/10000]: Loss: 0.014\n",
            "Training [6735/10000]: Loss: 0.012\n",
            "Training [6736/10000]: Loss: 0.014\n",
            "Training [6737/10000]: Loss: 0.012\n",
            "Training [6738/10000]: Loss: 0.014\n",
            "Training [6739/10000]: Loss: 0.013\n",
            "Training [6740/10000]: Loss: 0.010\n",
            "Training [6741/10000]: Loss: 0.012\n",
            "Training [6742/10000]: Loss: 0.012\n",
            "Training [6743/10000]: Loss: 0.015\n",
            "Training [6744/10000]: Loss: 0.012\n",
            "Training [6745/10000]: Loss: 0.007\n",
            "Training [6746/10000]: Loss: 0.008\n",
            "Training [6747/10000]: Loss: 0.013\n",
            "Training [6748/10000]: Loss: 0.013\n",
            "Training [6749/10000]: Loss: 0.008\n",
            "Training [6750/10000]: Loss: 0.016\n",
            "Training [6751/10000]: Loss: 0.007\n",
            "Training [6752/10000]: Loss: 0.010\n",
            "Training [6753/10000]: Loss: 0.021\n",
            "Training [6754/10000]: Loss: 0.012\n",
            "Training [6755/10000]: Loss: 0.015\n",
            "Training [6756/10000]: Loss: 0.013\n",
            "Training [6757/10000]: Loss: 0.016\n",
            "Training [6758/10000]: Loss: 0.013\n",
            "Training [6759/10000]: Loss: 0.009\n",
            "Training [6760/10000]: Loss: 0.015\n",
            "Training [6761/10000]: Loss: 0.011\n",
            "Training [6762/10000]: Loss: 0.011\n",
            "Training [6763/10000]: Loss: 0.011\n",
            "Training [6764/10000]: Loss: 0.011\n",
            "Training [6765/10000]: Loss: 0.013\n",
            "Training [6766/10000]: Loss: 0.015\n",
            "Training [6767/10000]: Loss: 0.010\n",
            "Training [6768/10000]: Loss: 0.008\n",
            "Training [6769/10000]: Loss: 0.011\n",
            "Training [6770/10000]: Loss: 0.019\n",
            "Training [6771/10000]: Loss: 0.012\n",
            "Training [6772/10000]: Loss: 0.010\n",
            "Training [6773/10000]: Loss: 0.013\n",
            "Training [6774/10000]: Loss: 0.012\n",
            "Training [6775/10000]: Loss: 0.008\n",
            "Training [6776/10000]: Loss: 0.010\n",
            "Training [6777/10000]: Loss: 0.009\n",
            "Training [6778/10000]: Loss: 0.013\n",
            "Training [6779/10000]: Loss: 0.010\n",
            "Training [6780/10000]: Loss: 0.009\n",
            "Training [6781/10000]: Loss: 0.013\n",
            "Training [6782/10000]: Loss: 0.011\n",
            "Training [6783/10000]: Loss: 0.015\n",
            "Training [6784/10000]: Loss: 0.010\n",
            "Training [6785/10000]: Loss: 0.006\n",
            "Training [6786/10000]: Loss: 0.007\n",
            "Training [6787/10000]: Loss: 0.011\n",
            "Training [6788/10000]: Loss: 0.008\n",
            "Training [6789/10000]: Loss: 0.015\n",
            "Training [6790/10000]: Loss: 0.008\n",
            "Training [6791/10000]: Loss: 0.010\n",
            "Training [6792/10000]: Loss: 0.012\n",
            "Training [6793/10000]: Loss: 0.013\n",
            "Training [6794/10000]: Loss: 0.010\n",
            "Training [6795/10000]: Loss: 0.013\n",
            "Training [6796/10000]: Loss: 0.013\n",
            "Training [6797/10000]: Loss: 0.012\n",
            "Training [6798/10000]: Loss: 0.007\n",
            "Training [6799/10000]: Loss: 0.012\n",
            "Training [6800/10000]: Loss: 0.012\n",
            "Test Loss: 0.056\n",
            "Training [6801/10000]: Loss: 0.009\n",
            "Training [6802/10000]: Loss: 0.010\n",
            "Training [6803/10000]: Loss: 0.009\n",
            "Training [6804/10000]: Loss: 0.008\n",
            "Training [6805/10000]: Loss: 0.008\n",
            "Training [6806/10000]: Loss: 0.008\n",
            "Training [6807/10000]: Loss: 0.013\n",
            "Training [6808/10000]: Loss: 0.015\n",
            "Training [6809/10000]: Loss: 0.010\n",
            "Training [6810/10000]: Loss: 0.013\n",
            "Training [6811/10000]: Loss: 0.011\n",
            "Training [6812/10000]: Loss: 0.010\n",
            "Training [6813/10000]: Loss: 0.014\n",
            "Training [6814/10000]: Loss: 0.013\n",
            "Training [6815/10000]: Loss: 0.010\n",
            "Training [6816/10000]: Loss: 0.010\n",
            "Training [6817/10000]: Loss: 0.015\n",
            "Training [6818/10000]: Loss: 0.009\n",
            "Training [6819/10000]: Loss: 0.010\n",
            "Training [6820/10000]: Loss: 0.012\n",
            "Training [6821/10000]: Loss: 0.012\n",
            "Training [6822/10000]: Loss: 0.010\n",
            "Training [6823/10000]: Loss: 0.006\n",
            "Training [6824/10000]: Loss: 0.009\n",
            "Training [6825/10000]: Loss: 0.019\n",
            "Training [6826/10000]: Loss: 0.010\n",
            "Training [6827/10000]: Loss: 0.010\n",
            "Training [6828/10000]: Loss: 0.007\n",
            "Training [6829/10000]: Loss: 0.013\n",
            "Training [6830/10000]: Loss: 0.007\n",
            "Training [6831/10000]: Loss: 0.013\n",
            "Training [6832/10000]: Loss: 0.013\n",
            "Training [6833/10000]: Loss: 0.016\n",
            "Training [6834/10000]: Loss: 0.015\n",
            "Training [6835/10000]: Loss: 0.010\n",
            "Training [6836/10000]: Loss: 0.012\n",
            "Training [6837/10000]: Loss: 0.009\n",
            "Training [6838/10000]: Loss: 0.013\n",
            "Training [6839/10000]: Loss: 0.010\n",
            "Training [6840/10000]: Loss: 0.010\n",
            "Training [6841/10000]: Loss: 0.011\n",
            "Training [6842/10000]: Loss: 0.016\n",
            "Training [6843/10000]: Loss: 0.011\n",
            "Training [6844/10000]: Loss: 0.011\n",
            "Training [6845/10000]: Loss: 0.018\n",
            "Training [6846/10000]: Loss: 0.012\n",
            "Training [6847/10000]: Loss: 0.007\n",
            "Training [6848/10000]: Loss: 0.013\n",
            "Training [6849/10000]: Loss: 0.013\n",
            "Training [6850/10000]: Loss: 0.015\n",
            "Training [6851/10000]: Loss: 0.015\n",
            "Training [6852/10000]: Loss: 0.013\n",
            "Training [6853/10000]: Loss: 0.013\n",
            "Training [6854/10000]: Loss: 0.013\n",
            "Training [6855/10000]: Loss: 0.020\n",
            "Training [6856/10000]: Loss: 0.010\n",
            "Training [6857/10000]: Loss: 0.009\n",
            "Training [6858/10000]: Loss: 0.012\n",
            "Training [6859/10000]: Loss: 0.012\n",
            "Training [6860/10000]: Loss: 0.008\n",
            "Training [6861/10000]: Loss: 0.013\n",
            "Training [6862/10000]: Loss: 0.012\n",
            "Training [6863/10000]: Loss: 0.010\n",
            "Training [6864/10000]: Loss: 0.013\n",
            "Training [6865/10000]: Loss: 0.013\n",
            "Training [6866/10000]: Loss: 0.007\n",
            "Training [6867/10000]: Loss: 0.008\n",
            "Training [6868/10000]: Loss: 0.009\n",
            "Training [6869/10000]: Loss: 0.014\n",
            "Training [6870/10000]: Loss: 0.013\n",
            "Training [6871/10000]: Loss: 0.020\n",
            "Training [6872/10000]: Loss: 0.009\n",
            "Training [6873/10000]: Loss: 0.014\n",
            "Training [6874/10000]: Loss: 0.009\n",
            "Training [6875/10000]: Loss: 0.009\n",
            "Training [6876/10000]: Loss: 0.011\n",
            "Training [6877/10000]: Loss: 0.014\n",
            "Training [6878/10000]: Loss: 0.013\n",
            "Training [6879/10000]: Loss: 0.012\n",
            "Training [6880/10000]: Loss: 0.013\n",
            "Training [6881/10000]: Loss: 0.014\n",
            "Training [6882/10000]: Loss: 0.011\n",
            "Training [6883/10000]: Loss: 0.013\n",
            "Training [6884/10000]: Loss: 0.008\n",
            "Training [6885/10000]: Loss: 0.012\n",
            "Training [6886/10000]: Loss: 0.014\n",
            "Training [6887/10000]: Loss: 0.019\n",
            "Training [6888/10000]: Loss: 0.015\n",
            "Training [6889/10000]: Loss: 0.016\n",
            "Training [6890/10000]: Loss: 0.016\n",
            "Training [6891/10000]: Loss: 0.012\n",
            "Training [6892/10000]: Loss: 0.014\n",
            "Training [6893/10000]: Loss: 0.010\n",
            "Training [6894/10000]: Loss: 0.013\n",
            "Training [6895/10000]: Loss: 0.012\n",
            "Training [6896/10000]: Loss: 0.011\n",
            "Training [6897/10000]: Loss: 0.012\n",
            "Training [6898/10000]: Loss: 0.011\n",
            "Training [6899/10000]: Loss: 0.008\n",
            "Training [6900/10000]: Loss: 0.006\n",
            "Test Loss: 0.055\n",
            "Training [6901/10000]: Loss: 0.016\n",
            "Training [6902/10000]: Loss: 0.016\n",
            "Training [6903/10000]: Loss: 0.006\n",
            "Training [6904/10000]: Loss: 0.007\n",
            "Training [6905/10000]: Loss: 0.011\n",
            "Training [6906/10000]: Loss: 0.008\n",
            "Training [6907/10000]: Loss: 0.009\n",
            "Training [6908/10000]: Loss: 0.009\n",
            "Training [6909/10000]: Loss: 0.012\n",
            "Training [6910/10000]: Loss: 0.013\n",
            "Training [6911/10000]: Loss: 0.014\n",
            "Training [6912/10000]: Loss: 0.009\n",
            "Training [6913/10000]: Loss: 0.016\n",
            "Training [6914/10000]: Loss: 0.011\n",
            "Training [6915/10000]: Loss: 0.014\n",
            "Training [6916/10000]: Loss: 0.011\n",
            "Training [6917/10000]: Loss: 0.012\n",
            "Training [6918/10000]: Loss: 0.009\n",
            "Training [6919/10000]: Loss: 0.017\n",
            "Training [6920/10000]: Loss: 0.013\n",
            "Training [6921/10000]: Loss: 0.015\n",
            "Training [6922/10000]: Loss: 0.013\n",
            "Training [6923/10000]: Loss: 0.013\n",
            "Training [6924/10000]: Loss: 0.013\n",
            "Training [6925/10000]: Loss: 0.010\n",
            "Training [6926/10000]: Loss: 0.007\n",
            "Training [6927/10000]: Loss: 0.012\n",
            "Training [6928/10000]: Loss: 0.014\n",
            "Training [6929/10000]: Loss: 0.012\n",
            "Training [6930/10000]: Loss: 0.016\n",
            "Training [6931/10000]: Loss: 0.016\n",
            "Training [6932/10000]: Loss: 0.013\n",
            "Training [6933/10000]: Loss: 0.009\n",
            "Training [6934/10000]: Loss: 0.014\n",
            "Training [6935/10000]: Loss: 0.015\n",
            "Training [6936/10000]: Loss: 0.016\n",
            "Training [6937/10000]: Loss: 0.014\n",
            "Training [6938/10000]: Loss: 0.012\n",
            "Training [6939/10000]: Loss: 0.012\n",
            "Training [6940/10000]: Loss: 0.006\n",
            "Training [6941/10000]: Loss: 0.010\n",
            "Training [6942/10000]: Loss: 0.011\n",
            "Training [6943/10000]: Loss: 0.010\n",
            "Training [6944/10000]: Loss: 0.014\n",
            "Training [6945/10000]: Loss: 0.013\n",
            "Training [6946/10000]: Loss: 0.015\n",
            "Training [6947/10000]: Loss: 0.013\n",
            "Training [6948/10000]: Loss: 0.007\n",
            "Training [6949/10000]: Loss: 0.009\n",
            "Training [6950/10000]: Loss: 0.011\n",
            "Training [6951/10000]: Loss: 0.008\n",
            "Training [6952/10000]: Loss: 0.015\n",
            "Training [6953/10000]: Loss: 0.023\n",
            "Training [6954/10000]: Loss: 0.010\n",
            "Training [6955/10000]: Loss: 0.014\n",
            "Training [6956/10000]: Loss: 0.013\n",
            "Training [6957/10000]: Loss: 0.014\n",
            "Training [6958/10000]: Loss: 0.015\n",
            "Training [6959/10000]: Loss: 0.015\n",
            "Training [6960/10000]: Loss: 0.018\n",
            "Training [6961/10000]: Loss: 0.014\n",
            "Training [6962/10000]: Loss: 0.013\n",
            "Training [6963/10000]: Loss: 0.013\n",
            "Training [6964/10000]: Loss: 0.011\n",
            "Training [6965/10000]: Loss: 0.015\n",
            "Training [6966/10000]: Loss: 0.010\n",
            "Training [6967/10000]: Loss: 0.012\n",
            "Training [6968/10000]: Loss: 0.018\n",
            "Training [6969/10000]: Loss: 0.014\n",
            "Training [6970/10000]: Loss: 0.013\n",
            "Training [6971/10000]: Loss: 0.013\n",
            "Training [6972/10000]: Loss: 0.012\n",
            "Training [6973/10000]: Loss: 0.011\n",
            "Training [6974/10000]: Loss: 0.015\n",
            "Training [6975/10000]: Loss: 0.013\n",
            "Training [6976/10000]: Loss: 0.005\n",
            "Training [6977/10000]: Loss: 0.012\n",
            "Training [6978/10000]: Loss: 0.016\n",
            "Training [6979/10000]: Loss: 0.009\n",
            "Training [6980/10000]: Loss: 0.017\n",
            "Training [6981/10000]: Loss: 0.012\n",
            "Training [6982/10000]: Loss: 0.019\n",
            "Training [6983/10000]: Loss: 0.013\n",
            "Training [6984/10000]: Loss: 0.010\n",
            "Training [6985/10000]: Loss: 0.016\n",
            "Training [6986/10000]: Loss: 0.016\n",
            "Training [6987/10000]: Loss: 0.012\n",
            "Training [6988/10000]: Loss: 0.015\n",
            "Training [6989/10000]: Loss: 0.014\n",
            "Training [6990/10000]: Loss: 0.016\n",
            "Training [6991/10000]: Loss: 0.014\n",
            "Training [6992/10000]: Loss: 0.013\n",
            "Training [6993/10000]: Loss: 0.017\n",
            "Training [6994/10000]: Loss: 0.015\n",
            "Training [6995/10000]: Loss: 0.012\n",
            "Training [6996/10000]: Loss: 0.016\n",
            "Training [6997/10000]: Loss: 0.011\n",
            "Training [6998/10000]: Loss: 0.014\n",
            "Training [6999/10000]: Loss: 0.011\n",
            "Training [7000/10000]: Loss: 0.008\n",
            "Test Loss: 0.059\n",
            "Training [7001/10000]: Loss: 0.010\n",
            "Training [7002/10000]: Loss: 0.010\n",
            "Training [7003/10000]: Loss: 0.010\n",
            "Training [7004/10000]: Loss: 0.015\n",
            "Training [7005/10000]: Loss: 0.012\n",
            "Training [7006/10000]: Loss: 0.010\n",
            "Training [7007/10000]: Loss: 0.012\n",
            "Training [7008/10000]: Loss: 0.011\n",
            "Training [7009/10000]: Loss: 0.012\n",
            "Training [7010/10000]: Loss: 0.013\n",
            "Training [7011/10000]: Loss: 0.015\n",
            "Training [7012/10000]: Loss: 0.012\n",
            "Training [7013/10000]: Loss: 0.012\n",
            "Training [7014/10000]: Loss: 0.007\n",
            "Training [7015/10000]: Loss: 0.013\n",
            "Training [7016/10000]: Loss: 0.012\n",
            "Training [7017/10000]: Loss: 0.006\n",
            "Training [7018/10000]: Loss: 0.011\n",
            "Training [7019/10000]: Loss: 0.016\n",
            "Training [7020/10000]: Loss: 0.013\n",
            "Training [7021/10000]: Loss: 0.010\n",
            "Training [7022/10000]: Loss: 0.012\n",
            "Training [7023/10000]: Loss: 0.010\n",
            "Training [7024/10000]: Loss: 0.014\n",
            "Training [7025/10000]: Loss: 0.009\n",
            "Training [7026/10000]: Loss: 0.008\n",
            "Training [7027/10000]: Loss: 0.011\n",
            "Training [7028/10000]: Loss: 0.011\n",
            "Training [7029/10000]: Loss: 0.014\n",
            "Training [7030/10000]: Loss: 0.015\n",
            "Training [7031/10000]: Loss: 0.012\n",
            "Training [7032/10000]: Loss: 0.012\n",
            "Training [7033/10000]: Loss: 0.012\n",
            "Training [7034/10000]: Loss: 0.008\n",
            "Training [7035/10000]: Loss: 0.013\n",
            "Training [7036/10000]: Loss: 0.010\n",
            "Training [7037/10000]: Loss: 0.016\n",
            "Training [7038/10000]: Loss: 0.009\n",
            "Training [7039/10000]: Loss: 0.014\n",
            "Training [7040/10000]: Loss: 0.011\n",
            "Training [7041/10000]: Loss: 0.011\n",
            "Training [7042/10000]: Loss: 0.013\n",
            "Training [7043/10000]: Loss: 0.010\n",
            "Training [7044/10000]: Loss: 0.010\n",
            "Training [7045/10000]: Loss: 0.007\n",
            "Training [7046/10000]: Loss: 0.012\n",
            "Training [7047/10000]: Loss: 0.011\n",
            "Training [7048/10000]: Loss: 0.011\n",
            "Training [7049/10000]: Loss: 0.009\n",
            "Training [7050/10000]: Loss: 0.012\n",
            "Training [7051/10000]: Loss: 0.017\n",
            "Training [7052/10000]: Loss: 0.017\n",
            "Training [7053/10000]: Loss: 0.014\n",
            "Training [7054/10000]: Loss: 0.014\n",
            "Training [7055/10000]: Loss: 0.019\n",
            "Training [7056/10000]: Loss: 0.013\n",
            "Training [7057/10000]: Loss: 0.011\n",
            "Training [7058/10000]: Loss: 0.008\n",
            "Training [7059/10000]: Loss: 0.012\n",
            "Training [7060/10000]: Loss: 0.010\n",
            "Training [7061/10000]: Loss: 0.013\n",
            "Training [7062/10000]: Loss: 0.011\n",
            "Training [7063/10000]: Loss: 0.013\n",
            "Training [7064/10000]: Loss: 0.014\n",
            "Training [7065/10000]: Loss: 0.013\n",
            "Training [7066/10000]: Loss: 0.011\n",
            "Training [7067/10000]: Loss: 0.013\n",
            "Training [7068/10000]: Loss: 0.012\n",
            "Training [7069/10000]: Loss: 0.008\n",
            "Training [7070/10000]: Loss: 0.015\n",
            "Training [7071/10000]: Loss: 0.012\n",
            "Training [7072/10000]: Loss: 0.013\n",
            "Training [7073/10000]: Loss: 0.007\n",
            "Training [7074/10000]: Loss: 0.013\n",
            "Training [7075/10000]: Loss: 0.014\n",
            "Training [7076/10000]: Loss: 0.013\n",
            "Training [7077/10000]: Loss: 0.006\n",
            "Training [7078/10000]: Loss: 0.012\n",
            "Training [7079/10000]: Loss: 0.011\n",
            "Training [7080/10000]: Loss: 0.012\n",
            "Training [7081/10000]: Loss: 0.008\n",
            "Training [7082/10000]: Loss: 0.008\n",
            "Training [7083/10000]: Loss: 0.012\n",
            "Training [7084/10000]: Loss: 0.018\n",
            "Training [7085/10000]: Loss: 0.020\n",
            "Training [7086/10000]: Loss: 0.011\n",
            "Training [7087/10000]: Loss: 0.016\n",
            "Training [7088/10000]: Loss: 0.013\n",
            "Training [7089/10000]: Loss: 0.016\n",
            "Training [7090/10000]: Loss: 0.014\n",
            "Training [7091/10000]: Loss: 0.008\n",
            "Training [7092/10000]: Loss: 0.011\n",
            "Training [7093/10000]: Loss: 0.012\n",
            "Training [7094/10000]: Loss: 0.009\n",
            "Training [7095/10000]: Loss: 0.009\n",
            "Training [7096/10000]: Loss: 0.014\n",
            "Training [7097/10000]: Loss: 0.007\n",
            "Training [7098/10000]: Loss: 0.012\n",
            "Training [7099/10000]: Loss: 0.016\n",
            "Training [7100/10000]: Loss: 0.010\n",
            "Test Loss: 0.054\n",
            "Training [7101/10000]: Loss: 0.010\n",
            "Training [7102/10000]: Loss: 0.010\n",
            "Training [7103/10000]: Loss: 0.006\n",
            "Training [7104/10000]: Loss: 0.012\n",
            "Training [7105/10000]: Loss: 0.012\n",
            "Training [7106/10000]: Loss: 0.012\n",
            "Training [7107/10000]: Loss: 0.016\n",
            "Training [7108/10000]: Loss: 0.013\n",
            "Training [7109/10000]: Loss: 0.019\n",
            "Training [7110/10000]: Loss: 0.010\n",
            "Training [7111/10000]: Loss: 0.014\n",
            "Training [7112/10000]: Loss: 0.011\n",
            "Training [7113/10000]: Loss: 0.011\n",
            "Training [7114/10000]: Loss: 0.013\n",
            "Training [7115/10000]: Loss: 0.010\n",
            "Training [7116/10000]: Loss: 0.012\n",
            "Training [7117/10000]: Loss: 0.010\n",
            "Training [7118/10000]: Loss: 0.011\n",
            "Training [7119/10000]: Loss: 0.012\n",
            "Training [7120/10000]: Loss: 0.012\n",
            "Training [7121/10000]: Loss: 0.014\n",
            "Training [7122/10000]: Loss: 0.014\n",
            "Training [7123/10000]: Loss: 0.012\n",
            "Training [7124/10000]: Loss: 0.013\n",
            "Training [7125/10000]: Loss: 0.017\n",
            "Training [7126/10000]: Loss: 0.012\n",
            "Training [7127/10000]: Loss: 0.009\n",
            "Training [7128/10000]: Loss: 0.009\n",
            "Training [7129/10000]: Loss: 0.008\n",
            "Training [7130/10000]: Loss: 0.012\n",
            "Training [7131/10000]: Loss: 0.011\n",
            "Training [7132/10000]: Loss: 0.012\n",
            "Training [7133/10000]: Loss: 0.010\n",
            "Training [7134/10000]: Loss: 0.015\n",
            "Training [7135/10000]: Loss: 0.013\n",
            "Training [7136/10000]: Loss: 0.008\n",
            "Training [7137/10000]: Loss: 0.009\n",
            "Training [7138/10000]: Loss: 0.009\n",
            "Training [7139/10000]: Loss: 0.016\n",
            "Training [7140/10000]: Loss: 0.015\n",
            "Training [7141/10000]: Loss: 0.009\n",
            "Training [7142/10000]: Loss: 0.015\n",
            "Training [7143/10000]: Loss: 0.013\n",
            "Training [7144/10000]: Loss: 0.011\n",
            "Training [7145/10000]: Loss: 0.014\n",
            "Training [7146/10000]: Loss: 0.005\n",
            "Training [7147/10000]: Loss: 0.020\n",
            "Training [7148/10000]: Loss: 0.010\n",
            "Training [7149/10000]: Loss: 0.006\n",
            "Training [7150/10000]: Loss: 0.010\n",
            "Training [7151/10000]: Loss: 0.009\n",
            "Training [7152/10000]: Loss: 0.018\n",
            "Training [7153/10000]: Loss: 0.015\n",
            "Training [7154/10000]: Loss: 0.011\n",
            "Training [7155/10000]: Loss: 0.009\n",
            "Training [7156/10000]: Loss: 0.013\n",
            "Training [7157/10000]: Loss: 0.012\n",
            "Training [7158/10000]: Loss: 0.013\n",
            "Training [7159/10000]: Loss: 0.015\n",
            "Training [7160/10000]: Loss: 0.009\n",
            "Training [7161/10000]: Loss: 0.011\n",
            "Training [7162/10000]: Loss: 0.013\n",
            "Training [7163/10000]: Loss: 0.013\n",
            "Training [7164/10000]: Loss: 0.015\n",
            "Training [7165/10000]: Loss: 0.009\n",
            "Training [7166/10000]: Loss: 0.011\n",
            "Training [7167/10000]: Loss: 0.010\n",
            "Training [7168/10000]: Loss: 0.012\n",
            "Training [7169/10000]: Loss: 0.016\n",
            "Training [7170/10000]: Loss: 0.017\n",
            "Training [7171/10000]: Loss: 0.009\n",
            "Training [7172/10000]: Loss: 0.012\n",
            "Training [7173/10000]: Loss: 0.012\n",
            "Training [7174/10000]: Loss: 0.011\n",
            "Training [7175/10000]: Loss: 0.016\n",
            "Training [7176/10000]: Loss: 0.019\n",
            "Training [7177/10000]: Loss: 0.016\n",
            "Training [7178/10000]: Loss: 0.010\n",
            "Training [7179/10000]: Loss: 0.010\n",
            "Training [7180/10000]: Loss: 0.018\n",
            "Training [7181/10000]: Loss: 0.011\n",
            "Training [7182/10000]: Loss: 0.010\n",
            "Training [7183/10000]: Loss: 0.008\n",
            "Training [7184/10000]: Loss: 0.010\n",
            "Training [7185/10000]: Loss: 0.007\n",
            "Training [7186/10000]: Loss: 0.007\n",
            "Training [7187/10000]: Loss: 0.019\n",
            "Training [7188/10000]: Loss: 0.013\n",
            "Training [7189/10000]: Loss: 0.009\n",
            "Training [7190/10000]: Loss: 0.016\n",
            "Training [7191/10000]: Loss: 0.008\n",
            "Training [7192/10000]: Loss: 0.009\n",
            "Training [7193/10000]: Loss: 0.012\n",
            "Training [7194/10000]: Loss: 0.021\n",
            "Training [7195/10000]: Loss: 0.013\n",
            "Training [7196/10000]: Loss: 0.015\n",
            "Training [7197/10000]: Loss: 0.009\n",
            "Training [7198/10000]: Loss: 0.009\n",
            "Training [7199/10000]: Loss: 0.012\n",
            "Training [7200/10000]: Loss: 0.013\n",
            "Test Loss: 0.056\n",
            "Training [7201/10000]: Loss: 0.009\n",
            "Training [7202/10000]: Loss: 0.009\n",
            "Training [7203/10000]: Loss: 0.013\n",
            "Training [7204/10000]: Loss: 0.010\n",
            "Training [7205/10000]: Loss: 0.012\n",
            "Training [7206/10000]: Loss: 0.016\n",
            "Training [7207/10000]: Loss: 0.012\n",
            "Training [7208/10000]: Loss: 0.010\n",
            "Training [7209/10000]: Loss: 0.017\n",
            "Training [7210/10000]: Loss: 0.015\n",
            "Training [7211/10000]: Loss: 0.010\n",
            "Training [7212/10000]: Loss: 0.009\n",
            "Training [7213/10000]: Loss: 0.010\n",
            "Training [7214/10000]: Loss: 0.018\n",
            "Training [7215/10000]: Loss: 0.008\n",
            "Training [7216/10000]: Loss: 0.013\n",
            "Training [7217/10000]: Loss: 0.010\n",
            "Training [7218/10000]: Loss: 0.015\n",
            "Training [7219/10000]: Loss: 0.015\n",
            "Training [7220/10000]: Loss: 0.014\n",
            "Training [7221/10000]: Loss: 0.012\n",
            "Training [7222/10000]: Loss: 0.013\n",
            "Training [7223/10000]: Loss: 0.009\n",
            "Training [7224/10000]: Loss: 0.008\n",
            "Training [7225/10000]: Loss: 0.012\n",
            "Training [7226/10000]: Loss: 0.008\n",
            "Training [7227/10000]: Loss: 0.009\n",
            "Training [7228/10000]: Loss: 0.012\n",
            "Training [7229/10000]: Loss: 0.013\n",
            "Training [7230/10000]: Loss: 0.014\n",
            "Training [7231/10000]: Loss: 0.009\n",
            "Training [7232/10000]: Loss: 0.012\n",
            "Training [7233/10000]: Loss: 0.011\n",
            "Training [7234/10000]: Loss: 0.011\n",
            "Training [7235/10000]: Loss: 0.016\n",
            "Training [7236/10000]: Loss: 0.011\n",
            "Training [7237/10000]: Loss: 0.012\n",
            "Training [7238/10000]: Loss: 0.011\n",
            "Training [7239/10000]: Loss: 0.010\n",
            "Training [7240/10000]: Loss: 0.008\n",
            "Training [7241/10000]: Loss: 0.016\n",
            "Training [7242/10000]: Loss: 0.009\n",
            "Training [7243/10000]: Loss: 0.008\n",
            "Training [7244/10000]: Loss: 0.013\n",
            "Training [7245/10000]: Loss: 0.013\n",
            "Training [7246/10000]: Loss: 0.018\n",
            "Training [7247/10000]: Loss: 0.014\n",
            "Training [7248/10000]: Loss: 0.009\n",
            "Training [7249/10000]: Loss: 0.009\n",
            "Training [7250/10000]: Loss: 0.012\n",
            "Training [7251/10000]: Loss: 0.009\n",
            "Training [7252/10000]: Loss: 0.010\n",
            "Training [7253/10000]: Loss: 0.014\n",
            "Training [7254/10000]: Loss: 0.012\n",
            "Training [7255/10000]: Loss: 0.009\n",
            "Training [7256/10000]: Loss: 0.011\n",
            "Training [7257/10000]: Loss: 0.015\n",
            "Training [7258/10000]: Loss: 0.012\n",
            "Training [7259/10000]: Loss: 0.013\n",
            "Training [7260/10000]: Loss: 0.011\n",
            "Training [7261/10000]: Loss: 0.011\n",
            "Training [7262/10000]: Loss: 0.015\n",
            "Training [7263/10000]: Loss: 0.011\n",
            "Training [7264/10000]: Loss: 0.010\n",
            "Training [7265/10000]: Loss: 0.015\n",
            "Training [7266/10000]: Loss: 0.017\n",
            "Training [7267/10000]: Loss: 0.015\n",
            "Training [7268/10000]: Loss: 0.014\n",
            "Training [7269/10000]: Loss: 0.008\n",
            "Training [7270/10000]: Loss: 0.013\n",
            "Training [7271/10000]: Loss: 0.009\n",
            "Training [7272/10000]: Loss: 0.017\n",
            "Training [7273/10000]: Loss: 0.011\n",
            "Training [7274/10000]: Loss: 0.013\n",
            "Training [7275/10000]: Loss: 0.014\n",
            "Training [7276/10000]: Loss: 0.012\n",
            "Training [7277/10000]: Loss: 0.021\n",
            "Training [7278/10000]: Loss: 0.012\n",
            "Training [7279/10000]: Loss: 0.015\n",
            "Training [7280/10000]: Loss: 0.011\n",
            "Training [7281/10000]: Loss: 0.019\n",
            "Training [7282/10000]: Loss: 0.013\n",
            "Training [7283/10000]: Loss: 0.008\n",
            "Training [7284/10000]: Loss: 0.010\n",
            "Training [7285/10000]: Loss: 0.009\n",
            "Training [7286/10000]: Loss: 0.014\n",
            "Training [7287/10000]: Loss: 0.010\n",
            "Training [7288/10000]: Loss: 0.007\n",
            "Training [7289/10000]: Loss: 0.013\n",
            "Training [7290/10000]: Loss: 0.017\n",
            "Training [7291/10000]: Loss: 0.008\n",
            "Training [7292/10000]: Loss: 0.009\n",
            "Training [7293/10000]: Loss: 0.011\n",
            "Training [7294/10000]: Loss: 0.011\n",
            "Training [7295/10000]: Loss: 0.012\n",
            "Training [7296/10000]: Loss: 0.008\n",
            "Training [7297/10000]: Loss: 0.011\n",
            "Training [7298/10000]: Loss: 0.006\n",
            "Training [7299/10000]: Loss: 0.011\n",
            "Training [7300/10000]: Loss: 0.009\n",
            "Test Loss: 0.066\n",
            "Training [7301/10000]: Loss: 0.014\n",
            "Training [7302/10000]: Loss: 0.012\n",
            "Training [7303/10000]: Loss: 0.012\n",
            "Training [7304/10000]: Loss: 0.012\n",
            "Training [7305/10000]: Loss: 0.011\n",
            "Training [7306/10000]: Loss: 0.007\n",
            "Training [7307/10000]: Loss: 0.008\n",
            "Training [7308/10000]: Loss: 0.009\n",
            "Training [7309/10000]: Loss: 0.014\n",
            "Training [7310/10000]: Loss: 0.009\n",
            "Training [7311/10000]: Loss: 0.012\n",
            "Training [7312/10000]: Loss: 0.014\n",
            "Training [7313/10000]: Loss: 0.012\n",
            "Training [7314/10000]: Loss: 0.015\n",
            "Training [7315/10000]: Loss: 0.015\n",
            "Training [7316/10000]: Loss: 0.012\n",
            "Training [7317/10000]: Loss: 0.016\n",
            "Training [7318/10000]: Loss: 0.008\n",
            "Training [7319/10000]: Loss: 0.014\n",
            "Training [7320/10000]: Loss: 0.014\n",
            "Training [7321/10000]: Loss: 0.017\n",
            "Training [7322/10000]: Loss: 0.010\n",
            "Training [7323/10000]: Loss: 0.010\n",
            "Training [7324/10000]: Loss: 0.009\n",
            "Training [7325/10000]: Loss: 0.011\n",
            "Training [7326/10000]: Loss: 0.010\n",
            "Training [7327/10000]: Loss: 0.013\n",
            "Training [7328/10000]: Loss: 0.012\n",
            "Training [7329/10000]: Loss: 0.011\n",
            "Training [7330/10000]: Loss: 0.014\n",
            "Training [7331/10000]: Loss: 0.013\n",
            "Training [7332/10000]: Loss: 0.012\n",
            "Training [7333/10000]: Loss: 0.017\n",
            "Training [7334/10000]: Loss: 0.016\n",
            "Training [7335/10000]: Loss: 0.014\n",
            "Training [7336/10000]: Loss: 0.012\n",
            "Training [7337/10000]: Loss: 0.013\n",
            "Training [7338/10000]: Loss: 0.017\n",
            "Training [7339/10000]: Loss: 0.015\n",
            "Training [7340/10000]: Loss: 0.012\n",
            "Training [7341/10000]: Loss: 0.010\n",
            "Training [7342/10000]: Loss: 0.007\n",
            "Training [7343/10000]: Loss: 0.011\n",
            "Training [7344/10000]: Loss: 0.013\n",
            "Training [7345/10000]: Loss: 0.009\n",
            "Training [7346/10000]: Loss: 0.009\n",
            "Training [7347/10000]: Loss: 0.012\n",
            "Training [7348/10000]: Loss: 0.007\n",
            "Training [7349/10000]: Loss: 0.022\n",
            "Training [7350/10000]: Loss: 0.019\n",
            "Training [7351/10000]: Loss: 0.013\n",
            "Training [7352/10000]: Loss: 0.012\n",
            "Training [7353/10000]: Loss: 0.016\n",
            "Training [7354/10000]: Loss: 0.013\n",
            "Training [7355/10000]: Loss: 0.012\n",
            "Training [7356/10000]: Loss: 0.010\n",
            "Training [7357/10000]: Loss: 0.009\n",
            "Training [7358/10000]: Loss: 0.018\n",
            "Training [7359/10000]: Loss: 0.011\n",
            "Training [7360/10000]: Loss: 0.016\n",
            "Training [7361/10000]: Loss: 0.012\n",
            "Training [7362/10000]: Loss: 0.012\n",
            "Training [7363/10000]: Loss: 0.014\n",
            "Training [7364/10000]: Loss: 0.014\n",
            "Training [7365/10000]: Loss: 0.017\n",
            "Training [7366/10000]: Loss: 0.009\n",
            "Training [7367/10000]: Loss: 0.005\n",
            "Training [7368/10000]: Loss: 0.008\n",
            "Training [7369/10000]: Loss: 0.014\n",
            "Training [7370/10000]: Loss: 0.017\n",
            "Training [7371/10000]: Loss: 0.011\n",
            "Training [7372/10000]: Loss: 0.006\n",
            "Training [7373/10000]: Loss: 0.017\n",
            "Training [7374/10000]: Loss: 0.011\n",
            "Training [7375/10000]: Loss: 0.017\n",
            "Training [7376/10000]: Loss: 0.012\n",
            "Training [7377/10000]: Loss: 0.012\n",
            "Training [7378/10000]: Loss: 0.013\n",
            "Training [7379/10000]: Loss: 0.015\n",
            "Training [7380/10000]: Loss: 0.014\n",
            "Training [7381/10000]: Loss: 0.009\n",
            "Training [7382/10000]: Loss: 0.008\n",
            "Training [7383/10000]: Loss: 0.015\n",
            "Training [7384/10000]: Loss: 0.011\n",
            "Training [7385/10000]: Loss: 0.014\n",
            "Training [7386/10000]: Loss: 0.010\n",
            "Training [7387/10000]: Loss: 0.011\n",
            "Training [7388/10000]: Loss: 0.015\n",
            "Training [7389/10000]: Loss: 0.011\n",
            "Training [7390/10000]: Loss: 0.008\n",
            "Training [7391/10000]: Loss: 0.009\n",
            "Training [7392/10000]: Loss: 0.017\n",
            "Training [7393/10000]: Loss: 0.011\n",
            "Training [7394/10000]: Loss: 0.009\n",
            "Training [7395/10000]: Loss: 0.011\n",
            "Training [7396/10000]: Loss: 0.011\n",
            "Training [7397/10000]: Loss: 0.013\n",
            "Training [7398/10000]: Loss: 0.010\n",
            "Training [7399/10000]: Loss: 0.013\n",
            "Training [7400/10000]: Loss: 0.008\n",
            "Test Loss: 0.058\n",
            "Training [7401/10000]: Loss: 0.011\n",
            "Training [7402/10000]: Loss: 0.008\n",
            "Training [7403/10000]: Loss: 0.016\n",
            "Training [7404/10000]: Loss: 0.011\n",
            "Training [7405/10000]: Loss: 0.012\n",
            "Training [7406/10000]: Loss: 0.013\n",
            "Training [7407/10000]: Loss: 0.009\n",
            "Training [7408/10000]: Loss: 0.015\n",
            "Training [7409/10000]: Loss: 0.017\n",
            "Training [7410/10000]: Loss: 0.009\n",
            "Training [7411/10000]: Loss: 0.012\n",
            "Training [7412/10000]: Loss: 0.013\n",
            "Training [7413/10000]: Loss: 0.014\n",
            "Training [7414/10000]: Loss: 0.013\n",
            "Training [7415/10000]: Loss: 0.011\n",
            "Training [7416/10000]: Loss: 0.011\n",
            "Training [7417/10000]: Loss: 0.012\n",
            "Training [7418/10000]: Loss: 0.014\n",
            "Training [7419/10000]: Loss: 0.010\n",
            "Training [7420/10000]: Loss: 0.012\n",
            "Training [7421/10000]: Loss: 0.011\n",
            "Training [7422/10000]: Loss: 0.008\n",
            "Training [7423/10000]: Loss: 0.013\n",
            "Training [7424/10000]: Loss: 0.010\n",
            "Training [7425/10000]: Loss: 0.013\n",
            "Training [7426/10000]: Loss: 0.015\n",
            "Training [7427/10000]: Loss: 0.013\n",
            "Training [7428/10000]: Loss: 0.012\n",
            "Training [7429/10000]: Loss: 0.013\n",
            "Training [7430/10000]: Loss: 0.015\n",
            "Training [7431/10000]: Loss: 0.010\n",
            "Training [7432/10000]: Loss: 0.010\n",
            "Training [7433/10000]: Loss: 0.014\n",
            "Training [7434/10000]: Loss: 0.015\n",
            "Training [7435/10000]: Loss: 0.010\n",
            "Training [7436/10000]: Loss: 0.013\n",
            "Training [7437/10000]: Loss: 0.006\n",
            "Training [7438/10000]: Loss: 0.017\n",
            "Training [7439/10000]: Loss: 0.009\n",
            "Training [7440/10000]: Loss: 0.014\n",
            "Training [7441/10000]: Loss: 0.018\n",
            "Training [7442/10000]: Loss: 0.008\n",
            "Training [7443/10000]: Loss: 0.010\n",
            "Training [7444/10000]: Loss: 0.010\n",
            "Training [7445/10000]: Loss: 0.019\n",
            "Training [7446/10000]: Loss: 0.010\n",
            "Training [7447/10000]: Loss: 0.012\n",
            "Training [7448/10000]: Loss: 0.012\n",
            "Training [7449/10000]: Loss: 0.008\n",
            "Training [7450/10000]: Loss: 0.009\n",
            "Training [7451/10000]: Loss: 0.009\n",
            "Training [7452/10000]: Loss: 0.012\n",
            "Training [7453/10000]: Loss: 0.011\n",
            "Training [7454/10000]: Loss: 0.012\n",
            "Training [7455/10000]: Loss: 0.009\n",
            "Training [7456/10000]: Loss: 0.016\n",
            "Training [7457/10000]: Loss: 0.012\n",
            "Training [7458/10000]: Loss: 0.008\n",
            "Training [7459/10000]: Loss: 0.017\n",
            "Training [7460/10000]: Loss: 0.009\n",
            "Training [7461/10000]: Loss: 0.011\n",
            "Training [7462/10000]: Loss: 0.012\n",
            "Training [7463/10000]: Loss: 0.013\n",
            "Training [7464/10000]: Loss: 0.007\n",
            "Training [7465/10000]: Loss: 0.013\n",
            "Training [7466/10000]: Loss: 0.011\n",
            "Training [7467/10000]: Loss: 0.010\n",
            "Training [7468/10000]: Loss: 0.011\n",
            "Training [7469/10000]: Loss: 0.008\n",
            "Training [7470/10000]: Loss: 0.017\n",
            "Training [7471/10000]: Loss: 0.016\n",
            "Training [7472/10000]: Loss: 0.006\n",
            "Training [7473/10000]: Loss: 0.013\n",
            "Training [7474/10000]: Loss: 0.010\n",
            "Training [7475/10000]: Loss: 0.011\n",
            "Training [7476/10000]: Loss: 0.013\n",
            "Training [7477/10000]: Loss: 0.012\n",
            "Training [7478/10000]: Loss: 0.016\n",
            "Training [7479/10000]: Loss: 0.009\n",
            "Training [7480/10000]: Loss: 0.009\n",
            "Training [7481/10000]: Loss: 0.011\n",
            "Training [7482/10000]: Loss: 0.008\n",
            "Training [7483/10000]: Loss: 0.012\n",
            "Training [7484/10000]: Loss: 0.016\n",
            "Training [7485/10000]: Loss: 0.012\n",
            "Training [7486/10000]: Loss: 0.013\n",
            "Training [7487/10000]: Loss: 0.016\n",
            "Training [7488/10000]: Loss: 0.012\n",
            "Training [7489/10000]: Loss: 0.013\n",
            "Training [7490/10000]: Loss: 0.007\n",
            "Training [7491/10000]: Loss: 0.015\n",
            "Training [7492/10000]: Loss: 0.011\n",
            "Training [7493/10000]: Loss: 0.013\n",
            "Training [7494/10000]: Loss: 0.010\n",
            "Training [7495/10000]: Loss: 0.013\n",
            "Training [7496/10000]: Loss: 0.010\n",
            "Training [7497/10000]: Loss: 0.012\n",
            "Training [7498/10000]: Loss: 0.012\n",
            "Training [7499/10000]: Loss: 0.014\n",
            "Training [7500/10000]: Loss: 0.009\n",
            "Test Loss: 0.055\n",
            "Training [7501/10000]: Loss: 0.009\n",
            "Training [7502/10000]: Loss: 0.014\n",
            "Training [7503/10000]: Loss: 0.007\n",
            "Training [7504/10000]: Loss: 0.012\n",
            "Training [7505/10000]: Loss: 0.007\n",
            "Training [7506/10000]: Loss: 0.011\n",
            "Training [7507/10000]: Loss: 0.008\n",
            "Training [7508/10000]: Loss: 0.016\n",
            "Training [7509/10000]: Loss: 0.022\n",
            "Training [7510/10000]: Loss: 0.009\n",
            "Training [7511/10000]: Loss: 0.014\n",
            "Training [7512/10000]: Loss: 0.014\n",
            "Training [7513/10000]: Loss: 0.011\n",
            "Training [7514/10000]: Loss: 0.008\n",
            "Training [7515/10000]: Loss: 0.014\n",
            "Training [7516/10000]: Loss: 0.011\n",
            "Training [7517/10000]: Loss: 0.012\n",
            "Training [7518/10000]: Loss: 0.010\n",
            "Training [7519/10000]: Loss: 0.013\n",
            "Training [7520/10000]: Loss: 0.010\n",
            "Training [7521/10000]: Loss: 0.014\n",
            "Training [7522/10000]: Loss: 0.013\n",
            "Training [7523/10000]: Loss: 0.015\n",
            "Training [7524/10000]: Loss: 0.015\n",
            "Training [7525/10000]: Loss: 0.015\n",
            "Training [7526/10000]: Loss: 0.013\n",
            "Training [7527/10000]: Loss: 0.009\n",
            "Training [7528/10000]: Loss: 0.016\n",
            "Training [7529/10000]: Loss: 0.007\n",
            "Training [7530/10000]: Loss: 0.010\n",
            "Training [7531/10000]: Loss: 0.012\n",
            "Training [7532/10000]: Loss: 0.010\n",
            "Training [7533/10000]: Loss: 0.013\n",
            "Training [7534/10000]: Loss: 0.008\n",
            "Training [7535/10000]: Loss: 0.015\n",
            "Training [7536/10000]: Loss: 0.011\n",
            "Training [7537/10000]: Loss: 0.010\n",
            "Training [7538/10000]: Loss: 0.007\n",
            "Training [7539/10000]: Loss: 0.008\n",
            "Training [7540/10000]: Loss: 0.010\n",
            "Training [7541/10000]: Loss: 0.013\n",
            "Training [7542/10000]: Loss: 0.013\n",
            "Training [7543/10000]: Loss: 0.012\n",
            "Training [7544/10000]: Loss: 0.013\n",
            "Training [7545/10000]: Loss: 0.013\n",
            "Training [7546/10000]: Loss: 0.014\n",
            "Training [7547/10000]: Loss: 0.014\n",
            "Training [7548/10000]: Loss: 0.014\n",
            "Training [7549/10000]: Loss: 0.013\n",
            "Training [7550/10000]: Loss: 0.010\n",
            "Training [7551/10000]: Loss: 0.015\n",
            "Training [7552/10000]: Loss: 0.012\n",
            "Training [7553/10000]: Loss: 0.011\n",
            "Training [7554/10000]: Loss: 0.008\n",
            "Training [7555/10000]: Loss: 0.018\n",
            "Training [7556/10000]: Loss: 0.015\n",
            "Training [7557/10000]: Loss: 0.011\n",
            "Training [7558/10000]: Loss: 0.013\n",
            "Training [7559/10000]: Loss: 0.008\n",
            "Training [7560/10000]: Loss: 0.015\n",
            "Training [7561/10000]: Loss: 0.013\n",
            "Training [7562/10000]: Loss: 0.011\n",
            "Training [7563/10000]: Loss: 0.010\n",
            "Training [7564/10000]: Loss: 0.018\n",
            "Training [7565/10000]: Loss: 0.017\n",
            "Training [7566/10000]: Loss: 0.013\n",
            "Training [7567/10000]: Loss: 0.013\n",
            "Training [7568/10000]: Loss: 0.007\n",
            "Training [7569/10000]: Loss: 0.017\n",
            "Training [7570/10000]: Loss: 0.012\n",
            "Training [7571/10000]: Loss: 0.015\n",
            "Training [7572/10000]: Loss: 0.006\n",
            "Training [7573/10000]: Loss: 0.010\n",
            "Training [7574/10000]: Loss: 0.013\n",
            "Training [7575/10000]: Loss: 0.009\n",
            "Training [7576/10000]: Loss: 0.009\n",
            "Training [7577/10000]: Loss: 0.007\n",
            "Training [7578/10000]: Loss: 0.013\n",
            "Training [7579/10000]: Loss: 0.016\n",
            "Training [7580/10000]: Loss: 0.019\n",
            "Training [7581/10000]: Loss: 0.012\n",
            "Training [7582/10000]: Loss: 0.007\n",
            "Training [7583/10000]: Loss: 0.011\n",
            "Training [7584/10000]: Loss: 0.010\n",
            "Training [7585/10000]: Loss: 0.009\n",
            "Training [7586/10000]: Loss: 0.012\n",
            "Training [7587/10000]: Loss: 0.007\n",
            "Training [7588/10000]: Loss: 0.012\n",
            "Training [7589/10000]: Loss: 0.013\n",
            "Training [7590/10000]: Loss: 0.013\n",
            "Training [7591/10000]: Loss: 0.014\n",
            "Training [7592/10000]: Loss: 0.012\n",
            "Training [7593/10000]: Loss: 0.008\n",
            "Training [7594/10000]: Loss: 0.013\n",
            "Training [7595/10000]: Loss: 0.012\n",
            "Training [7596/10000]: Loss: 0.012\n",
            "Training [7597/10000]: Loss: 0.008\n",
            "Training [7598/10000]: Loss: 0.013\n",
            "Training [7599/10000]: Loss: 0.016\n",
            "Training [7600/10000]: Loss: 0.014\n",
            "Test Loss: 0.056\n",
            "Training [7601/10000]: Loss: 0.016\n",
            "Training [7602/10000]: Loss: 0.015\n",
            "Training [7603/10000]: Loss: 0.013\n",
            "Training [7604/10000]: Loss: 0.014\n",
            "Training [7605/10000]: Loss: 0.010\n",
            "Training [7606/10000]: Loss: 0.013\n",
            "Training [7607/10000]: Loss: 0.012\n",
            "Training [7608/10000]: Loss: 0.009\n",
            "Training [7609/10000]: Loss: 0.013\n",
            "Training [7610/10000]: Loss: 0.016\n",
            "Training [7611/10000]: Loss: 0.009\n",
            "Training [7612/10000]: Loss: 0.013\n",
            "Training [7613/10000]: Loss: 0.007\n",
            "Training [7614/10000]: Loss: 0.012\n",
            "Training [7615/10000]: Loss: 0.015\n",
            "Training [7616/10000]: Loss: 0.012\n",
            "Training [7617/10000]: Loss: 0.012\n",
            "Training [7618/10000]: Loss: 0.013\n",
            "Training [7619/10000]: Loss: 0.013\n",
            "Training [7620/10000]: Loss: 0.011\n",
            "Training [7621/10000]: Loss: 0.011\n",
            "Training [7622/10000]: Loss: 0.013\n",
            "Training [7623/10000]: Loss: 0.008\n",
            "Training [7624/10000]: Loss: 0.010\n",
            "Training [7625/10000]: Loss: 0.017\n",
            "Training [7626/10000]: Loss: 0.008\n",
            "Training [7627/10000]: Loss: 0.016\n",
            "Training [7628/10000]: Loss: 0.005\n",
            "Training [7629/10000]: Loss: 0.012\n",
            "Training [7630/10000]: Loss: 0.015\n",
            "Training [7631/10000]: Loss: 0.008\n",
            "Training [7632/10000]: Loss: 0.018\n",
            "Training [7633/10000]: Loss: 0.010\n",
            "Training [7634/10000]: Loss: 0.011\n",
            "Training [7635/10000]: Loss: 0.011\n",
            "Training [7636/10000]: Loss: 0.011\n",
            "Training [7637/10000]: Loss: 0.011\n",
            "Training [7638/10000]: Loss: 0.015\n",
            "Training [7639/10000]: Loss: 0.009\n",
            "Training [7640/10000]: Loss: 0.013\n",
            "Training [7641/10000]: Loss: 0.012\n",
            "Training [7642/10000]: Loss: 0.009\n",
            "Training [7643/10000]: Loss: 0.010\n",
            "Training [7644/10000]: Loss: 0.012\n",
            "Training [7645/10000]: Loss: 0.012\n",
            "Training [7646/10000]: Loss: 0.013\n",
            "Training [7647/10000]: Loss: 0.007\n",
            "Training [7648/10000]: Loss: 0.008\n",
            "Training [7649/10000]: Loss: 0.012\n",
            "Training [7650/10000]: Loss: 0.009\n",
            "Training [7651/10000]: Loss: 0.009\n",
            "Training [7652/10000]: Loss: 0.011\n",
            "Training [7653/10000]: Loss: 0.013\n",
            "Training [7654/10000]: Loss: 0.013\n",
            "Training [7655/10000]: Loss: 0.017\n",
            "Training [7656/10000]: Loss: 0.011\n",
            "Training [7657/10000]: Loss: 0.010\n",
            "Training [7658/10000]: Loss: 0.010\n",
            "Training [7659/10000]: Loss: 0.016\n",
            "Training [7660/10000]: Loss: 0.012\n",
            "Training [7661/10000]: Loss: 0.008\n",
            "Training [7662/10000]: Loss: 0.013\n",
            "Training [7663/10000]: Loss: 0.014\n",
            "Training [7664/10000]: Loss: 0.012\n",
            "Training [7665/10000]: Loss: 0.012\n",
            "Training [7666/10000]: Loss: 0.011\n",
            "Training [7667/10000]: Loss: 0.013\n",
            "Training [7668/10000]: Loss: 0.014\n",
            "Training [7669/10000]: Loss: 0.008\n",
            "Training [7670/10000]: Loss: 0.012\n",
            "Training [7671/10000]: Loss: 0.014\n",
            "Training [7672/10000]: Loss: 0.015\n",
            "Training [7673/10000]: Loss: 0.011\n",
            "Training [7674/10000]: Loss: 0.007\n",
            "Training [7675/10000]: Loss: 0.014\n",
            "Training [7676/10000]: Loss: 0.011\n",
            "Training [7677/10000]: Loss: 0.009\n",
            "Training [7678/10000]: Loss: 0.014\n",
            "Training [7679/10000]: Loss: 0.013\n",
            "Training [7680/10000]: Loss: 0.010\n",
            "Training [7681/10000]: Loss: 0.011\n",
            "Training [7682/10000]: Loss: 0.017\n",
            "Training [7683/10000]: Loss: 0.012\n",
            "Training [7684/10000]: Loss: 0.012\n",
            "Training [7685/10000]: Loss: 0.013\n",
            "Training [7686/10000]: Loss: 0.011\n",
            "Training [7687/10000]: Loss: 0.009\n",
            "Training [7688/10000]: Loss: 0.014\n",
            "Training [7689/10000]: Loss: 0.011\n",
            "Training [7690/10000]: Loss: 0.014\n",
            "Training [7691/10000]: Loss: 0.010\n",
            "Training [7692/10000]: Loss: 0.008\n",
            "Training [7693/10000]: Loss: 0.016\n",
            "Training [7694/10000]: Loss: 0.011\n",
            "Training [7695/10000]: Loss: 0.009\n",
            "Training [7696/10000]: Loss: 0.014\n",
            "Training [7697/10000]: Loss: 0.011\n",
            "Training [7698/10000]: Loss: 0.009\n",
            "Training [7699/10000]: Loss: 0.010\n",
            "Training [7700/10000]: Loss: 0.011\n",
            "Test Loss: 0.061\n",
            "Training [7701/10000]: Loss: 0.010\n",
            "Training [7702/10000]: Loss: 0.009\n",
            "Training [7703/10000]: Loss: 0.010\n",
            "Training [7704/10000]: Loss: 0.008\n",
            "Training [7705/10000]: Loss: 0.006\n",
            "Training [7706/10000]: Loss: 0.006\n",
            "Training [7707/10000]: Loss: 0.008\n",
            "Training [7708/10000]: Loss: 0.009\n",
            "Training [7709/10000]: Loss: 0.015\n",
            "Training [7710/10000]: Loss: 0.013\n",
            "Training [7711/10000]: Loss: 0.014\n",
            "Training [7712/10000]: Loss: 0.016\n",
            "Training [7713/10000]: Loss: 0.013\n",
            "Training [7714/10000]: Loss: 0.011\n",
            "Training [7715/10000]: Loss: 0.008\n",
            "Training [7716/10000]: Loss: 0.009\n",
            "Training [7717/10000]: Loss: 0.004\n",
            "Training [7718/10000]: Loss: 0.012\n",
            "Training [7719/10000]: Loss: 0.013\n",
            "Training [7720/10000]: Loss: 0.012\n",
            "Training [7721/10000]: Loss: 0.012\n",
            "Training [7722/10000]: Loss: 0.012\n",
            "Training [7723/10000]: Loss: 0.010\n",
            "Training [7724/10000]: Loss: 0.014\n",
            "Training [7725/10000]: Loss: 0.010\n",
            "Training [7726/10000]: Loss: 0.011\n",
            "Training [7727/10000]: Loss: 0.009\n",
            "Training [7728/10000]: Loss: 0.010\n",
            "Training [7729/10000]: Loss: 0.015\n",
            "Training [7730/10000]: Loss: 0.016\n",
            "Training [7731/10000]: Loss: 0.011\n",
            "Training [7732/10000]: Loss: 0.012\n",
            "Training [7733/10000]: Loss: 0.015\n",
            "Training [7734/10000]: Loss: 0.011\n",
            "Training [7735/10000]: Loss: 0.009\n",
            "Training [7736/10000]: Loss: 0.009\n",
            "Training [7737/10000]: Loss: 0.010\n",
            "Training [7738/10000]: Loss: 0.012\n",
            "Training [7739/10000]: Loss: 0.015\n",
            "Training [7740/10000]: Loss: 0.011\n",
            "Training [7741/10000]: Loss: 0.008\n",
            "Training [7742/10000]: Loss: 0.012\n",
            "Training [7743/10000]: Loss: 0.009\n",
            "Training [7744/10000]: Loss: 0.008\n",
            "Training [7745/10000]: Loss: 0.010\n",
            "Training [7746/10000]: Loss: 0.013\n",
            "Training [7747/10000]: Loss: 0.009\n",
            "Training [7748/10000]: Loss: 0.013\n",
            "Training [7749/10000]: Loss: 0.016\n",
            "Training [7750/10000]: Loss: 0.010\n",
            "Training [7751/10000]: Loss: 0.017\n",
            "Training [7752/10000]: Loss: 0.012\n",
            "Training [7753/10000]: Loss: 0.013\n",
            "Training [7754/10000]: Loss: 0.008\n",
            "Training [7755/10000]: Loss: 0.016\n",
            "Training [7756/10000]: Loss: 0.009\n",
            "Training [7757/10000]: Loss: 0.006\n",
            "Training [7758/10000]: Loss: 0.016\n",
            "Training [7759/10000]: Loss: 0.008\n",
            "Training [7760/10000]: Loss: 0.007\n",
            "Training [7761/10000]: Loss: 0.012\n",
            "Training [7762/10000]: Loss: 0.015\n",
            "Training [7763/10000]: Loss: 0.007\n",
            "Training [7764/10000]: Loss: 0.010\n",
            "Training [7765/10000]: Loss: 0.014\n",
            "Training [7766/10000]: Loss: 0.013\n",
            "Training [7767/10000]: Loss: 0.011\n",
            "Training [7768/10000]: Loss: 0.010\n",
            "Training [7769/10000]: Loss: 0.009\n",
            "Training [7770/10000]: Loss: 0.012\n",
            "Training [7771/10000]: Loss: 0.007\n",
            "Training [7772/10000]: Loss: 0.009\n",
            "Training [7773/10000]: Loss: 0.008\n",
            "Training [7774/10000]: Loss: 0.017\n",
            "Training [7775/10000]: Loss: 0.015\n",
            "Training [7776/10000]: Loss: 0.009\n",
            "Training [7777/10000]: Loss: 0.012\n",
            "Training [7778/10000]: Loss: 0.009\n",
            "Training [7779/10000]: Loss: 0.009\n",
            "Training [7780/10000]: Loss: 0.008\n",
            "Training [7781/10000]: Loss: 0.012\n",
            "Training [7782/10000]: Loss: 0.009\n",
            "Training [7783/10000]: Loss: 0.007\n",
            "Training [7784/10000]: Loss: 0.012\n",
            "Training [7785/10000]: Loss: 0.007\n",
            "Training [7786/10000]: Loss: 0.013\n",
            "Training [7787/10000]: Loss: 0.010\n",
            "Training [7788/10000]: Loss: 0.015\n",
            "Training [7789/10000]: Loss: 0.010\n",
            "Training [7790/10000]: Loss: 0.008\n",
            "Training [7791/10000]: Loss: 0.015\n",
            "Training [7792/10000]: Loss: 0.008\n",
            "Training [7793/10000]: Loss: 0.023\n",
            "Training [7794/10000]: Loss: 0.010\n",
            "Training [7795/10000]: Loss: 0.008\n",
            "Training [7796/10000]: Loss: 0.010\n",
            "Training [7797/10000]: Loss: 0.009\n",
            "Training [7798/10000]: Loss: 0.009\n",
            "Training [7799/10000]: Loss: 0.013\n",
            "Training [7800/10000]: Loss: 0.008\n",
            "Test Loss: 0.058\n",
            "Training [7801/10000]: Loss: 0.005\n",
            "Training [7802/10000]: Loss: 0.012\n",
            "Training [7803/10000]: Loss: 0.010\n",
            "Training [7804/10000]: Loss: 0.006\n",
            "Training [7805/10000]: Loss: 0.009\n",
            "Training [7806/10000]: Loss: 0.015\n",
            "Training [7807/10000]: Loss: 0.012\n",
            "Training [7808/10000]: Loss: 0.013\n",
            "Training [7809/10000]: Loss: 0.013\n",
            "Training [7810/10000]: Loss: 0.015\n",
            "Training [7811/10000]: Loss: 0.017\n",
            "Training [7812/10000]: Loss: 0.013\n",
            "Training [7813/10000]: Loss: 0.011\n",
            "Training [7814/10000]: Loss: 0.010\n",
            "Training [7815/10000]: Loss: 0.012\n",
            "Training [7816/10000]: Loss: 0.014\n",
            "Training [7817/10000]: Loss: 0.013\n",
            "Training [7818/10000]: Loss: 0.011\n",
            "Training [7819/10000]: Loss: 0.011\n",
            "Training [7820/10000]: Loss: 0.011\n",
            "Training [7821/10000]: Loss: 0.008\n",
            "Training [7822/10000]: Loss: 0.010\n",
            "Training [7823/10000]: Loss: 0.011\n",
            "Training [7824/10000]: Loss: 0.008\n",
            "Training [7825/10000]: Loss: 0.008\n",
            "Training [7826/10000]: Loss: 0.019\n",
            "Training [7827/10000]: Loss: 0.013\n",
            "Training [7828/10000]: Loss: 0.011\n",
            "Training [7829/10000]: Loss: 0.011\n",
            "Training [7830/10000]: Loss: 0.010\n",
            "Training [7831/10000]: Loss: 0.009\n",
            "Training [7832/10000]: Loss: 0.009\n",
            "Training [7833/10000]: Loss: 0.012\n",
            "Training [7834/10000]: Loss: 0.014\n",
            "Training [7835/10000]: Loss: 0.010\n",
            "Training [7836/10000]: Loss: 0.007\n",
            "Training [7837/10000]: Loss: 0.015\n",
            "Training [7838/10000]: Loss: 0.007\n",
            "Training [7839/10000]: Loss: 0.012\n",
            "Training [7840/10000]: Loss: 0.009\n",
            "Training [7841/10000]: Loss: 0.013\n",
            "Training [7842/10000]: Loss: 0.009\n",
            "Training [7843/10000]: Loss: 0.011\n",
            "Training [7844/10000]: Loss: 0.011\n",
            "Training [7845/10000]: Loss: 0.010\n",
            "Training [7846/10000]: Loss: 0.019\n",
            "Training [7847/10000]: Loss: 0.009\n",
            "Training [7848/10000]: Loss: 0.009\n",
            "Training [7849/10000]: Loss: 0.011\n",
            "Training [7850/10000]: Loss: 0.012\n",
            "Training [7851/10000]: Loss: 0.008\n",
            "Training [7852/10000]: Loss: 0.016\n",
            "Training [7853/10000]: Loss: 0.014\n",
            "Training [7854/10000]: Loss: 0.008\n",
            "Training [7855/10000]: Loss: 0.012\n",
            "Training [7856/10000]: Loss: 0.016\n",
            "Training [7857/10000]: Loss: 0.010\n",
            "Training [7858/10000]: Loss: 0.009\n",
            "Training [7859/10000]: Loss: 0.016\n",
            "Training [7860/10000]: Loss: 0.010\n",
            "Training [7861/10000]: Loss: 0.016\n",
            "Training [7862/10000]: Loss: 0.012\n",
            "Training [7863/10000]: Loss: 0.010\n",
            "Training [7864/10000]: Loss: 0.009\n",
            "Training [7865/10000]: Loss: 0.013\n",
            "Training [7866/10000]: Loss: 0.007\n",
            "Training [7867/10000]: Loss: 0.006\n",
            "Training [7868/10000]: Loss: 0.011\n",
            "Training [7869/10000]: Loss: 0.010\n",
            "Training [7870/10000]: Loss: 0.012\n",
            "Training [7871/10000]: Loss: 0.013\n",
            "Training [7872/10000]: Loss: 0.010\n",
            "Training [7873/10000]: Loss: 0.012\n",
            "Training [7874/10000]: Loss: 0.011\n",
            "Training [7875/10000]: Loss: 0.011\n",
            "Training [7876/10000]: Loss: 0.006\n",
            "Training [7877/10000]: Loss: 0.013\n",
            "Training [7878/10000]: Loss: 0.011\n",
            "Training [7879/10000]: Loss: 0.011\n",
            "Training [7880/10000]: Loss: 0.011\n",
            "Training [7881/10000]: Loss: 0.010\n",
            "Training [7882/10000]: Loss: 0.011\n",
            "Training [7883/10000]: Loss: 0.013\n",
            "Training [7884/10000]: Loss: 0.009\n",
            "Training [7885/10000]: Loss: 0.012\n",
            "Training [7886/10000]: Loss: 0.013\n",
            "Training [7887/10000]: Loss: 0.010\n",
            "Training [7888/10000]: Loss: 0.011\n",
            "Training [7889/10000]: Loss: 0.009\n",
            "Training [7890/10000]: Loss: 0.011\n",
            "Training [7891/10000]: Loss: 0.009\n",
            "Training [7892/10000]: Loss: 0.011\n",
            "Training [7893/10000]: Loss: 0.011\n",
            "Training [7894/10000]: Loss: 0.011\n",
            "Training [7895/10000]: Loss: 0.010\n",
            "Training [7896/10000]: Loss: 0.006\n",
            "Training [7897/10000]: Loss: 0.010\n",
            "Training [7898/10000]: Loss: 0.005\n",
            "Training [7899/10000]: Loss: 0.010\n",
            "Training [7900/10000]: Loss: 0.012\n",
            "Test Loss: 0.059\n",
            "Training [7901/10000]: Loss: 0.009\n",
            "Training [7902/10000]: Loss: 0.021\n",
            "Training [7903/10000]: Loss: 0.010\n",
            "Training [7904/10000]: Loss: 0.011\n",
            "Training [7905/10000]: Loss: 0.011\n",
            "Training [7906/10000]: Loss: 0.012\n",
            "Training [7907/10000]: Loss: 0.007\n",
            "Training [7908/10000]: Loss: 0.006\n",
            "Training [7909/10000]: Loss: 0.008\n",
            "Training [7910/10000]: Loss: 0.020\n",
            "Training [7911/10000]: Loss: 0.009\n",
            "Training [7912/10000]: Loss: 0.015\n",
            "Training [7913/10000]: Loss: 0.011\n",
            "Training [7914/10000]: Loss: 0.014\n",
            "Training [7915/10000]: Loss: 0.010\n",
            "Training [7916/10000]: Loss: 0.012\n",
            "Training [7917/10000]: Loss: 0.011\n",
            "Training [7918/10000]: Loss: 0.007\n",
            "Training [7919/10000]: Loss: 0.009\n",
            "Training [7920/10000]: Loss: 0.014\n",
            "Training [7921/10000]: Loss: 0.009\n",
            "Training [7922/10000]: Loss: 0.009\n",
            "Training [7923/10000]: Loss: 0.009\n",
            "Training [7924/10000]: Loss: 0.008\n",
            "Training [7925/10000]: Loss: 0.011\n",
            "Training [7926/10000]: Loss: 0.008\n",
            "Training [7927/10000]: Loss: 0.011\n",
            "Training [7928/10000]: Loss: 0.009\n",
            "Training [7929/10000]: Loss: 0.015\n",
            "Training [7930/10000]: Loss: 0.013\n",
            "Training [7931/10000]: Loss: 0.013\n",
            "Training [7932/10000]: Loss: 0.016\n",
            "Training [7933/10000]: Loss: 0.012\n",
            "Training [7934/10000]: Loss: 0.009\n",
            "Training [7935/10000]: Loss: 0.009\n",
            "Training [7936/10000]: Loss: 0.014\n",
            "Training [7937/10000]: Loss: 0.012\n",
            "Training [7938/10000]: Loss: 0.014\n",
            "Training [7939/10000]: Loss: 0.010\n",
            "Training [7940/10000]: Loss: 0.012\n",
            "Training [7941/10000]: Loss: 0.014\n",
            "Training [7942/10000]: Loss: 0.013\n",
            "Training [7943/10000]: Loss: 0.010\n",
            "Training [7944/10000]: Loss: 0.009\n",
            "Training [7945/10000]: Loss: 0.010\n",
            "Training [7946/10000]: Loss: 0.012\n",
            "Training [7947/10000]: Loss: 0.014\n",
            "Training [7948/10000]: Loss: 0.008\n",
            "Training [7949/10000]: Loss: 0.012\n",
            "Training [7950/10000]: Loss: 0.012\n",
            "Training [7951/10000]: Loss: 0.010\n",
            "Training [7952/10000]: Loss: 0.007\n",
            "Training [7953/10000]: Loss: 0.012\n",
            "Training [7954/10000]: Loss: 0.012\n",
            "Training [7955/10000]: Loss: 0.013\n",
            "Training [7956/10000]: Loss: 0.006\n",
            "Training [7957/10000]: Loss: 0.012\n",
            "Training [7958/10000]: Loss: 0.007\n",
            "Training [7959/10000]: Loss: 0.012\n",
            "Training [7960/10000]: Loss: 0.010\n",
            "Training [7961/10000]: Loss: 0.010\n",
            "Training [7962/10000]: Loss: 0.007\n",
            "Training [7963/10000]: Loss: 0.013\n",
            "Training [7964/10000]: Loss: 0.010\n",
            "Training [7965/10000]: Loss: 0.007\n",
            "Training [7966/10000]: Loss: 0.014\n",
            "Training [7967/10000]: Loss: 0.009\n",
            "Training [7968/10000]: Loss: 0.009\n",
            "Training [7969/10000]: Loss: 0.008\n",
            "Training [7970/10000]: Loss: 0.008\n",
            "Training [7971/10000]: Loss: 0.013\n",
            "Training [7972/10000]: Loss: 0.014\n",
            "Training [7973/10000]: Loss: 0.013\n",
            "Training [7974/10000]: Loss: 0.011\n",
            "Training [7975/10000]: Loss: 0.013\n",
            "Training [7976/10000]: Loss: 0.010\n",
            "Training [7977/10000]: Loss: 0.012\n",
            "Training [7978/10000]: Loss: 0.010\n",
            "Training [7979/10000]: Loss: 0.011\n",
            "Training [7980/10000]: Loss: 0.012\n",
            "Training [7981/10000]: Loss: 0.011\n",
            "Training [7982/10000]: Loss: 0.008\n",
            "Training [7983/10000]: Loss: 0.012\n",
            "Training [7984/10000]: Loss: 0.008\n",
            "Training [7985/10000]: Loss: 0.013\n",
            "Training [7986/10000]: Loss: 0.009\n",
            "Training [7987/10000]: Loss: 0.015\n",
            "Training [7988/10000]: Loss: 0.010\n",
            "Training [7989/10000]: Loss: 0.010\n",
            "Training [7990/10000]: Loss: 0.013\n",
            "Training [7991/10000]: Loss: 0.012\n",
            "Training [7992/10000]: Loss: 0.009\n",
            "Training [7993/10000]: Loss: 0.014\n",
            "Training [7994/10000]: Loss: 0.012\n",
            "Training [7995/10000]: Loss: 0.015\n",
            "Training [7996/10000]: Loss: 0.014\n",
            "Training [7997/10000]: Loss: 0.012\n",
            "Training [7998/10000]: Loss: 0.010\n",
            "Training [7999/10000]: Loss: 0.014\n",
            "Training [8000/10000]: Loss: 0.012\n",
            "Test Loss: 0.057\n",
            "Training [8001/10000]: Loss: 0.012\n",
            "Training [8002/10000]: Loss: 0.014\n",
            "Training [8003/10000]: Loss: 0.010\n",
            "Training [8004/10000]: Loss: 0.011\n",
            "Training [8005/10000]: Loss: 0.009\n",
            "Training [8006/10000]: Loss: 0.014\n",
            "Training [8007/10000]: Loss: 0.012\n",
            "Training [8008/10000]: Loss: 0.013\n",
            "Training [8009/10000]: Loss: 0.008\n",
            "Training [8010/10000]: Loss: 0.012\n",
            "Training [8011/10000]: Loss: 0.012\n",
            "Training [8012/10000]: Loss: 0.010\n",
            "Training [8013/10000]: Loss: 0.012\n",
            "Training [8014/10000]: Loss: 0.009\n",
            "Training [8015/10000]: Loss: 0.011\n",
            "Training [8016/10000]: Loss: 0.013\n",
            "Training [8017/10000]: Loss: 0.014\n",
            "Training [8018/10000]: Loss: 0.014\n",
            "Training [8019/10000]: Loss: 0.008\n",
            "Training [8020/10000]: Loss: 0.013\n",
            "Training [8021/10000]: Loss: 0.011\n",
            "Training [8022/10000]: Loss: 0.015\n",
            "Training [8023/10000]: Loss: 0.011\n",
            "Training [8024/10000]: Loss: 0.011\n",
            "Training [8025/10000]: Loss: 0.012\n",
            "Training [8026/10000]: Loss: 0.010\n",
            "Training [8027/10000]: Loss: 0.012\n",
            "Training [8028/10000]: Loss: 0.010\n",
            "Training [8029/10000]: Loss: 0.009\n",
            "Training [8030/10000]: Loss: 0.010\n",
            "Training [8031/10000]: Loss: 0.010\n",
            "Training [8032/10000]: Loss: 0.011\n",
            "Training [8033/10000]: Loss: 0.007\n",
            "Training [8034/10000]: Loss: 0.016\n",
            "Training [8035/10000]: Loss: 0.012\n",
            "Training [8036/10000]: Loss: 0.009\n",
            "Training [8037/10000]: Loss: 0.014\n",
            "Training [8038/10000]: Loss: 0.009\n",
            "Training [8039/10000]: Loss: 0.011\n",
            "Training [8040/10000]: Loss: 0.011\n",
            "Training [8041/10000]: Loss: 0.014\n",
            "Training [8042/10000]: Loss: 0.012\n",
            "Training [8043/10000]: Loss: 0.009\n",
            "Training [8044/10000]: Loss: 0.007\n",
            "Training [8045/10000]: Loss: 0.013\n",
            "Training [8046/10000]: Loss: 0.012\n",
            "Training [8047/10000]: Loss: 0.012\n",
            "Training [8048/10000]: Loss: 0.012\n",
            "Training [8049/10000]: Loss: 0.008\n",
            "Training [8050/10000]: Loss: 0.008\n",
            "Training [8051/10000]: Loss: 0.010\n",
            "Training [8052/10000]: Loss: 0.015\n",
            "Training [8053/10000]: Loss: 0.009\n",
            "Training [8054/10000]: Loss: 0.014\n",
            "Training [8055/10000]: Loss: 0.014\n",
            "Training [8056/10000]: Loss: 0.006\n",
            "Training [8057/10000]: Loss: 0.014\n",
            "Training [8058/10000]: Loss: 0.009\n",
            "Training [8059/10000]: Loss: 0.009\n",
            "Training [8060/10000]: Loss: 0.011\n",
            "Training [8061/10000]: Loss: 0.007\n",
            "Training [8062/10000]: Loss: 0.008\n",
            "Training [8063/10000]: Loss: 0.009\n",
            "Training [8064/10000]: Loss: 0.016\n",
            "Training [8065/10000]: Loss: 0.010\n",
            "Training [8066/10000]: Loss: 0.007\n",
            "Training [8067/10000]: Loss: 0.008\n",
            "Training [8068/10000]: Loss: 0.007\n",
            "Training [8069/10000]: Loss: 0.017\n",
            "Training [8070/10000]: Loss: 0.012\n",
            "Training [8071/10000]: Loss: 0.011\n",
            "Training [8072/10000]: Loss: 0.013\n",
            "Training [8073/10000]: Loss: 0.014\n",
            "Training [8074/10000]: Loss: 0.011\n",
            "Training [8075/10000]: Loss: 0.004\n",
            "Training [8076/10000]: Loss: 0.011\n",
            "Training [8077/10000]: Loss: 0.011\n",
            "Training [8078/10000]: Loss: 0.010\n",
            "Training [8079/10000]: Loss: 0.008\n",
            "Training [8080/10000]: Loss: 0.009\n",
            "Training [8081/10000]: Loss: 0.007\n",
            "Training [8082/10000]: Loss: 0.011\n",
            "Training [8083/10000]: Loss: 0.007\n",
            "Training [8084/10000]: Loss: 0.012\n",
            "Training [8085/10000]: Loss: 0.007\n",
            "Training [8086/10000]: Loss: 0.011\n",
            "Training [8087/10000]: Loss: 0.013\n",
            "Training [8088/10000]: Loss: 0.011\n",
            "Training [8089/10000]: Loss: 0.014\n",
            "Training [8090/10000]: Loss: 0.014\n",
            "Training [8091/10000]: Loss: 0.009\n",
            "Training [8092/10000]: Loss: 0.012\n",
            "Training [8093/10000]: Loss: 0.014\n",
            "Training [8094/10000]: Loss: 0.012\n",
            "Training [8095/10000]: Loss: 0.013\n",
            "Training [8096/10000]: Loss: 0.014\n",
            "Training [8097/10000]: Loss: 0.009\n",
            "Training [8098/10000]: Loss: 0.014\n",
            "Training [8099/10000]: Loss: 0.008\n",
            "Training [8100/10000]: Loss: 0.009\n",
            "Test Loss: 0.058\n",
            "Training [8101/10000]: Loss: 0.016\n",
            "Training [8102/10000]: Loss: 0.013\n",
            "Training [8103/10000]: Loss: 0.011\n",
            "Training [8104/10000]: Loss: 0.012\n",
            "Training [8105/10000]: Loss: 0.011\n",
            "Training [8106/10000]: Loss: 0.014\n",
            "Training [8107/10000]: Loss: 0.009\n",
            "Training [8108/10000]: Loss: 0.012\n",
            "Training [8109/10000]: Loss: 0.008\n",
            "Training [8110/10000]: Loss: 0.012\n",
            "Training [8111/10000]: Loss: 0.014\n",
            "Training [8112/10000]: Loss: 0.013\n",
            "Training [8113/10000]: Loss: 0.013\n",
            "Training [8114/10000]: Loss: 0.016\n",
            "Training [8115/10000]: Loss: 0.013\n",
            "Training [8116/10000]: Loss: 0.013\n",
            "Training [8117/10000]: Loss: 0.011\n",
            "Training [8118/10000]: Loss: 0.012\n",
            "Training [8119/10000]: Loss: 0.009\n",
            "Training [8120/10000]: Loss: 0.008\n",
            "Training [8121/10000]: Loss: 0.006\n",
            "Training [8122/10000]: Loss: 0.010\n",
            "Training [8123/10000]: Loss: 0.011\n",
            "Training [8124/10000]: Loss: 0.011\n",
            "Training [8125/10000]: Loss: 0.013\n",
            "Training [8126/10000]: Loss: 0.009\n",
            "Training [8127/10000]: Loss: 0.011\n",
            "Training [8128/10000]: Loss: 0.010\n",
            "Training [8129/10000]: Loss: 0.011\n",
            "Training [8130/10000]: Loss: 0.015\n",
            "Training [8131/10000]: Loss: 0.006\n",
            "Training [8132/10000]: Loss: 0.007\n",
            "Training [8133/10000]: Loss: 0.007\n",
            "Training [8134/10000]: Loss: 0.011\n",
            "Training [8135/10000]: Loss: 0.009\n",
            "Training [8136/10000]: Loss: 0.011\n",
            "Training [8137/10000]: Loss: 0.017\n",
            "Training [8138/10000]: Loss: 0.016\n",
            "Training [8139/10000]: Loss: 0.013\n",
            "Training [8140/10000]: Loss: 0.012\n",
            "Training [8141/10000]: Loss: 0.010\n",
            "Training [8142/10000]: Loss: 0.013\n",
            "Training [8143/10000]: Loss: 0.008\n",
            "Training [8144/10000]: Loss: 0.014\n",
            "Training [8145/10000]: Loss: 0.010\n",
            "Training [8146/10000]: Loss: 0.016\n",
            "Training [8147/10000]: Loss: 0.013\n",
            "Training [8148/10000]: Loss: 0.015\n",
            "Training [8149/10000]: Loss: 0.011\n",
            "Training [8150/10000]: Loss: 0.012\n",
            "Training [8151/10000]: Loss: 0.016\n",
            "Training [8152/10000]: Loss: 0.014\n",
            "Training [8153/10000]: Loss: 0.012\n",
            "Training [8154/10000]: Loss: 0.011\n",
            "Training [8155/10000]: Loss: 0.016\n",
            "Training [8156/10000]: Loss: 0.013\n",
            "Training [8157/10000]: Loss: 0.011\n",
            "Training [8158/10000]: Loss: 0.018\n",
            "Training [8159/10000]: Loss: 0.011\n",
            "Training [8160/10000]: Loss: 0.017\n",
            "Training [8161/10000]: Loss: 0.009\n",
            "Training [8162/10000]: Loss: 0.011\n",
            "Training [8163/10000]: Loss: 0.015\n",
            "Training [8164/10000]: Loss: 0.009\n",
            "Training [8165/10000]: Loss: 0.009\n",
            "Training [8166/10000]: Loss: 0.010\n",
            "Training [8167/10000]: Loss: 0.010\n",
            "Training [8168/10000]: Loss: 0.011\n",
            "Training [8169/10000]: Loss: 0.009\n",
            "Training [8170/10000]: Loss: 0.013\n",
            "Training [8171/10000]: Loss: 0.008\n",
            "Training [8172/10000]: Loss: 0.014\n",
            "Training [8173/10000]: Loss: 0.010\n",
            "Training [8174/10000]: Loss: 0.013\n",
            "Training [8175/10000]: Loss: 0.014\n",
            "Training [8176/10000]: Loss: 0.009\n",
            "Training [8177/10000]: Loss: 0.010\n",
            "Training [8178/10000]: Loss: 0.013\n",
            "Training [8179/10000]: Loss: 0.015\n",
            "Training [8180/10000]: Loss: 0.009\n",
            "Training [8181/10000]: Loss: 0.014\n",
            "Training [8182/10000]: Loss: 0.006\n",
            "Training [8183/10000]: Loss: 0.017\n",
            "Training [8184/10000]: Loss: 0.012\n",
            "Training [8185/10000]: Loss: 0.014\n",
            "Training [8186/10000]: Loss: 0.015\n",
            "Training [8187/10000]: Loss: 0.015\n",
            "Training [8188/10000]: Loss: 0.009\n",
            "Training [8189/10000]: Loss: 0.011\n",
            "Training [8190/10000]: Loss: 0.010\n",
            "Training [8191/10000]: Loss: 0.010\n",
            "Training [8192/10000]: Loss: 0.008\n",
            "Training [8193/10000]: Loss: 0.011\n",
            "Training [8194/10000]: Loss: 0.011\n",
            "Training [8195/10000]: Loss: 0.008\n",
            "Training [8196/10000]: Loss: 0.017\n",
            "Training [8197/10000]: Loss: 0.014\n",
            "Training [8198/10000]: Loss: 0.008\n",
            "Training [8199/10000]: Loss: 0.011\n",
            "Training [8200/10000]: Loss: 0.010\n",
            "Test Loss: 0.062\n",
            "Training [8201/10000]: Loss: 0.009\n",
            "Training [8202/10000]: Loss: 0.015\n",
            "Training [8203/10000]: Loss: 0.007\n",
            "Training [8204/10000]: Loss: 0.010\n",
            "Training [8205/10000]: Loss: 0.012\n",
            "Training [8206/10000]: Loss: 0.007\n",
            "Training [8207/10000]: Loss: 0.008\n",
            "Training [8208/10000]: Loss: 0.008\n",
            "Training [8209/10000]: Loss: 0.010\n",
            "Training [8210/10000]: Loss: 0.011\n",
            "Training [8211/10000]: Loss: 0.009\n",
            "Training [8212/10000]: Loss: 0.013\n",
            "Training [8213/10000]: Loss: 0.015\n",
            "Training [8214/10000]: Loss: 0.011\n",
            "Training [8215/10000]: Loss: 0.009\n",
            "Training [8216/10000]: Loss: 0.011\n",
            "Training [8217/10000]: Loss: 0.007\n",
            "Training [8218/10000]: Loss: 0.012\n",
            "Training [8219/10000]: Loss: 0.009\n",
            "Training [8220/10000]: Loss: 0.012\n",
            "Training [8221/10000]: Loss: 0.011\n",
            "Training [8222/10000]: Loss: 0.012\n",
            "Training [8223/10000]: Loss: 0.016\n",
            "Training [8224/10000]: Loss: 0.010\n",
            "Training [8225/10000]: Loss: 0.011\n",
            "Training [8226/10000]: Loss: 0.008\n",
            "Training [8227/10000]: Loss: 0.014\n",
            "Training [8228/10000]: Loss: 0.011\n",
            "Training [8229/10000]: Loss: 0.011\n",
            "Training [8230/10000]: Loss: 0.013\n",
            "Training [8231/10000]: Loss: 0.012\n",
            "Training [8232/10000]: Loss: 0.007\n",
            "Training [8233/10000]: Loss: 0.014\n",
            "Training [8234/10000]: Loss: 0.011\n",
            "Training [8235/10000]: Loss: 0.012\n",
            "Training [8236/10000]: Loss: 0.014\n",
            "Training [8237/10000]: Loss: 0.011\n",
            "Training [8238/10000]: Loss: 0.009\n",
            "Training [8239/10000]: Loss: 0.013\n",
            "Training [8240/10000]: Loss: 0.011\n",
            "Training [8241/10000]: Loss: 0.013\n",
            "Training [8242/10000]: Loss: 0.008\n",
            "Training [8243/10000]: Loss: 0.008\n",
            "Training [8244/10000]: Loss: 0.011\n",
            "Training [8245/10000]: Loss: 0.009\n",
            "Training [8246/10000]: Loss: 0.010\n",
            "Training [8247/10000]: Loss: 0.012\n",
            "Training [8248/10000]: Loss: 0.009\n",
            "Training [8249/10000]: Loss: 0.010\n",
            "Training [8250/10000]: Loss: 0.013\n",
            "Training [8251/10000]: Loss: 0.013\n",
            "Training [8252/10000]: Loss: 0.010\n",
            "Training [8253/10000]: Loss: 0.009\n",
            "Training [8254/10000]: Loss: 0.010\n",
            "Training [8255/10000]: Loss: 0.012\n",
            "Training [8256/10000]: Loss: 0.013\n",
            "Training [8257/10000]: Loss: 0.017\n",
            "Training [8258/10000]: Loss: 0.013\n",
            "Training [8259/10000]: Loss: 0.013\n",
            "Training [8260/10000]: Loss: 0.011\n",
            "Training [8261/10000]: Loss: 0.012\n",
            "Training [8262/10000]: Loss: 0.011\n",
            "Training [8263/10000]: Loss: 0.014\n",
            "Training [8264/10000]: Loss: 0.010\n",
            "Training [8265/10000]: Loss: 0.014\n",
            "Training [8266/10000]: Loss: 0.010\n",
            "Training [8267/10000]: Loss: 0.014\n",
            "Training [8268/10000]: Loss: 0.010\n",
            "Training [8269/10000]: Loss: 0.009\n",
            "Training [8270/10000]: Loss: 0.011\n",
            "Training [8271/10000]: Loss: 0.009\n",
            "Training [8272/10000]: Loss: 0.014\n",
            "Training [8273/10000]: Loss: 0.013\n",
            "Training [8274/10000]: Loss: 0.013\n",
            "Training [8275/10000]: Loss: 0.010\n",
            "Training [8276/10000]: Loss: 0.014\n",
            "Training [8277/10000]: Loss: 0.011\n",
            "Training [8278/10000]: Loss: 0.014\n",
            "Training [8279/10000]: Loss: 0.010\n",
            "Training [8280/10000]: Loss: 0.016\n",
            "Training [8281/10000]: Loss: 0.015\n",
            "Training [8282/10000]: Loss: 0.015\n",
            "Training [8283/10000]: Loss: 0.009\n",
            "Training [8284/10000]: Loss: 0.008\n",
            "Training [8285/10000]: Loss: 0.009\n",
            "Training [8286/10000]: Loss: 0.010\n",
            "Training [8287/10000]: Loss: 0.007\n",
            "Training [8288/10000]: Loss: 0.006\n",
            "Training [8289/10000]: Loss: 0.005\n",
            "Training [8290/10000]: Loss: 0.005\n",
            "Training [8291/10000]: Loss: 0.009\n",
            "Training [8292/10000]: Loss: 0.010\n",
            "Training [8293/10000]: Loss: 0.012\n",
            "Training [8294/10000]: Loss: 0.009\n",
            "Training [8295/10000]: Loss: 0.012\n",
            "Training [8296/10000]: Loss: 0.007\n",
            "Training [8297/10000]: Loss: 0.012\n",
            "Training [8298/10000]: Loss: 0.007\n",
            "Training [8299/10000]: Loss: 0.007\n",
            "Training [8300/10000]: Loss: 0.014\n",
            "Test Loss: 0.061\n",
            "Training [8301/10000]: Loss: 0.013\n",
            "Training [8302/10000]: Loss: 0.010\n",
            "Training [8303/10000]: Loss: 0.004\n",
            "Training [8304/10000]: Loss: 0.010\n",
            "Training [8305/10000]: Loss: 0.015\n",
            "Training [8306/10000]: Loss: 0.013\n",
            "Training [8307/10000]: Loss: 0.006\n",
            "Training [8308/10000]: Loss: 0.008\n",
            "Training [8309/10000]: Loss: 0.010\n",
            "Training [8310/10000]: Loss: 0.008\n",
            "Training [8311/10000]: Loss: 0.014\n",
            "Training [8312/10000]: Loss: 0.013\n",
            "Training [8313/10000]: Loss: 0.013\n",
            "Training [8314/10000]: Loss: 0.015\n",
            "Training [8315/10000]: Loss: 0.009\n",
            "Training [8316/10000]: Loss: 0.010\n",
            "Training [8317/10000]: Loss: 0.008\n",
            "Training [8318/10000]: Loss: 0.008\n",
            "Training [8319/10000]: Loss: 0.016\n",
            "Training [8320/10000]: Loss: 0.013\n",
            "Training [8321/10000]: Loss: 0.011\n",
            "Training [8322/10000]: Loss: 0.009\n",
            "Training [8323/10000]: Loss: 0.015\n",
            "Training [8324/10000]: Loss: 0.009\n",
            "Training [8325/10000]: Loss: 0.014\n",
            "Training [8326/10000]: Loss: 0.009\n",
            "Training [8327/10000]: Loss: 0.009\n",
            "Training [8328/10000]: Loss: 0.011\n",
            "Training [8329/10000]: Loss: 0.010\n",
            "Training [8330/10000]: Loss: 0.012\n",
            "Training [8331/10000]: Loss: 0.009\n",
            "Training [8332/10000]: Loss: 0.008\n",
            "Training [8333/10000]: Loss: 0.012\n",
            "Training [8334/10000]: Loss: 0.009\n",
            "Training [8335/10000]: Loss: 0.010\n",
            "Training [8336/10000]: Loss: 0.008\n",
            "Training [8337/10000]: Loss: 0.009\n",
            "Training [8338/10000]: Loss: 0.014\n",
            "Training [8339/10000]: Loss: 0.009\n",
            "Training [8340/10000]: Loss: 0.011\n",
            "Training [8341/10000]: Loss: 0.011\n",
            "Training [8342/10000]: Loss: 0.008\n",
            "Training [8343/10000]: Loss: 0.012\n",
            "Training [8344/10000]: Loss: 0.008\n",
            "Training [8345/10000]: Loss: 0.010\n",
            "Training [8346/10000]: Loss: 0.012\n",
            "Training [8347/10000]: Loss: 0.012\n",
            "Training [8348/10000]: Loss: 0.011\n",
            "Training [8349/10000]: Loss: 0.011\n",
            "Training [8350/10000]: Loss: 0.007\n",
            "Training [8351/10000]: Loss: 0.007\n",
            "Training [8352/10000]: Loss: 0.013\n",
            "Training [8353/10000]: Loss: 0.012\n",
            "Training [8354/10000]: Loss: 0.010\n",
            "Training [8355/10000]: Loss: 0.011\n",
            "Training [8356/10000]: Loss: 0.008\n",
            "Training [8357/10000]: Loss: 0.010\n",
            "Training [8358/10000]: Loss: 0.011\n",
            "Training [8359/10000]: Loss: 0.012\n",
            "Training [8360/10000]: Loss: 0.013\n",
            "Training [8361/10000]: Loss: 0.012\n",
            "Training [8362/10000]: Loss: 0.009\n",
            "Training [8363/10000]: Loss: 0.008\n",
            "Training [8364/10000]: Loss: 0.011\n",
            "Training [8365/10000]: Loss: 0.012\n",
            "Training [8366/10000]: Loss: 0.014\n",
            "Training [8367/10000]: Loss: 0.009\n",
            "Training [8368/10000]: Loss: 0.010\n",
            "Training [8369/10000]: Loss: 0.007\n",
            "Training [8370/10000]: Loss: 0.007\n",
            "Training [8371/10000]: Loss: 0.014\n",
            "Training [8372/10000]: Loss: 0.012\n",
            "Training [8373/10000]: Loss: 0.010\n",
            "Training [8374/10000]: Loss: 0.010\n",
            "Training [8375/10000]: Loss: 0.015\n",
            "Training [8376/10000]: Loss: 0.012\n",
            "Training [8377/10000]: Loss: 0.011\n",
            "Training [8378/10000]: Loss: 0.010\n",
            "Training [8379/10000]: Loss: 0.011\n",
            "Training [8380/10000]: Loss: 0.012\n",
            "Training [8381/10000]: Loss: 0.012\n",
            "Training [8382/10000]: Loss: 0.011\n",
            "Training [8383/10000]: Loss: 0.008\n",
            "Training [8384/10000]: Loss: 0.007\n",
            "Training [8385/10000]: Loss: 0.016\n",
            "Training [8386/10000]: Loss: 0.015\n",
            "Training [8387/10000]: Loss: 0.011\n",
            "Training [8388/10000]: Loss: 0.017\n",
            "Training [8389/10000]: Loss: 0.012\n",
            "Training [8390/10000]: Loss: 0.012\n",
            "Training [8391/10000]: Loss: 0.012\n",
            "Training [8392/10000]: Loss: 0.010\n",
            "Training [8393/10000]: Loss: 0.009\n",
            "Training [8394/10000]: Loss: 0.010\n",
            "Training [8395/10000]: Loss: 0.011\n",
            "Training [8396/10000]: Loss: 0.007\n",
            "Training [8397/10000]: Loss: 0.013\n",
            "Training [8398/10000]: Loss: 0.009\n",
            "Training [8399/10000]: Loss: 0.010\n",
            "Training [8400/10000]: Loss: 0.009\n",
            "Test Loss: 0.060\n",
            "Training [8401/10000]: Loss: 0.010\n",
            "Training [8402/10000]: Loss: 0.011\n",
            "Training [8403/10000]: Loss: 0.018\n",
            "Training [8404/10000]: Loss: 0.010\n",
            "Training [8405/10000]: Loss: 0.010\n",
            "Training [8406/10000]: Loss: 0.007\n",
            "Training [8407/10000]: Loss: 0.013\n",
            "Training [8408/10000]: Loss: 0.015\n",
            "Training [8409/10000]: Loss: 0.011\n",
            "Training [8410/10000]: Loss: 0.013\n",
            "Training [8411/10000]: Loss: 0.013\n",
            "Training [8412/10000]: Loss: 0.007\n",
            "Training [8413/10000]: Loss: 0.008\n",
            "Training [8414/10000]: Loss: 0.014\n",
            "Training [8415/10000]: Loss: 0.010\n",
            "Training [8416/10000]: Loss: 0.007\n",
            "Training [8417/10000]: Loss: 0.008\n",
            "Training [8418/10000]: Loss: 0.009\n",
            "Training [8419/10000]: Loss: 0.011\n",
            "Training [8420/10000]: Loss: 0.008\n",
            "Training [8421/10000]: Loss: 0.013\n",
            "Training [8422/10000]: Loss: 0.010\n",
            "Training [8423/10000]: Loss: 0.012\n",
            "Training [8424/10000]: Loss: 0.013\n",
            "Training [8425/10000]: Loss: 0.010\n",
            "Training [8426/10000]: Loss: 0.006\n",
            "Training [8427/10000]: Loss: 0.013\n",
            "Training [8428/10000]: Loss: 0.014\n",
            "Training [8429/10000]: Loss: 0.013\n",
            "Training [8430/10000]: Loss: 0.008\n",
            "Training [8431/10000]: Loss: 0.017\n",
            "Training [8432/10000]: Loss: 0.010\n",
            "Training [8433/10000]: Loss: 0.012\n",
            "Training [8434/10000]: Loss: 0.010\n",
            "Training [8435/10000]: Loss: 0.010\n",
            "Training [8436/10000]: Loss: 0.011\n",
            "Training [8437/10000]: Loss: 0.008\n",
            "Training [8438/10000]: Loss: 0.009\n",
            "Training [8439/10000]: Loss: 0.015\n",
            "Training [8440/10000]: Loss: 0.007\n",
            "Training [8441/10000]: Loss: 0.010\n",
            "Training [8442/10000]: Loss: 0.011\n",
            "Training [8443/10000]: Loss: 0.010\n",
            "Training [8444/10000]: Loss: 0.009\n",
            "Training [8445/10000]: Loss: 0.012\n",
            "Training [8446/10000]: Loss: 0.009\n",
            "Training [8447/10000]: Loss: 0.008\n",
            "Training [8448/10000]: Loss: 0.009\n",
            "Training [8449/10000]: Loss: 0.017\n",
            "Training [8450/10000]: Loss: 0.010\n",
            "Training [8451/10000]: Loss: 0.006\n",
            "Training [8452/10000]: Loss: 0.010\n",
            "Training [8453/10000]: Loss: 0.009\n",
            "Training [8454/10000]: Loss: 0.012\n",
            "Training [8455/10000]: Loss: 0.012\n",
            "Training [8456/10000]: Loss: 0.009\n",
            "Training [8457/10000]: Loss: 0.011\n",
            "Training [8458/10000]: Loss: 0.007\n",
            "Training [8459/10000]: Loss: 0.014\n",
            "Training [8460/10000]: Loss: 0.010\n",
            "Training [8461/10000]: Loss: 0.008\n",
            "Training [8462/10000]: Loss: 0.015\n",
            "Training [8463/10000]: Loss: 0.015\n",
            "Training [8464/10000]: Loss: 0.013\n",
            "Training [8465/10000]: Loss: 0.012\n",
            "Training [8466/10000]: Loss: 0.015\n",
            "Training [8467/10000]: Loss: 0.014\n",
            "Training [8468/10000]: Loss: 0.011\n",
            "Training [8469/10000]: Loss: 0.007\n",
            "Training [8470/10000]: Loss: 0.006\n",
            "Training [8471/10000]: Loss: 0.005\n",
            "Training [8472/10000]: Loss: 0.010\n",
            "Training [8473/10000]: Loss: 0.011\n",
            "Training [8474/10000]: Loss: 0.007\n",
            "Training [8475/10000]: Loss: 0.012\n",
            "Training [8476/10000]: Loss: 0.011\n",
            "Training [8477/10000]: Loss: 0.012\n",
            "Training [8478/10000]: Loss: 0.013\n",
            "Training [8479/10000]: Loss: 0.011\n",
            "Training [8480/10000]: Loss: 0.011\n",
            "Training [8481/10000]: Loss: 0.012\n",
            "Training [8482/10000]: Loss: 0.008\n",
            "Training [8483/10000]: Loss: 0.013\n",
            "Training [8484/10000]: Loss: 0.016\n",
            "Training [8485/10000]: Loss: 0.008\n",
            "Training [8486/10000]: Loss: 0.007\n",
            "Training [8487/10000]: Loss: 0.008\n",
            "Training [8488/10000]: Loss: 0.009\n",
            "Training [8489/10000]: Loss: 0.009\n",
            "Training [8490/10000]: Loss: 0.014\n",
            "Training [8491/10000]: Loss: 0.006\n",
            "Training [8492/10000]: Loss: 0.010\n",
            "Training [8493/10000]: Loss: 0.010\n",
            "Training [8494/10000]: Loss: 0.007\n",
            "Training [8495/10000]: Loss: 0.008\n",
            "Training [8496/10000]: Loss: 0.006\n",
            "Training [8497/10000]: Loss: 0.010\n",
            "Training [8498/10000]: Loss: 0.011\n",
            "Training [8499/10000]: Loss: 0.011\n",
            "Training [8500/10000]: Loss: 0.011\n",
            "Test Loss: 0.059\n",
            "Training [8501/10000]: Loss: 0.011\n",
            "Training [8502/10000]: Loss: 0.009\n",
            "Training [8503/10000]: Loss: 0.009\n",
            "Training [8504/10000]: Loss: 0.008\n",
            "Training [8505/10000]: Loss: 0.010\n",
            "Training [8506/10000]: Loss: 0.011\n",
            "Training [8507/10000]: Loss: 0.009\n",
            "Training [8508/10000]: Loss: 0.011\n",
            "Training [8509/10000]: Loss: 0.012\n",
            "Training [8510/10000]: Loss: 0.009\n",
            "Training [8511/10000]: Loss: 0.007\n",
            "Training [8512/10000]: Loss: 0.012\n",
            "Training [8513/10000]: Loss: 0.007\n",
            "Training [8514/10000]: Loss: 0.007\n",
            "Training [8515/10000]: Loss: 0.009\n",
            "Training [8516/10000]: Loss: 0.009\n",
            "Training [8517/10000]: Loss: 0.008\n",
            "Training [8518/10000]: Loss: 0.007\n",
            "Training [8519/10000]: Loss: 0.009\n",
            "Training [8520/10000]: Loss: 0.009\n",
            "Training [8521/10000]: Loss: 0.010\n",
            "Training [8522/10000]: Loss: 0.012\n",
            "Training [8523/10000]: Loss: 0.012\n",
            "Training [8524/10000]: Loss: 0.013\n",
            "Training [8525/10000]: Loss: 0.011\n",
            "Training [8526/10000]: Loss: 0.011\n",
            "Training [8527/10000]: Loss: 0.013\n",
            "Training [8528/10000]: Loss: 0.011\n",
            "Training [8529/10000]: Loss: 0.014\n",
            "Training [8530/10000]: Loss: 0.010\n",
            "Training [8531/10000]: Loss: 0.010\n",
            "Training [8532/10000]: Loss: 0.009\n",
            "Training [8533/10000]: Loss: 0.008\n",
            "Training [8534/10000]: Loss: 0.010\n",
            "Training [8535/10000]: Loss: 0.013\n",
            "Training [8536/10000]: Loss: 0.012\n",
            "Training [8537/10000]: Loss: 0.008\n",
            "Training [8538/10000]: Loss: 0.010\n",
            "Training [8539/10000]: Loss: 0.014\n",
            "Training [8540/10000]: Loss: 0.006\n",
            "Training [8541/10000]: Loss: 0.011\n",
            "Training [8542/10000]: Loss: 0.012\n",
            "Training [8543/10000]: Loss: 0.008\n",
            "Training [8544/10000]: Loss: 0.011\n",
            "Training [8545/10000]: Loss: 0.011\n",
            "Training [8546/10000]: Loss: 0.010\n",
            "Training [8547/10000]: Loss: 0.014\n",
            "Training [8548/10000]: Loss: 0.010\n",
            "Training [8549/10000]: Loss: 0.013\n",
            "Training [8550/10000]: Loss: 0.009\n",
            "Training [8551/10000]: Loss: 0.011\n",
            "Training [8552/10000]: Loss: 0.011\n",
            "Training [8553/10000]: Loss: 0.015\n",
            "Training [8554/10000]: Loss: 0.015\n",
            "Training [8555/10000]: Loss: 0.014\n",
            "Training [8556/10000]: Loss: 0.005\n",
            "Training [8557/10000]: Loss: 0.011\n",
            "Training [8558/10000]: Loss: 0.009\n",
            "Training [8559/10000]: Loss: 0.009\n",
            "Training [8560/10000]: Loss: 0.012\n",
            "Training [8561/10000]: Loss: 0.008\n",
            "Training [8562/10000]: Loss: 0.016\n",
            "Training [8563/10000]: Loss: 0.010\n",
            "Training [8564/10000]: Loss: 0.012\n",
            "Training [8565/10000]: Loss: 0.008\n",
            "Training [8566/10000]: Loss: 0.009\n",
            "Training [8567/10000]: Loss: 0.010\n",
            "Training [8568/10000]: Loss: 0.014\n",
            "Training [8569/10000]: Loss: 0.015\n",
            "Training [8570/10000]: Loss: 0.010\n",
            "Training [8571/10000]: Loss: 0.011\n",
            "Training [8572/10000]: Loss: 0.010\n",
            "Training [8573/10000]: Loss: 0.010\n",
            "Training [8574/10000]: Loss: 0.008\n",
            "Training [8575/10000]: Loss: 0.013\n",
            "Training [8576/10000]: Loss: 0.010\n",
            "Training [8577/10000]: Loss: 0.008\n",
            "Training [8578/10000]: Loss: 0.006\n",
            "Training [8579/10000]: Loss: 0.011\n",
            "Training [8580/10000]: Loss: 0.009\n",
            "Training [8581/10000]: Loss: 0.009\n",
            "Training [8582/10000]: Loss: 0.011\n",
            "Training [8583/10000]: Loss: 0.012\n",
            "Training [8584/10000]: Loss: 0.008\n",
            "Training [8585/10000]: Loss: 0.010\n",
            "Training [8586/10000]: Loss: 0.006\n",
            "Training [8587/10000]: Loss: 0.010\n",
            "Training [8588/10000]: Loss: 0.009\n",
            "Training [8589/10000]: Loss: 0.006\n",
            "Training [8590/10000]: Loss: 0.007\n",
            "Training [8591/10000]: Loss: 0.014\n",
            "Training [8592/10000]: Loss: 0.008\n",
            "Training [8593/10000]: Loss: 0.013\n",
            "Training [8594/10000]: Loss: 0.005\n",
            "Training [8595/10000]: Loss: 0.014\n",
            "Training [8596/10000]: Loss: 0.010\n",
            "Training [8597/10000]: Loss: 0.011\n",
            "Training [8598/10000]: Loss: 0.012\n",
            "Training [8599/10000]: Loss: 0.009\n",
            "Training [8600/10000]: Loss: 0.011\n",
            "Test Loss: 0.060\n",
            "Training [8601/10000]: Loss: 0.005\n",
            "Training [8602/10000]: Loss: 0.012\n",
            "Training [8603/10000]: Loss: 0.014\n",
            "Training [8604/10000]: Loss: 0.008\n",
            "Training [8605/10000]: Loss: 0.008\n",
            "Training [8606/10000]: Loss: 0.008\n",
            "Training [8607/10000]: Loss: 0.009\n",
            "Training [8608/10000]: Loss: 0.016\n",
            "Training [8609/10000]: Loss: 0.007\n",
            "Training [8610/10000]: Loss: 0.009\n",
            "Training [8611/10000]: Loss: 0.009\n",
            "Training [8612/10000]: Loss: 0.014\n",
            "Training [8613/10000]: Loss: 0.008\n",
            "Training [8614/10000]: Loss: 0.010\n",
            "Training [8615/10000]: Loss: 0.008\n",
            "Training [8616/10000]: Loss: 0.012\n",
            "Training [8617/10000]: Loss: 0.010\n",
            "Training [8618/10000]: Loss: 0.011\n",
            "Training [8619/10000]: Loss: 0.011\n",
            "Training [8620/10000]: Loss: 0.016\n",
            "Training [8621/10000]: Loss: 0.012\n",
            "Training [8622/10000]: Loss: 0.013\n",
            "Training [8623/10000]: Loss: 0.009\n",
            "Training [8624/10000]: Loss: 0.012\n",
            "Training [8625/10000]: Loss: 0.012\n",
            "Training [8626/10000]: Loss: 0.011\n",
            "Training [8627/10000]: Loss: 0.010\n",
            "Training [8628/10000]: Loss: 0.008\n",
            "Training [8629/10000]: Loss: 0.006\n",
            "Training [8630/10000]: Loss: 0.013\n",
            "Training [8631/10000]: Loss: 0.009\n",
            "Training [8632/10000]: Loss: 0.009\n",
            "Training [8633/10000]: Loss: 0.013\n",
            "Training [8634/10000]: Loss: 0.013\n",
            "Training [8635/10000]: Loss: 0.011\n",
            "Training [8636/10000]: Loss: 0.012\n",
            "Training [8637/10000]: Loss: 0.011\n",
            "Training [8638/10000]: Loss: 0.008\n",
            "Training [8639/10000]: Loss: 0.016\n",
            "Training [8640/10000]: Loss: 0.014\n",
            "Training [8641/10000]: Loss: 0.010\n",
            "Training [8642/10000]: Loss: 0.010\n",
            "Training [8643/10000]: Loss: 0.017\n",
            "Training [8644/10000]: Loss: 0.010\n",
            "Training [8645/10000]: Loss: 0.011\n",
            "Training [8646/10000]: Loss: 0.009\n",
            "Training [8647/10000]: Loss: 0.005\n",
            "Training [8648/10000]: Loss: 0.010\n",
            "Training [8649/10000]: Loss: 0.013\n",
            "Training [8650/10000]: Loss: 0.012\n",
            "Training [8651/10000]: Loss: 0.009\n",
            "Training [8652/10000]: Loss: 0.008\n",
            "Training [8653/10000]: Loss: 0.012\n",
            "Training [8654/10000]: Loss: 0.006\n",
            "Training [8655/10000]: Loss: 0.013\n",
            "Training [8656/10000]: Loss: 0.010\n",
            "Training [8657/10000]: Loss: 0.007\n",
            "Training [8658/10000]: Loss: 0.013\n",
            "Training [8659/10000]: Loss: 0.014\n",
            "Training [8660/10000]: Loss: 0.011\n",
            "Training [8661/10000]: Loss: 0.009\n",
            "Training [8662/10000]: Loss: 0.010\n",
            "Training [8663/10000]: Loss: 0.011\n",
            "Training [8664/10000]: Loss: 0.011\n",
            "Training [8665/10000]: Loss: 0.011\n",
            "Training [8666/10000]: Loss: 0.008\n",
            "Training [8667/10000]: Loss: 0.007\n",
            "Training [8668/10000]: Loss: 0.010\n",
            "Training [8669/10000]: Loss: 0.012\n",
            "Training [8670/10000]: Loss: 0.017\n",
            "Training [8671/10000]: Loss: 0.011\n",
            "Training [8672/10000]: Loss: 0.009\n",
            "Training [8673/10000]: Loss: 0.010\n",
            "Training [8674/10000]: Loss: 0.008\n",
            "Training [8675/10000]: Loss: 0.008\n",
            "Training [8676/10000]: Loss: 0.010\n",
            "Training [8677/10000]: Loss: 0.008\n",
            "Training [8678/10000]: Loss: 0.009\n",
            "Training [8679/10000]: Loss: 0.013\n",
            "Training [8680/10000]: Loss: 0.011\n",
            "Training [8681/10000]: Loss: 0.011\n",
            "Training [8682/10000]: Loss: 0.011\n",
            "Training [8683/10000]: Loss: 0.008\n",
            "Training [8684/10000]: Loss: 0.010\n",
            "Training [8685/10000]: Loss: 0.012\n",
            "Training [8686/10000]: Loss: 0.012\n",
            "Training [8687/10000]: Loss: 0.009\n",
            "Training [8688/10000]: Loss: 0.013\n",
            "Training [8689/10000]: Loss: 0.013\n",
            "Training [8690/10000]: Loss: 0.016\n",
            "Training [8691/10000]: Loss: 0.009\n",
            "Training [8692/10000]: Loss: 0.011\n",
            "Training [8693/10000]: Loss: 0.008\n",
            "Training [8694/10000]: Loss: 0.008\n",
            "Training [8695/10000]: Loss: 0.011\n",
            "Training [8696/10000]: Loss: 0.012\n",
            "Training [8697/10000]: Loss: 0.014\n",
            "Training [8698/10000]: Loss: 0.008\n",
            "Training [8699/10000]: Loss: 0.009\n",
            "Training [8700/10000]: Loss: 0.012\n",
            "Test Loss: 0.059\n",
            "Training [8701/10000]: Loss: 0.015\n",
            "Training [8702/10000]: Loss: 0.009\n",
            "Training [8703/10000]: Loss: 0.016\n",
            "Training [8704/10000]: Loss: 0.015\n",
            "Training [8705/10000]: Loss: 0.011\n",
            "Training [8706/10000]: Loss: 0.013\n",
            "Training [8707/10000]: Loss: 0.011\n",
            "Training [8708/10000]: Loss: 0.015\n",
            "Training [8709/10000]: Loss: 0.010\n",
            "Training [8710/10000]: Loss: 0.008\n",
            "Training [8711/10000]: Loss: 0.010\n",
            "Training [8712/10000]: Loss: 0.012\n",
            "Training [8713/10000]: Loss: 0.009\n",
            "Training [8714/10000]: Loss: 0.008\n",
            "Training [8715/10000]: Loss: 0.010\n",
            "Training [8716/10000]: Loss: 0.014\n",
            "Training [8717/10000]: Loss: 0.008\n",
            "Training [8718/10000]: Loss: 0.008\n",
            "Training [8719/10000]: Loss: 0.015\n",
            "Training [8720/10000]: Loss: 0.008\n",
            "Training [8721/10000]: Loss: 0.011\n",
            "Training [8722/10000]: Loss: 0.016\n",
            "Training [8723/10000]: Loss: 0.010\n",
            "Training [8724/10000]: Loss: 0.011\n",
            "Training [8725/10000]: Loss: 0.010\n",
            "Training [8726/10000]: Loss: 0.009\n",
            "Training [8727/10000]: Loss: 0.014\n",
            "Training [8728/10000]: Loss: 0.007\n",
            "Training [8729/10000]: Loss: 0.011\n",
            "Training [8730/10000]: Loss: 0.010\n",
            "Training [8731/10000]: Loss: 0.012\n",
            "Training [8732/10000]: Loss: 0.013\n",
            "Training [8733/10000]: Loss: 0.011\n",
            "Training [8734/10000]: Loss: 0.011\n",
            "Training [8735/10000]: Loss: 0.013\n",
            "Training [8736/10000]: Loss: 0.012\n",
            "Training [8737/10000]: Loss: 0.011\n",
            "Training [8738/10000]: Loss: 0.010\n",
            "Training [8739/10000]: Loss: 0.011\n",
            "Training [8740/10000]: Loss: 0.013\n",
            "Training [8741/10000]: Loss: 0.007\n",
            "Training [8742/10000]: Loss: 0.013\n",
            "Training [8743/10000]: Loss: 0.014\n",
            "Training [8744/10000]: Loss: 0.006\n",
            "Training [8745/10000]: Loss: 0.009\n",
            "Training [8746/10000]: Loss: 0.013\n",
            "Training [8747/10000]: Loss: 0.011\n",
            "Training [8748/10000]: Loss: 0.010\n",
            "Training [8749/10000]: Loss: 0.011\n",
            "Training [8750/10000]: Loss: 0.011\n",
            "Training [8751/10000]: Loss: 0.006\n",
            "Training [8752/10000]: Loss: 0.012\n",
            "Training [8753/10000]: Loss: 0.006\n",
            "Training [8754/10000]: Loss: 0.013\n",
            "Training [8755/10000]: Loss: 0.009\n",
            "Training [8756/10000]: Loss: 0.014\n",
            "Training [8757/10000]: Loss: 0.012\n",
            "Training [8758/10000]: Loss: 0.016\n",
            "Training [8759/10000]: Loss: 0.009\n",
            "Training [8760/10000]: Loss: 0.007\n",
            "Training [8761/10000]: Loss: 0.008\n",
            "Training [8762/10000]: Loss: 0.009\n",
            "Training [8763/10000]: Loss: 0.011\n",
            "Training [8764/10000]: Loss: 0.010\n",
            "Training [8765/10000]: Loss: 0.012\n",
            "Training [8766/10000]: Loss: 0.013\n",
            "Training [8767/10000]: Loss: 0.012\n",
            "Training [8768/10000]: Loss: 0.010\n",
            "Training [8769/10000]: Loss: 0.008\n",
            "Training [8770/10000]: Loss: 0.009\n",
            "Training [8771/10000]: Loss: 0.006\n",
            "Training [8772/10000]: Loss: 0.010\n",
            "Training [8773/10000]: Loss: 0.010\n",
            "Training [8774/10000]: Loss: 0.012\n",
            "Training [8775/10000]: Loss: 0.014\n",
            "Training [8776/10000]: Loss: 0.010\n",
            "Training [8777/10000]: Loss: 0.008\n",
            "Training [8778/10000]: Loss: 0.006\n",
            "Training [8779/10000]: Loss: 0.016\n",
            "Training [8780/10000]: Loss: 0.013\n",
            "Training [8781/10000]: Loss: 0.011\n",
            "Training [8782/10000]: Loss: 0.010\n",
            "Training [8783/10000]: Loss: 0.011\n",
            "Training [8784/10000]: Loss: 0.017\n",
            "Training [8785/10000]: Loss: 0.007\n",
            "Training [8786/10000]: Loss: 0.012\n",
            "Training [8787/10000]: Loss: 0.011\n",
            "Training [8788/10000]: Loss: 0.012\n",
            "Training [8789/10000]: Loss: 0.011\n",
            "Training [8790/10000]: Loss: 0.009\n",
            "Training [8791/10000]: Loss: 0.009\n",
            "Training [8792/10000]: Loss: 0.009\n",
            "Training [8793/10000]: Loss: 0.016\n",
            "Training [8794/10000]: Loss: 0.013\n",
            "Training [8795/10000]: Loss: 0.007\n",
            "Training [8796/10000]: Loss: 0.012\n",
            "Training [8797/10000]: Loss: 0.013\n",
            "Training [8798/10000]: Loss: 0.013\n",
            "Training [8799/10000]: Loss: 0.014\n",
            "Training [8800/10000]: Loss: 0.010\n",
            "Test Loss: 0.057\n",
            "Training [8801/10000]: Loss: 0.007\n",
            "Training [8802/10000]: Loss: 0.009\n",
            "Training [8803/10000]: Loss: 0.012\n",
            "Training [8804/10000]: Loss: 0.010\n",
            "Training [8805/10000]: Loss: 0.010\n",
            "Training [8806/10000]: Loss: 0.008\n",
            "Training [8807/10000]: Loss: 0.011\n",
            "Training [8808/10000]: Loss: 0.011\n",
            "Training [8809/10000]: Loss: 0.006\n",
            "Training [8810/10000]: Loss: 0.013\n",
            "Training [8811/10000]: Loss: 0.013\n",
            "Training [8812/10000]: Loss: 0.014\n",
            "Training [8813/10000]: Loss: 0.011\n",
            "Training [8814/10000]: Loss: 0.008\n",
            "Training [8815/10000]: Loss: 0.013\n",
            "Training [8816/10000]: Loss: 0.012\n",
            "Training [8817/10000]: Loss: 0.010\n",
            "Training [8818/10000]: Loss: 0.010\n",
            "Training [8819/10000]: Loss: 0.015\n",
            "Training [8820/10000]: Loss: 0.012\n",
            "Training [8821/10000]: Loss: 0.012\n",
            "Training [8822/10000]: Loss: 0.010\n",
            "Training [8823/10000]: Loss: 0.006\n",
            "Training [8824/10000]: Loss: 0.013\n",
            "Training [8825/10000]: Loss: 0.011\n",
            "Training [8826/10000]: Loss: 0.011\n",
            "Training [8827/10000]: Loss: 0.006\n",
            "Training [8828/10000]: Loss: 0.010\n",
            "Training [8829/10000]: Loss: 0.010\n",
            "Training [8830/10000]: Loss: 0.006\n",
            "Training [8831/10000]: Loss: 0.011\n",
            "Training [8832/10000]: Loss: 0.014\n",
            "Training [8833/10000]: Loss: 0.013\n",
            "Training [8834/10000]: Loss: 0.014\n",
            "Training [8835/10000]: Loss: 0.015\n",
            "Training [8836/10000]: Loss: 0.014\n",
            "Training [8837/10000]: Loss: 0.011\n",
            "Training [8838/10000]: Loss: 0.016\n",
            "Training [8839/10000]: Loss: 0.010\n",
            "Training [8840/10000]: Loss: 0.009\n",
            "Training [8841/10000]: Loss: 0.008\n",
            "Training [8842/10000]: Loss: 0.007\n",
            "Training [8843/10000]: Loss: 0.012\n",
            "Training [8844/10000]: Loss: 0.007\n",
            "Training [8845/10000]: Loss: 0.009\n",
            "Training [8846/10000]: Loss: 0.007\n",
            "Training [8847/10000]: Loss: 0.006\n",
            "Training [8848/10000]: Loss: 0.009\n",
            "Training [8849/10000]: Loss: 0.010\n",
            "Training [8850/10000]: Loss: 0.006\n",
            "Training [8851/10000]: Loss: 0.011\n",
            "Training [8852/10000]: Loss: 0.010\n",
            "Training [8853/10000]: Loss: 0.006\n",
            "Training [8854/10000]: Loss: 0.005\n",
            "Training [8855/10000]: Loss: 0.009\n",
            "Training [8856/10000]: Loss: 0.010\n",
            "Training [8857/10000]: Loss: 0.011\n",
            "Training [8858/10000]: Loss: 0.009\n",
            "Training [8859/10000]: Loss: 0.010\n",
            "Training [8860/10000]: Loss: 0.008\n",
            "Training [8861/10000]: Loss: 0.009\n",
            "Training [8862/10000]: Loss: 0.015\n",
            "Training [8863/10000]: Loss: 0.013\n",
            "Training [8864/10000]: Loss: 0.010\n",
            "Training [8865/10000]: Loss: 0.011\n",
            "Training [8866/10000]: Loss: 0.014\n",
            "Training [8867/10000]: Loss: 0.009\n",
            "Training [8868/10000]: Loss: 0.010\n",
            "Training [8869/10000]: Loss: 0.014\n",
            "Training [8870/10000]: Loss: 0.007\n",
            "Training [8871/10000]: Loss: 0.008\n",
            "Training [8872/10000]: Loss: 0.007\n",
            "Training [8873/10000]: Loss: 0.011\n",
            "Training [8874/10000]: Loss: 0.012\n",
            "Training [8875/10000]: Loss: 0.009\n",
            "Training [8876/10000]: Loss: 0.008\n",
            "Training [8877/10000]: Loss: 0.008\n",
            "Training [8878/10000]: Loss: 0.012\n",
            "Training [8879/10000]: Loss: 0.009\n",
            "Training [8880/10000]: Loss: 0.010\n",
            "Training [8881/10000]: Loss: 0.015\n",
            "Training [8882/10000]: Loss: 0.008\n",
            "Training [8883/10000]: Loss: 0.010\n",
            "Training [8884/10000]: Loss: 0.009\n",
            "Training [8885/10000]: Loss: 0.010\n",
            "Training [8886/10000]: Loss: 0.007\n",
            "Training [8887/10000]: Loss: 0.011\n",
            "Training [8888/10000]: Loss: 0.014\n",
            "Training [8889/10000]: Loss: 0.012\n",
            "Training [8890/10000]: Loss: 0.013\n",
            "Training [8891/10000]: Loss: 0.012\n",
            "Training [8892/10000]: Loss: 0.012\n",
            "Training [8893/10000]: Loss: 0.014\n",
            "Training [8894/10000]: Loss: 0.010\n",
            "Training [8895/10000]: Loss: 0.009\n",
            "Training [8896/10000]: Loss: 0.009\n",
            "Training [8897/10000]: Loss: 0.011\n",
            "Training [8898/10000]: Loss: 0.011\n",
            "Training [8899/10000]: Loss: 0.009\n",
            "Training [8900/10000]: Loss: 0.008\n",
            "Test Loss: 0.063\n",
            "Training [8901/10000]: Loss: 0.010\n",
            "Training [8902/10000]: Loss: 0.013\n",
            "Training [8903/10000]: Loss: 0.008\n",
            "Training [8904/10000]: Loss: 0.006\n",
            "Training [8905/10000]: Loss: 0.013\n",
            "Training [8906/10000]: Loss: 0.009\n",
            "Training [8907/10000]: Loss: 0.005\n",
            "Training [8908/10000]: Loss: 0.007\n",
            "Training [8909/10000]: Loss: 0.009\n",
            "Training [8910/10000]: Loss: 0.006\n",
            "Training [8911/10000]: Loss: 0.011\n",
            "Training [8912/10000]: Loss: 0.009\n",
            "Training [8913/10000]: Loss: 0.011\n",
            "Training [8914/10000]: Loss: 0.009\n",
            "Training [8915/10000]: Loss: 0.005\n",
            "Training [8916/10000]: Loss: 0.016\n",
            "Training [8917/10000]: Loss: 0.009\n",
            "Training [8918/10000]: Loss: 0.010\n",
            "Training [8919/10000]: Loss: 0.010\n",
            "Training [8920/10000]: Loss: 0.011\n",
            "Training [8921/10000]: Loss: 0.016\n",
            "Training [8922/10000]: Loss: 0.013\n",
            "Training [8923/10000]: Loss: 0.008\n",
            "Training [8924/10000]: Loss: 0.011\n",
            "Training [8925/10000]: Loss: 0.010\n",
            "Training [8926/10000]: Loss: 0.008\n",
            "Training [8927/10000]: Loss: 0.011\n",
            "Training [8928/10000]: Loss: 0.010\n",
            "Training [8929/10000]: Loss: 0.011\n",
            "Training [8930/10000]: Loss: 0.010\n",
            "Training [8931/10000]: Loss: 0.011\n",
            "Training [8932/10000]: Loss: 0.010\n",
            "Training [8933/10000]: Loss: 0.008\n",
            "Training [8934/10000]: Loss: 0.010\n",
            "Training [8935/10000]: Loss: 0.012\n",
            "Training [8936/10000]: Loss: 0.010\n",
            "Training [8937/10000]: Loss: 0.011\n",
            "Training [8938/10000]: Loss: 0.010\n",
            "Training [8939/10000]: Loss: 0.008\n",
            "Training [8940/10000]: Loss: 0.013\n",
            "Training [8941/10000]: Loss: 0.011\n",
            "Training [8942/10000]: Loss: 0.010\n",
            "Training [8943/10000]: Loss: 0.009\n",
            "Training [8944/10000]: Loss: 0.005\n",
            "Training [8945/10000]: Loss: 0.005\n",
            "Training [8946/10000]: Loss: 0.005\n",
            "Training [8947/10000]: Loss: 0.009\n",
            "Training [8948/10000]: Loss: 0.012\n",
            "Training [8949/10000]: Loss: 0.012\n",
            "Training [8950/10000]: Loss: 0.009\n",
            "Training [8951/10000]: Loss: 0.015\n",
            "Training [8952/10000]: Loss: 0.008\n",
            "Training [8953/10000]: Loss: 0.010\n",
            "Training [8954/10000]: Loss: 0.011\n",
            "Training [8955/10000]: Loss: 0.011\n",
            "Training [8956/10000]: Loss: 0.009\n",
            "Training [8957/10000]: Loss: 0.008\n",
            "Training [8958/10000]: Loss: 0.009\n",
            "Training [8959/10000]: Loss: 0.010\n",
            "Training [8960/10000]: Loss: 0.010\n",
            "Training [8961/10000]: Loss: 0.006\n",
            "Training [8962/10000]: Loss: 0.009\n",
            "Training [8963/10000]: Loss: 0.011\n",
            "Training [8964/10000]: Loss: 0.009\n",
            "Training [8965/10000]: Loss: 0.013\n",
            "Training [8966/10000]: Loss: 0.009\n",
            "Training [8967/10000]: Loss: 0.009\n",
            "Training [8968/10000]: Loss: 0.014\n",
            "Training [8969/10000]: Loss: 0.009\n",
            "Training [8970/10000]: Loss: 0.013\n",
            "Training [8971/10000]: Loss: 0.013\n",
            "Training [8972/10000]: Loss: 0.014\n",
            "Training [8973/10000]: Loss: 0.008\n",
            "Training [8974/10000]: Loss: 0.008\n",
            "Training [8975/10000]: Loss: 0.010\n",
            "Training [8976/10000]: Loss: 0.008\n",
            "Training [8977/10000]: Loss: 0.009\n",
            "Training [8978/10000]: Loss: 0.012\n",
            "Training [8979/10000]: Loss: 0.009\n",
            "Training [8980/10000]: Loss: 0.012\n",
            "Training [8981/10000]: Loss: 0.011\n",
            "Training [8982/10000]: Loss: 0.010\n",
            "Training [8983/10000]: Loss: 0.011\n",
            "Training [8984/10000]: Loss: 0.007\n",
            "Training [8985/10000]: Loss: 0.007\n",
            "Training [8986/10000]: Loss: 0.010\n",
            "Training [8987/10000]: Loss: 0.012\n",
            "Training [8988/10000]: Loss: 0.005\n",
            "Training [8989/10000]: Loss: 0.011\n",
            "Training [8990/10000]: Loss: 0.014\n",
            "Training [8991/10000]: Loss: 0.012\n",
            "Training [8992/10000]: Loss: 0.013\n",
            "Training [8993/10000]: Loss: 0.011\n",
            "Training [8994/10000]: Loss: 0.009\n",
            "Training [8995/10000]: Loss: 0.012\n",
            "Training [8996/10000]: Loss: 0.009\n",
            "Training [8997/10000]: Loss: 0.006\n",
            "Training [8998/10000]: Loss: 0.013\n",
            "Training [8999/10000]: Loss: 0.011\n",
            "Training [9000/10000]: Loss: 0.010\n",
            "Test Loss: 0.062\n",
            "Training [9001/10000]: Loss: 0.012\n",
            "Training [9002/10000]: Loss: 0.009\n",
            "Training [9003/10000]: Loss: 0.017\n",
            "Training [9004/10000]: Loss: 0.011\n",
            "Training [9005/10000]: Loss: 0.010\n",
            "Training [9006/10000]: Loss: 0.009\n",
            "Training [9007/10000]: Loss: 0.009\n",
            "Training [9008/10000]: Loss: 0.008\n",
            "Training [9009/10000]: Loss: 0.008\n",
            "Training [9010/10000]: Loss: 0.008\n",
            "Training [9011/10000]: Loss: 0.014\n",
            "Training [9012/10000]: Loss: 0.009\n",
            "Training [9013/10000]: Loss: 0.008\n",
            "Training [9014/10000]: Loss: 0.016\n",
            "Training [9015/10000]: Loss: 0.008\n",
            "Training [9016/10000]: Loss: 0.006\n",
            "Training [9017/10000]: Loss: 0.015\n",
            "Training [9018/10000]: Loss: 0.009\n",
            "Training [9019/10000]: Loss: 0.009\n",
            "Training [9020/10000]: Loss: 0.007\n",
            "Training [9021/10000]: Loss: 0.016\n",
            "Training [9022/10000]: Loss: 0.014\n",
            "Training [9023/10000]: Loss: 0.009\n",
            "Training [9024/10000]: Loss: 0.011\n",
            "Training [9025/10000]: Loss: 0.008\n",
            "Training [9026/10000]: Loss: 0.009\n",
            "Training [9027/10000]: Loss: 0.009\n",
            "Training [9028/10000]: Loss: 0.013\n",
            "Training [9029/10000]: Loss: 0.008\n",
            "Training [9030/10000]: Loss: 0.012\n",
            "Training [9031/10000]: Loss: 0.013\n",
            "Training [9032/10000]: Loss: 0.010\n",
            "Training [9033/10000]: Loss: 0.009\n",
            "Training [9034/10000]: Loss: 0.011\n",
            "Training [9035/10000]: Loss: 0.009\n",
            "Training [9036/10000]: Loss: 0.009\n",
            "Training [9037/10000]: Loss: 0.012\n",
            "Training [9038/10000]: Loss: 0.009\n",
            "Training [9039/10000]: Loss: 0.013\n",
            "Training [9040/10000]: Loss: 0.011\n",
            "Training [9041/10000]: Loss: 0.010\n",
            "Training [9042/10000]: Loss: 0.005\n",
            "Training [9043/10000]: Loss: 0.011\n",
            "Training [9044/10000]: Loss: 0.009\n",
            "Training [9045/10000]: Loss: 0.008\n",
            "Training [9046/10000]: Loss: 0.012\n",
            "Training [9047/10000]: Loss: 0.010\n",
            "Training [9048/10000]: Loss: 0.010\n",
            "Training [9049/10000]: Loss: 0.009\n",
            "Training [9050/10000]: Loss: 0.012\n",
            "Training [9051/10000]: Loss: 0.009\n",
            "Training [9052/10000]: Loss: 0.012\n",
            "Training [9053/10000]: Loss: 0.008\n",
            "Training [9054/10000]: Loss: 0.009\n",
            "Training [9055/10000]: Loss: 0.010\n",
            "Training [9056/10000]: Loss: 0.010\n",
            "Training [9057/10000]: Loss: 0.006\n",
            "Training [9058/10000]: Loss: 0.014\n",
            "Training [9059/10000]: Loss: 0.011\n",
            "Training [9060/10000]: Loss: 0.010\n",
            "Training [9061/10000]: Loss: 0.008\n",
            "Training [9062/10000]: Loss: 0.014\n",
            "Training [9063/10000]: Loss: 0.014\n",
            "Training [9064/10000]: Loss: 0.014\n",
            "Training [9065/10000]: Loss: 0.008\n",
            "Training [9066/10000]: Loss: 0.010\n",
            "Training [9067/10000]: Loss: 0.012\n",
            "Training [9068/10000]: Loss: 0.009\n",
            "Training [9069/10000]: Loss: 0.010\n",
            "Training [9070/10000]: Loss: 0.008\n",
            "Training [9071/10000]: Loss: 0.009\n",
            "Training [9072/10000]: Loss: 0.008\n",
            "Training [9073/10000]: Loss: 0.007\n",
            "Training [9074/10000]: Loss: 0.011\n",
            "Training [9075/10000]: Loss: 0.009\n",
            "Training [9076/10000]: Loss: 0.007\n",
            "Training [9077/10000]: Loss: 0.008\n",
            "Training [9078/10000]: Loss: 0.010\n",
            "Training [9079/10000]: Loss: 0.009\n",
            "Training [9080/10000]: Loss: 0.008\n",
            "Training [9081/10000]: Loss: 0.012\n",
            "Training [9082/10000]: Loss: 0.009\n",
            "Training [9083/10000]: Loss: 0.008\n",
            "Training [9084/10000]: Loss: 0.009\n",
            "Training [9085/10000]: Loss: 0.013\n",
            "Training [9086/10000]: Loss: 0.007\n",
            "Training [9087/10000]: Loss: 0.012\n",
            "Training [9088/10000]: Loss: 0.008\n",
            "Training [9089/10000]: Loss: 0.008\n",
            "Training [9090/10000]: Loss: 0.006\n",
            "Training [9091/10000]: Loss: 0.010\n",
            "Training [9092/10000]: Loss: 0.007\n",
            "Training [9093/10000]: Loss: 0.013\n",
            "Training [9094/10000]: Loss: 0.011\n",
            "Training [9095/10000]: Loss: 0.012\n",
            "Training [9096/10000]: Loss: 0.011\n",
            "Training [9097/10000]: Loss: 0.011\n",
            "Training [9098/10000]: Loss: 0.010\n",
            "Training [9099/10000]: Loss: 0.012\n",
            "Training [9100/10000]: Loss: 0.007\n",
            "Test Loss: 0.062\n",
            "Training [9101/10000]: Loss: 0.011\n",
            "Training [9102/10000]: Loss: 0.007\n",
            "Training [9103/10000]: Loss: 0.012\n",
            "Training [9104/10000]: Loss: 0.007\n",
            "Training [9105/10000]: Loss: 0.010\n",
            "Training [9106/10000]: Loss: 0.009\n",
            "Training [9107/10000]: Loss: 0.009\n",
            "Training [9108/10000]: Loss: 0.011\n",
            "Training [9109/10000]: Loss: 0.009\n",
            "Training [9110/10000]: Loss: 0.009\n",
            "Training [9111/10000]: Loss: 0.009\n",
            "Training [9112/10000]: Loss: 0.012\n",
            "Training [9113/10000]: Loss: 0.012\n",
            "Training [9114/10000]: Loss: 0.013\n",
            "Training [9115/10000]: Loss: 0.011\n",
            "Training [9116/10000]: Loss: 0.009\n",
            "Training [9117/10000]: Loss: 0.009\n",
            "Training [9118/10000]: Loss: 0.010\n",
            "Training [9119/10000]: Loss: 0.007\n",
            "Training [9120/10000]: Loss: 0.009\n",
            "Training [9121/10000]: Loss: 0.012\n",
            "Training [9122/10000]: Loss: 0.010\n",
            "Training [9123/10000]: Loss: 0.009\n",
            "Training [9124/10000]: Loss: 0.012\n",
            "Training [9125/10000]: Loss: 0.014\n",
            "Training [9126/10000]: Loss: 0.008\n",
            "Training [9127/10000]: Loss: 0.010\n",
            "Training [9128/10000]: Loss: 0.009\n",
            "Training [9129/10000]: Loss: 0.010\n",
            "Training [9130/10000]: Loss: 0.010\n",
            "Training [9131/10000]: Loss: 0.010\n",
            "Training [9132/10000]: Loss: 0.007\n",
            "Training [9133/10000]: Loss: 0.009\n",
            "Training [9134/10000]: Loss: 0.008\n",
            "Training [9135/10000]: Loss: 0.011\n",
            "Training [9136/10000]: Loss: 0.012\n",
            "Training [9137/10000]: Loss: 0.010\n",
            "Training [9138/10000]: Loss: 0.008\n",
            "Training [9139/10000]: Loss: 0.010\n",
            "Training [9140/10000]: Loss: 0.010\n",
            "Training [9141/10000]: Loss: 0.011\n",
            "Training [9142/10000]: Loss: 0.007\n",
            "Training [9143/10000]: Loss: 0.010\n",
            "Training [9144/10000]: Loss: 0.010\n",
            "Training [9145/10000]: Loss: 0.007\n",
            "Training [9146/10000]: Loss: 0.018\n",
            "Training [9147/10000]: Loss: 0.012\n",
            "Training [9148/10000]: Loss: 0.012\n",
            "Training [9149/10000]: Loss: 0.011\n",
            "Training [9150/10000]: Loss: 0.013\n",
            "Training [9151/10000]: Loss: 0.009\n",
            "Training [9152/10000]: Loss: 0.007\n",
            "Training [9153/10000]: Loss: 0.010\n",
            "Training [9154/10000]: Loss: 0.012\n",
            "Training [9155/10000]: Loss: 0.012\n",
            "Training [9156/10000]: Loss: 0.013\n",
            "Training [9157/10000]: Loss: 0.007\n",
            "Training [9158/10000]: Loss: 0.013\n",
            "Training [9159/10000]: Loss: 0.011\n",
            "Training [9160/10000]: Loss: 0.009\n",
            "Training [9161/10000]: Loss: 0.014\n",
            "Training [9162/10000]: Loss: 0.009\n",
            "Training [9163/10000]: Loss: 0.011\n",
            "Training [9164/10000]: Loss: 0.009\n",
            "Training [9165/10000]: Loss: 0.013\n",
            "Training [9166/10000]: Loss: 0.014\n",
            "Training [9167/10000]: Loss: 0.015\n",
            "Training [9168/10000]: Loss: 0.012\n",
            "Training [9169/10000]: Loss: 0.010\n",
            "Training [9170/10000]: Loss: 0.009\n",
            "Training [9171/10000]: Loss: 0.010\n",
            "Training [9172/10000]: Loss: 0.013\n",
            "Training [9173/10000]: Loss: 0.009\n",
            "Training [9174/10000]: Loss: 0.010\n",
            "Training [9175/10000]: Loss: 0.011\n",
            "Training [9176/10000]: Loss: 0.012\n",
            "Training [9177/10000]: Loss: 0.010\n",
            "Training [9178/10000]: Loss: 0.007\n",
            "Training [9179/10000]: Loss: 0.007\n",
            "Training [9180/10000]: Loss: 0.011\n",
            "Training [9181/10000]: Loss: 0.007\n",
            "Training [9182/10000]: Loss: 0.010\n",
            "Training [9183/10000]: Loss: 0.014\n",
            "Training [9184/10000]: Loss: 0.011\n",
            "Training [9185/10000]: Loss: 0.011\n",
            "Training [9186/10000]: Loss: 0.011\n",
            "Training [9187/10000]: Loss: 0.012\n",
            "Training [9188/10000]: Loss: 0.020\n",
            "Training [9189/10000]: Loss: 0.008\n",
            "Training [9190/10000]: Loss: 0.009\n",
            "Training [9191/10000]: Loss: 0.010\n",
            "Training [9192/10000]: Loss: 0.010\n",
            "Training [9193/10000]: Loss: 0.010\n",
            "Training [9194/10000]: Loss: 0.010\n",
            "Training [9195/10000]: Loss: 0.013\n",
            "Training [9196/10000]: Loss: 0.008\n",
            "Training [9197/10000]: Loss: 0.009\n",
            "Training [9198/10000]: Loss: 0.011\n",
            "Training [9199/10000]: Loss: 0.013\n",
            "Training [9200/10000]: Loss: 0.008\n",
            "Test Loss: 0.059\n",
            "Training [9201/10000]: Loss: 0.008\n",
            "Training [9202/10000]: Loss: 0.012\n",
            "Training [9203/10000]: Loss: 0.009\n",
            "Training [9204/10000]: Loss: 0.012\n",
            "Training [9205/10000]: Loss: 0.009\n",
            "Training [9206/10000]: Loss: 0.007\n",
            "Training [9207/10000]: Loss: 0.013\n",
            "Training [9208/10000]: Loss: 0.011\n",
            "Training [9209/10000]: Loss: 0.006\n",
            "Training [9210/10000]: Loss: 0.009\n",
            "Training [9211/10000]: Loss: 0.014\n",
            "Training [9212/10000]: Loss: 0.012\n",
            "Training [9213/10000]: Loss: 0.014\n",
            "Training [9214/10000]: Loss: 0.012\n",
            "Training [9215/10000]: Loss: 0.009\n",
            "Training [9216/10000]: Loss: 0.009\n",
            "Training [9217/10000]: Loss: 0.013\n",
            "Training [9218/10000]: Loss: 0.007\n",
            "Training [9219/10000]: Loss: 0.011\n",
            "Training [9220/10000]: Loss: 0.010\n",
            "Training [9221/10000]: Loss: 0.010\n",
            "Training [9222/10000]: Loss: 0.010\n",
            "Training [9223/10000]: Loss: 0.010\n",
            "Training [9224/10000]: Loss: 0.008\n",
            "Training [9225/10000]: Loss: 0.008\n",
            "Training [9226/10000]: Loss: 0.016\n",
            "Training [9227/10000]: Loss: 0.009\n",
            "Training [9228/10000]: Loss: 0.012\n",
            "Training [9229/10000]: Loss: 0.011\n",
            "Training [9230/10000]: Loss: 0.012\n",
            "Training [9231/10000]: Loss: 0.010\n",
            "Training [9232/10000]: Loss: 0.009\n",
            "Training [9233/10000]: Loss: 0.011\n",
            "Training [9234/10000]: Loss: 0.008\n",
            "Training [9235/10000]: Loss: 0.010\n",
            "Training [9236/10000]: Loss: 0.009\n",
            "Training [9237/10000]: Loss: 0.016\n",
            "Training [9238/10000]: Loss: 0.007\n",
            "Training [9239/10000]: Loss: 0.011\n",
            "Training [9240/10000]: Loss: 0.013\n",
            "Training [9241/10000]: Loss: 0.012\n",
            "Training [9242/10000]: Loss: 0.009\n",
            "Training [9243/10000]: Loss: 0.009\n",
            "Training [9244/10000]: Loss: 0.008\n",
            "Training [9245/10000]: Loss: 0.009\n",
            "Training [9246/10000]: Loss: 0.007\n",
            "Training [9247/10000]: Loss: 0.013\n",
            "Training [9248/10000]: Loss: 0.011\n",
            "Training [9249/10000]: Loss: 0.012\n",
            "Training [9250/10000]: Loss: 0.013\n",
            "Training [9251/10000]: Loss: 0.011\n",
            "Training [9252/10000]: Loss: 0.010\n",
            "Training [9253/10000]: Loss: 0.012\n",
            "Training [9254/10000]: Loss: 0.006\n",
            "Training [9255/10000]: Loss: 0.014\n",
            "Training [9256/10000]: Loss: 0.010\n",
            "Training [9257/10000]: Loss: 0.008\n",
            "Training [9258/10000]: Loss: 0.012\n",
            "Training [9259/10000]: Loss: 0.007\n",
            "Training [9260/10000]: Loss: 0.009\n",
            "Training [9261/10000]: Loss: 0.008\n",
            "Training [9262/10000]: Loss: 0.007\n",
            "Training [9263/10000]: Loss: 0.009\n",
            "Training [9264/10000]: Loss: 0.014\n",
            "Training [9265/10000]: Loss: 0.010\n",
            "Training [9266/10000]: Loss: 0.011\n",
            "Training [9267/10000]: Loss: 0.009\n",
            "Training [9268/10000]: Loss: 0.010\n",
            "Training [9269/10000]: Loss: 0.009\n",
            "Training [9270/10000]: Loss: 0.007\n",
            "Training [9271/10000]: Loss: 0.012\n",
            "Training [9272/10000]: Loss: 0.012\n",
            "Training [9273/10000]: Loss: 0.009\n",
            "Training [9274/10000]: Loss: 0.006\n",
            "Training [9275/10000]: Loss: 0.007\n",
            "Training [9276/10000]: Loss: 0.009\n",
            "Training [9277/10000]: Loss: 0.013\n",
            "Training [9278/10000]: Loss: 0.011\n",
            "Training [9279/10000]: Loss: 0.012\n",
            "Training [9280/10000]: Loss: 0.012\n",
            "Training [9281/10000]: Loss: 0.012\n",
            "Training [9282/10000]: Loss: 0.014\n",
            "Training [9283/10000]: Loss: 0.011\n",
            "Training [9284/10000]: Loss: 0.010\n",
            "Training [9285/10000]: Loss: 0.014\n",
            "Training [9286/10000]: Loss: 0.008\n",
            "Training [9287/10000]: Loss: 0.007\n",
            "Training [9288/10000]: Loss: 0.009\n",
            "Training [9289/10000]: Loss: 0.011\n",
            "Training [9290/10000]: Loss: 0.012\n",
            "Training [9291/10000]: Loss: 0.009\n",
            "Training [9292/10000]: Loss: 0.013\n",
            "Training [9293/10000]: Loss: 0.010\n",
            "Training [9294/10000]: Loss: 0.012\n",
            "Training [9295/10000]: Loss: 0.008\n",
            "Training [9296/10000]: Loss: 0.013\n",
            "Training [9297/10000]: Loss: 0.006\n",
            "Training [9298/10000]: Loss: 0.007\n",
            "Training [9299/10000]: Loss: 0.007\n",
            "Training [9300/10000]: Loss: 0.009\n",
            "Test Loss: 0.060\n",
            "Training [9301/10000]: Loss: 0.012\n",
            "Training [9302/10000]: Loss: 0.012\n",
            "Training [9303/10000]: Loss: 0.011\n",
            "Training [9304/10000]: Loss: 0.011\n",
            "Training [9305/10000]: Loss: 0.012\n",
            "Training [9306/10000]: Loss: 0.010\n",
            "Training [9307/10000]: Loss: 0.009\n",
            "Training [9308/10000]: Loss: 0.009\n",
            "Training [9309/10000]: Loss: 0.008\n",
            "Training [9310/10000]: Loss: 0.011\n",
            "Training [9311/10000]: Loss: 0.009\n",
            "Training [9312/10000]: Loss: 0.006\n",
            "Training [9313/10000]: Loss: 0.015\n",
            "Training [9314/10000]: Loss: 0.011\n",
            "Training [9315/10000]: Loss: 0.010\n",
            "Training [9316/10000]: Loss: 0.010\n",
            "Training [9317/10000]: Loss: 0.011\n",
            "Training [9318/10000]: Loss: 0.011\n",
            "Training [9319/10000]: Loss: 0.011\n",
            "Training [9320/10000]: Loss: 0.014\n",
            "Training [9321/10000]: Loss: 0.010\n",
            "Training [9322/10000]: Loss: 0.011\n",
            "Training [9323/10000]: Loss: 0.006\n",
            "Training [9324/10000]: Loss: 0.017\n",
            "Training [9325/10000]: Loss: 0.007\n",
            "Training [9326/10000]: Loss: 0.007\n",
            "Training [9327/10000]: Loss: 0.009\n",
            "Training [9328/10000]: Loss: 0.013\n",
            "Training [9329/10000]: Loss: 0.007\n",
            "Training [9330/10000]: Loss: 0.011\n",
            "Training [9331/10000]: Loss: 0.012\n",
            "Training [9332/10000]: Loss: 0.007\n",
            "Training [9333/10000]: Loss: 0.008\n",
            "Training [9334/10000]: Loss: 0.007\n",
            "Training [9335/10000]: Loss: 0.019\n",
            "Training [9336/10000]: Loss: 0.010\n",
            "Training [9337/10000]: Loss: 0.006\n",
            "Training [9338/10000]: Loss: 0.010\n",
            "Training [9339/10000]: Loss: 0.008\n",
            "Training [9340/10000]: Loss: 0.014\n",
            "Training [9341/10000]: Loss: 0.010\n",
            "Training [9342/10000]: Loss: 0.012\n",
            "Training [9343/10000]: Loss: 0.006\n",
            "Training [9344/10000]: Loss: 0.016\n",
            "Training [9345/10000]: Loss: 0.010\n",
            "Training [9346/10000]: Loss: 0.008\n",
            "Training [9347/10000]: Loss: 0.010\n",
            "Training [9348/10000]: Loss: 0.010\n",
            "Training [9349/10000]: Loss: 0.012\n",
            "Training [9350/10000]: Loss: 0.010\n",
            "Training [9351/10000]: Loss: 0.007\n",
            "Training [9352/10000]: Loss: 0.012\n",
            "Training [9353/10000]: Loss: 0.010\n",
            "Training [9354/10000]: Loss: 0.012\n",
            "Training [9355/10000]: Loss: 0.005\n",
            "Training [9356/10000]: Loss: 0.009\n",
            "Training [9357/10000]: Loss: 0.008\n",
            "Training [9358/10000]: Loss: 0.010\n",
            "Training [9359/10000]: Loss: 0.009\n",
            "Training [9360/10000]: Loss: 0.010\n",
            "Training [9361/10000]: Loss: 0.010\n",
            "Training [9362/10000]: Loss: 0.008\n",
            "Training [9363/10000]: Loss: 0.014\n",
            "Training [9364/10000]: Loss: 0.010\n",
            "Training [9365/10000]: Loss: 0.012\n",
            "Training [9366/10000]: Loss: 0.008\n",
            "Training [9367/10000]: Loss: 0.009\n",
            "Training [9368/10000]: Loss: 0.005\n",
            "Training [9369/10000]: Loss: 0.011\n",
            "Training [9370/10000]: Loss: 0.011\n",
            "Training [9371/10000]: Loss: 0.013\n",
            "Training [9372/10000]: Loss: 0.012\n",
            "Training [9373/10000]: Loss: 0.007\n",
            "Training [9374/10000]: Loss: 0.005\n",
            "Training [9375/10000]: Loss: 0.010\n",
            "Training [9376/10000]: Loss: 0.011\n",
            "Training [9377/10000]: Loss: 0.012\n",
            "Training [9378/10000]: Loss: 0.007\n",
            "Training [9379/10000]: Loss: 0.007\n",
            "Training [9380/10000]: Loss: 0.009\n",
            "Training [9381/10000]: Loss: 0.007\n",
            "Training [9382/10000]: Loss: 0.011\n",
            "Training [9383/10000]: Loss: 0.005\n",
            "Training [9384/10000]: Loss: 0.014\n",
            "Training [9385/10000]: Loss: 0.010\n",
            "Training [9386/10000]: Loss: 0.010\n",
            "Training [9387/10000]: Loss: 0.011\n",
            "Training [9388/10000]: Loss: 0.012\n",
            "Training [9389/10000]: Loss: 0.006\n",
            "Training [9390/10000]: Loss: 0.010\n",
            "Training [9391/10000]: Loss: 0.010\n",
            "Training [9392/10000]: Loss: 0.012\n",
            "Training [9393/10000]: Loss: 0.013\n",
            "Training [9394/10000]: Loss: 0.012\n",
            "Training [9395/10000]: Loss: 0.012\n",
            "Training [9396/10000]: Loss: 0.010\n",
            "Training [9397/10000]: Loss: 0.011\n",
            "Training [9398/10000]: Loss: 0.008\n",
            "Training [9399/10000]: Loss: 0.009\n",
            "Training [9400/10000]: Loss: 0.010\n",
            "Test Loss: 0.063\n",
            "Training [9401/10000]: Loss: 0.011\n",
            "Training [9402/10000]: Loss: 0.005\n",
            "Training [9403/10000]: Loss: 0.012\n",
            "Training [9404/10000]: Loss: 0.008\n",
            "Training [9405/10000]: Loss: 0.006\n",
            "Training [9406/10000]: Loss: 0.008\n",
            "Training [9407/10000]: Loss: 0.010\n",
            "Training [9408/10000]: Loss: 0.007\n",
            "Training [9409/10000]: Loss: 0.012\n",
            "Training [9410/10000]: Loss: 0.007\n",
            "Training [9411/10000]: Loss: 0.009\n",
            "Training [9412/10000]: Loss: 0.009\n",
            "Training [9413/10000]: Loss: 0.009\n",
            "Training [9414/10000]: Loss: 0.013\n",
            "Training [9415/10000]: Loss: 0.012\n",
            "Training [9416/10000]: Loss: 0.011\n",
            "Training [9417/10000]: Loss: 0.007\n",
            "Training [9418/10000]: Loss: 0.009\n",
            "Training [9419/10000]: Loss: 0.010\n",
            "Training [9420/10000]: Loss: 0.006\n",
            "Training [9421/10000]: Loss: 0.009\n",
            "Training [9422/10000]: Loss: 0.006\n",
            "Training [9423/10000]: Loss: 0.007\n",
            "Training [9424/10000]: Loss: 0.011\n",
            "Training [9425/10000]: Loss: 0.011\n",
            "Training [9426/10000]: Loss: 0.010\n",
            "Training [9427/10000]: Loss: 0.008\n",
            "Training [9428/10000]: Loss: 0.013\n",
            "Training [9429/10000]: Loss: 0.015\n",
            "Training [9430/10000]: Loss: 0.008\n",
            "Training [9431/10000]: Loss: 0.009\n",
            "Training [9432/10000]: Loss: 0.008\n",
            "Training [9433/10000]: Loss: 0.006\n",
            "Training [9434/10000]: Loss: 0.011\n",
            "Training [9435/10000]: Loss: 0.009\n",
            "Training [9436/10000]: Loss: 0.014\n",
            "Training [9437/10000]: Loss: 0.008\n",
            "Training [9438/10000]: Loss: 0.008\n",
            "Training [9439/10000]: Loss: 0.016\n",
            "Training [9440/10000]: Loss: 0.008\n",
            "Training [9441/10000]: Loss: 0.010\n",
            "Training [9442/10000]: Loss: 0.008\n",
            "Training [9443/10000]: Loss: 0.010\n",
            "Training [9444/10000]: Loss: 0.008\n",
            "Training [9445/10000]: Loss: 0.010\n",
            "Training [9446/10000]: Loss: 0.011\n",
            "Training [9447/10000]: Loss: 0.009\n",
            "Training [9448/10000]: Loss: 0.009\n",
            "Training [9449/10000]: Loss: 0.009\n",
            "Training [9450/10000]: Loss: 0.010\n",
            "Training [9451/10000]: Loss: 0.011\n",
            "Training [9452/10000]: Loss: 0.007\n",
            "Training [9453/10000]: Loss: 0.011\n",
            "Training [9454/10000]: Loss: 0.006\n",
            "Training [9455/10000]: Loss: 0.013\n",
            "Training [9456/10000]: Loss: 0.012\n",
            "Training [9457/10000]: Loss: 0.007\n",
            "Training [9458/10000]: Loss: 0.013\n",
            "Training [9459/10000]: Loss: 0.008\n",
            "Training [9460/10000]: Loss: 0.004\n",
            "Training [9461/10000]: Loss: 0.010\n",
            "Training [9462/10000]: Loss: 0.011\n",
            "Training [9463/10000]: Loss: 0.011\n",
            "Training [9464/10000]: Loss: 0.009\n",
            "Training [9465/10000]: Loss: 0.008\n",
            "Training [9466/10000]: Loss: 0.007\n",
            "Training [9467/10000]: Loss: 0.010\n",
            "Training [9468/10000]: Loss: 0.005\n",
            "Training [9469/10000]: Loss: 0.008\n",
            "Training [9470/10000]: Loss: 0.009\n",
            "Training [9471/10000]: Loss: 0.008\n",
            "Training [9472/10000]: Loss: 0.008\n",
            "Training [9473/10000]: Loss: 0.012\n",
            "Training [9474/10000]: Loss: 0.012\n",
            "Training [9475/10000]: Loss: 0.006\n",
            "Training [9476/10000]: Loss: 0.011\n",
            "Training [9477/10000]: Loss: 0.010\n",
            "Training [9478/10000]: Loss: 0.007\n",
            "Training [9479/10000]: Loss: 0.010\n",
            "Training [9480/10000]: Loss: 0.014\n",
            "Training [9481/10000]: Loss: 0.010\n",
            "Training [9482/10000]: Loss: 0.014\n",
            "Training [9483/10000]: Loss: 0.011\n",
            "Training [9484/10000]: Loss: 0.012\n",
            "Training [9485/10000]: Loss: 0.010\n",
            "Training [9486/10000]: Loss: 0.007\n",
            "Training [9487/10000]: Loss: 0.007\n",
            "Training [9488/10000]: Loss: 0.010\n",
            "Training [9489/10000]: Loss: 0.008\n",
            "Training [9490/10000]: Loss: 0.012\n",
            "Training [9491/10000]: Loss: 0.013\n",
            "Training [9492/10000]: Loss: 0.012\n",
            "Training [9493/10000]: Loss: 0.007\n",
            "Training [9494/10000]: Loss: 0.005\n",
            "Training [9495/10000]: Loss: 0.011\n",
            "Training [9496/10000]: Loss: 0.006\n",
            "Training [9497/10000]: Loss: 0.011\n",
            "Training [9498/10000]: Loss: 0.008\n",
            "Training [9499/10000]: Loss: 0.012\n",
            "Training [9500/10000]: Loss: 0.009\n",
            "Test Loss: 0.071\n",
            "Training [9501/10000]: Loss: 0.008\n",
            "Training [9502/10000]: Loss: 0.017\n",
            "Training [9503/10000]: Loss: 0.006\n",
            "Training [9504/10000]: Loss: 0.012\n",
            "Training [9505/10000]: Loss: 0.007\n",
            "Training [9506/10000]: Loss: 0.008\n",
            "Training [9507/10000]: Loss: 0.006\n",
            "Training [9508/10000]: Loss: 0.008\n",
            "Training [9509/10000]: Loss: 0.011\n",
            "Training [9510/10000]: Loss: 0.011\n",
            "Training [9511/10000]: Loss: 0.011\n",
            "Training [9512/10000]: Loss: 0.007\n",
            "Training [9513/10000]: Loss: 0.008\n",
            "Training [9514/10000]: Loss: 0.011\n",
            "Training [9515/10000]: Loss: 0.008\n",
            "Training [9516/10000]: Loss: 0.007\n",
            "Training [9517/10000]: Loss: 0.012\n",
            "Training [9518/10000]: Loss: 0.011\n",
            "Training [9519/10000]: Loss: 0.010\n",
            "Training [9520/10000]: Loss: 0.010\n",
            "Training [9521/10000]: Loss: 0.012\n",
            "Training [9522/10000]: Loss: 0.011\n",
            "Training [9523/10000]: Loss: 0.011\n",
            "Training [9524/10000]: Loss: 0.010\n",
            "Training [9525/10000]: Loss: 0.011\n",
            "Training [9526/10000]: Loss: 0.009\n",
            "Training [9527/10000]: Loss: 0.010\n",
            "Training [9528/10000]: Loss: 0.006\n",
            "Training [9529/10000]: Loss: 0.005\n",
            "Training [9530/10000]: Loss: 0.010\n",
            "Training [9531/10000]: Loss: 0.010\n",
            "Training [9532/10000]: Loss: 0.009\n",
            "Training [9533/10000]: Loss: 0.009\n",
            "Training [9534/10000]: Loss: 0.013\n",
            "Training [9535/10000]: Loss: 0.009\n",
            "Training [9536/10000]: Loss: 0.009\n",
            "Training [9537/10000]: Loss: 0.011\n",
            "Training [9538/10000]: Loss: 0.008\n",
            "Training [9539/10000]: Loss: 0.009\n",
            "Training [9540/10000]: Loss: 0.011\n",
            "Training [9541/10000]: Loss: 0.010\n",
            "Training [9542/10000]: Loss: 0.012\n",
            "Training [9543/10000]: Loss: 0.009\n",
            "Training [9544/10000]: Loss: 0.008\n",
            "Training [9545/10000]: Loss: 0.007\n",
            "Training [9546/10000]: Loss: 0.008\n",
            "Training [9547/10000]: Loss: 0.008\n",
            "Training [9548/10000]: Loss: 0.011\n",
            "Training [9549/10000]: Loss: 0.013\n",
            "Training [9550/10000]: Loss: 0.010\n",
            "Training [9551/10000]: Loss: 0.014\n",
            "Training [9552/10000]: Loss: 0.005\n",
            "Training [9553/10000]: Loss: 0.008\n",
            "Training [9554/10000]: Loss: 0.007\n",
            "Training [9555/10000]: Loss: 0.013\n",
            "Training [9556/10000]: Loss: 0.008\n",
            "Training [9557/10000]: Loss: 0.009\n",
            "Training [9558/10000]: Loss: 0.014\n",
            "Training [9559/10000]: Loss: 0.011\n",
            "Training [9560/10000]: Loss: 0.015\n",
            "Training [9561/10000]: Loss: 0.006\n",
            "Training [9562/10000]: Loss: 0.009\n",
            "Training [9563/10000]: Loss: 0.010\n",
            "Training [9564/10000]: Loss: 0.006\n",
            "Training [9565/10000]: Loss: 0.006\n",
            "Training [9566/10000]: Loss: 0.009\n",
            "Training [9567/10000]: Loss: 0.009\n",
            "Training [9568/10000]: Loss: 0.008\n",
            "Training [9569/10000]: Loss: 0.012\n",
            "Training [9570/10000]: Loss: 0.009\n",
            "Training [9571/10000]: Loss: 0.010\n",
            "Training [9572/10000]: Loss: 0.011\n",
            "Training [9573/10000]: Loss: 0.010\n",
            "Training [9574/10000]: Loss: 0.010\n",
            "Training [9575/10000]: Loss: 0.010\n",
            "Training [9576/10000]: Loss: 0.010\n",
            "Training [9577/10000]: Loss: 0.007\n",
            "Training [9578/10000]: Loss: 0.013\n",
            "Training [9579/10000]: Loss: 0.007\n",
            "Training [9580/10000]: Loss: 0.006\n",
            "Training [9581/10000]: Loss: 0.005\n",
            "Training [9582/10000]: Loss: 0.011\n",
            "Training [9583/10000]: Loss: 0.008\n",
            "Training [9584/10000]: Loss: 0.007\n",
            "Training [9585/10000]: Loss: 0.010\n",
            "Training [9586/10000]: Loss: 0.007\n",
            "Training [9587/10000]: Loss: 0.009\n",
            "Training [9588/10000]: Loss: 0.009\n",
            "Training [9589/10000]: Loss: 0.006\n",
            "Training [9590/10000]: Loss: 0.014\n",
            "Training [9591/10000]: Loss: 0.006\n",
            "Training [9592/10000]: Loss: 0.010\n",
            "Training [9593/10000]: Loss: 0.006\n",
            "Training [9594/10000]: Loss: 0.010\n",
            "Training [9595/10000]: Loss: 0.009\n",
            "Training [9596/10000]: Loss: 0.007\n",
            "Training [9597/10000]: Loss: 0.009\n",
            "Training [9598/10000]: Loss: 0.012\n",
            "Training [9599/10000]: Loss: 0.008\n",
            "Training [9600/10000]: Loss: 0.007\n",
            "Test Loss: 0.066\n",
            "Training [9601/10000]: Loss: 0.009\n",
            "Training [9602/10000]: Loss: 0.010\n",
            "Training [9603/10000]: Loss: 0.010\n",
            "Training [9604/10000]: Loss: 0.010\n",
            "Training [9605/10000]: Loss: 0.007\n",
            "Training [9606/10000]: Loss: 0.007\n",
            "Training [9607/10000]: Loss: 0.008\n",
            "Training [9608/10000]: Loss: 0.010\n",
            "Training [9609/10000]: Loss: 0.010\n",
            "Training [9610/10000]: Loss: 0.008\n",
            "Training [9611/10000]: Loss: 0.008\n",
            "Training [9612/10000]: Loss: 0.009\n",
            "Training [9613/10000]: Loss: 0.008\n",
            "Training [9614/10000]: Loss: 0.010\n",
            "Training [9615/10000]: Loss: 0.011\n",
            "Training [9616/10000]: Loss: 0.007\n",
            "Training [9617/10000]: Loss: 0.009\n",
            "Training [9618/10000]: Loss: 0.010\n",
            "Training [9619/10000]: Loss: 0.010\n",
            "Training [9620/10000]: Loss: 0.014\n",
            "Training [9621/10000]: Loss: 0.010\n",
            "Training [9622/10000]: Loss: 0.007\n",
            "Training [9623/10000]: Loss: 0.006\n",
            "Training [9624/10000]: Loss: 0.011\n",
            "Training [9625/10000]: Loss: 0.008\n",
            "Training [9626/10000]: Loss: 0.009\n",
            "Training [9627/10000]: Loss: 0.012\n",
            "Training [9628/10000]: Loss: 0.008\n",
            "Training [9629/10000]: Loss: 0.008\n",
            "Training [9630/10000]: Loss: 0.006\n",
            "Training [9631/10000]: Loss: 0.006\n",
            "Training [9632/10000]: Loss: 0.007\n",
            "Training [9633/10000]: Loss: 0.008\n",
            "Training [9634/10000]: Loss: 0.005\n",
            "Training [9635/10000]: Loss: 0.013\n",
            "Training [9636/10000]: Loss: 0.007\n",
            "Training [9637/10000]: Loss: 0.011\n",
            "Training [9638/10000]: Loss: 0.006\n",
            "Training [9639/10000]: Loss: 0.009\n",
            "Training [9640/10000]: Loss: 0.010\n",
            "Training [9641/10000]: Loss: 0.010\n",
            "Training [9642/10000]: Loss: 0.010\n",
            "Training [9643/10000]: Loss: 0.007\n",
            "Training [9644/10000]: Loss: 0.006\n",
            "Training [9645/10000]: Loss: 0.007\n",
            "Training [9646/10000]: Loss: 0.017\n",
            "Training [9647/10000]: Loss: 0.010\n",
            "Training [9648/10000]: Loss: 0.008\n",
            "Training [9649/10000]: Loss: 0.008\n",
            "Training [9650/10000]: Loss: 0.011\n",
            "Training [9651/10000]: Loss: 0.007\n",
            "Training [9652/10000]: Loss: 0.010\n",
            "Training [9653/10000]: Loss: 0.006\n",
            "Training [9654/10000]: Loss: 0.012\n",
            "Training [9655/10000]: Loss: 0.011\n",
            "Training [9656/10000]: Loss: 0.011\n",
            "Training [9657/10000]: Loss: 0.005\n",
            "Training [9658/10000]: Loss: 0.004\n",
            "Training [9659/10000]: Loss: 0.013\n",
            "Training [9660/10000]: Loss: 0.015\n",
            "Training [9661/10000]: Loss: 0.008\n",
            "Training [9662/10000]: Loss: 0.005\n",
            "Training [9663/10000]: Loss: 0.012\n",
            "Training [9664/10000]: Loss: 0.009\n",
            "Training [9665/10000]: Loss: 0.010\n",
            "Training [9666/10000]: Loss: 0.014\n",
            "Training [9667/10000]: Loss: 0.008\n",
            "Training [9668/10000]: Loss: 0.008\n",
            "Training [9669/10000]: Loss: 0.010\n",
            "Training [9670/10000]: Loss: 0.010\n",
            "Training [9671/10000]: Loss: 0.009\n",
            "Training [9672/10000]: Loss: 0.008\n",
            "Training [9673/10000]: Loss: 0.009\n",
            "Training [9674/10000]: Loss: 0.007\n",
            "Training [9675/10000]: Loss: 0.010\n",
            "Training [9676/10000]: Loss: 0.009\n",
            "Training [9677/10000]: Loss: 0.008\n",
            "Training [9678/10000]: Loss: 0.006\n",
            "Training [9679/10000]: Loss: 0.010\n",
            "Training [9680/10000]: Loss: 0.010\n",
            "Training [9681/10000]: Loss: 0.009\n",
            "Training [9682/10000]: Loss: 0.006\n",
            "Training [9683/10000]: Loss: 0.010\n",
            "Training [9684/10000]: Loss: 0.010\n",
            "Training [9685/10000]: Loss: 0.007\n",
            "Training [9686/10000]: Loss: 0.006\n",
            "Training [9687/10000]: Loss: 0.008\n",
            "Training [9688/10000]: Loss: 0.010\n",
            "Training [9689/10000]: Loss: 0.009\n",
            "Training [9690/10000]: Loss: 0.006\n",
            "Training [9691/10000]: Loss: 0.008\n",
            "Training [9692/10000]: Loss: 0.006\n",
            "Training [9693/10000]: Loss: 0.009\n",
            "Training [9694/10000]: Loss: 0.010\n",
            "Training [9695/10000]: Loss: 0.010\n",
            "Training [9696/10000]: Loss: 0.009\n",
            "Training [9697/10000]: Loss: 0.009\n",
            "Training [9698/10000]: Loss: 0.006\n",
            "Training [9699/10000]: Loss: 0.008\n",
            "Training [9700/10000]: Loss: 0.008\n",
            "Test Loss: 0.065\n",
            "Training [9701/10000]: Loss: 0.011\n",
            "Training [9702/10000]: Loss: 0.010\n",
            "Training [9703/10000]: Loss: 0.009\n",
            "Training [9704/10000]: Loss: 0.008\n",
            "Training [9705/10000]: Loss: 0.007\n",
            "Training [9706/10000]: Loss: 0.011\n",
            "Training [9707/10000]: Loss: 0.007\n",
            "Training [9708/10000]: Loss: 0.016\n",
            "Training [9709/10000]: Loss: 0.008\n",
            "Training [9710/10000]: Loss: 0.012\n",
            "Training [9711/10000]: Loss: 0.010\n",
            "Training [9712/10000]: Loss: 0.010\n",
            "Training [9713/10000]: Loss: 0.013\n",
            "Training [9714/10000]: Loss: 0.008\n",
            "Training [9715/10000]: Loss: 0.007\n",
            "Training [9716/10000]: Loss: 0.006\n",
            "Training [9717/10000]: Loss: 0.012\n",
            "Training [9718/10000]: Loss: 0.012\n",
            "Training [9719/10000]: Loss: 0.010\n",
            "Training [9720/10000]: Loss: 0.011\n",
            "Training [9721/10000]: Loss: 0.009\n",
            "Training [9722/10000]: Loss: 0.009\n",
            "Training [9723/10000]: Loss: 0.008\n",
            "Training [9724/10000]: Loss: 0.007\n",
            "Training [9725/10000]: Loss: 0.013\n",
            "Training [9726/10000]: Loss: 0.011\n",
            "Training [9727/10000]: Loss: 0.008\n",
            "Training [9728/10000]: Loss: 0.007\n",
            "Training [9729/10000]: Loss: 0.010\n",
            "Training [9730/10000]: Loss: 0.010\n",
            "Training [9731/10000]: Loss: 0.009\n",
            "Training [9732/10000]: Loss: 0.009\n",
            "Training [9733/10000]: Loss: 0.008\n",
            "Training [9734/10000]: Loss: 0.013\n",
            "Training [9735/10000]: Loss: 0.012\n",
            "Training [9736/10000]: Loss: 0.010\n",
            "Training [9737/10000]: Loss: 0.008\n",
            "Training [9738/10000]: Loss: 0.009\n",
            "Training [9739/10000]: Loss: 0.010\n",
            "Training [9740/10000]: Loss: 0.009\n",
            "Training [9741/10000]: Loss: 0.011\n",
            "Training [9742/10000]: Loss: 0.010\n",
            "Training [9743/10000]: Loss: 0.008\n",
            "Training [9744/10000]: Loss: 0.012\n",
            "Training [9745/10000]: Loss: 0.012\n",
            "Training [9746/10000]: Loss: 0.011\n",
            "Training [9747/10000]: Loss: 0.012\n",
            "Training [9748/10000]: Loss: 0.014\n",
            "Training [9749/10000]: Loss: 0.010\n",
            "Training [9750/10000]: Loss: 0.011\n",
            "Training [9751/10000]: Loss: 0.009\n",
            "Training [9752/10000]: Loss: 0.012\n",
            "Training [9753/10000]: Loss: 0.007\n",
            "Training [9754/10000]: Loss: 0.009\n",
            "Training [9755/10000]: Loss: 0.007\n",
            "Training [9756/10000]: Loss: 0.012\n",
            "Training [9757/10000]: Loss: 0.011\n",
            "Training [9758/10000]: Loss: 0.015\n",
            "Training [9759/10000]: Loss: 0.011\n",
            "Training [9760/10000]: Loss: 0.009\n",
            "Training [9761/10000]: Loss: 0.012\n",
            "Training [9762/10000]: Loss: 0.013\n",
            "Training [9763/10000]: Loss: 0.007\n",
            "Training [9764/10000]: Loss: 0.012\n",
            "Training [9765/10000]: Loss: 0.009\n",
            "Training [9766/10000]: Loss: 0.009\n",
            "Training [9767/10000]: Loss: 0.010\n",
            "Training [9768/10000]: Loss: 0.011\n",
            "Training [9769/10000]: Loss: 0.009\n",
            "Training [9770/10000]: Loss: 0.011\n",
            "Training [9771/10000]: Loss: 0.010\n",
            "Training [9772/10000]: Loss: 0.013\n",
            "Training [9773/10000]: Loss: 0.008\n",
            "Training [9774/10000]: Loss: 0.010\n",
            "Training [9775/10000]: Loss: 0.007\n",
            "Training [9776/10000]: Loss: 0.006\n",
            "Training [9777/10000]: Loss: 0.009\n",
            "Training [9778/10000]: Loss: 0.011\n",
            "Training [9779/10000]: Loss: 0.009\n",
            "Training [9780/10000]: Loss: 0.005\n",
            "Training [9781/10000]: Loss: 0.005\n",
            "Training [9782/10000]: Loss: 0.011\n",
            "Training [9783/10000]: Loss: 0.009\n",
            "Training [9784/10000]: Loss: 0.011\n",
            "Training [9785/10000]: Loss: 0.009\n",
            "Training [9786/10000]: Loss: 0.013\n",
            "Training [9787/10000]: Loss: 0.010\n",
            "Training [9788/10000]: Loss: 0.009\n",
            "Training [9789/10000]: Loss: 0.010\n",
            "Training [9790/10000]: Loss: 0.010\n",
            "Training [9791/10000]: Loss: 0.010\n",
            "Training [9792/10000]: Loss: 0.011\n",
            "Training [9793/10000]: Loss: 0.005\n",
            "Training [9794/10000]: Loss: 0.009\n",
            "Training [9795/10000]: Loss: 0.008\n",
            "Training [9796/10000]: Loss: 0.010\n",
            "Training [9797/10000]: Loss: 0.011\n",
            "Training [9798/10000]: Loss: 0.009\n",
            "Training [9799/10000]: Loss: 0.007\n",
            "Training [9800/10000]: Loss: 0.007\n",
            "Test Loss: 0.068\n",
            "Training [9801/10000]: Loss: 0.010\n",
            "Training [9802/10000]: Loss: 0.009\n",
            "Training [9803/10000]: Loss: 0.013\n",
            "Training [9804/10000]: Loss: 0.009\n",
            "Training [9805/10000]: Loss: 0.006\n",
            "Training [9806/10000]: Loss: 0.012\n",
            "Training [9807/10000]: Loss: 0.008\n",
            "Training [9808/10000]: Loss: 0.011\n",
            "Training [9809/10000]: Loss: 0.006\n",
            "Training [9810/10000]: Loss: 0.009\n",
            "Training [9811/10000]: Loss: 0.008\n",
            "Training [9812/10000]: Loss: 0.006\n",
            "Training [9813/10000]: Loss: 0.008\n",
            "Training [9814/10000]: Loss: 0.009\n",
            "Training [9815/10000]: Loss: 0.009\n",
            "Training [9816/10000]: Loss: 0.008\n",
            "Training [9817/10000]: Loss: 0.007\n",
            "Training [9818/10000]: Loss: 0.009\n",
            "Training [9819/10000]: Loss: 0.011\n",
            "Training [9820/10000]: Loss: 0.010\n",
            "Training [9821/10000]: Loss: 0.008\n",
            "Training [9822/10000]: Loss: 0.012\n",
            "Training [9823/10000]: Loss: 0.012\n",
            "Training [9824/10000]: Loss: 0.014\n",
            "Training [9825/10000]: Loss: 0.008\n",
            "Training [9826/10000]: Loss: 0.010\n",
            "Training [9827/10000]: Loss: 0.010\n",
            "Training [9828/10000]: Loss: 0.009\n",
            "Training [9829/10000]: Loss: 0.010\n",
            "Training [9830/10000]: Loss: 0.009\n",
            "Training [9831/10000]: Loss: 0.009\n",
            "Training [9832/10000]: Loss: 0.012\n",
            "Training [9833/10000]: Loss: 0.011\n",
            "Training [9834/10000]: Loss: 0.011\n",
            "Training [9835/10000]: Loss: 0.007\n",
            "Training [9836/10000]: Loss: 0.011\n",
            "Training [9837/10000]: Loss: 0.011\n",
            "Training [9838/10000]: Loss: 0.008\n",
            "Training [9839/10000]: Loss: 0.010\n",
            "Training [9840/10000]: Loss: 0.012\n",
            "Training [9841/10000]: Loss: 0.011\n",
            "Training [9842/10000]: Loss: 0.011\n",
            "Training [9843/10000]: Loss: 0.010\n",
            "Training [9844/10000]: Loss: 0.009\n",
            "Training [9845/10000]: Loss: 0.007\n",
            "Training [9846/10000]: Loss: 0.007\n",
            "Training [9847/10000]: Loss: 0.007\n",
            "Training [9848/10000]: Loss: 0.009\n",
            "Training [9849/10000]: Loss: 0.007\n",
            "Training [9850/10000]: Loss: 0.008\n",
            "Training [9851/10000]: Loss: 0.010\n",
            "Training [9852/10000]: Loss: 0.011\n",
            "Training [9853/10000]: Loss: 0.006\n",
            "Training [9854/10000]: Loss: 0.008\n",
            "Training [9855/10000]: Loss: 0.012\n",
            "Training [9856/10000]: Loss: 0.009\n",
            "Training [9857/10000]: Loss: 0.007\n",
            "Training [9858/10000]: Loss: 0.009\n",
            "Training [9859/10000]: Loss: 0.009\n",
            "Training [9860/10000]: Loss: 0.010\n",
            "Training [9861/10000]: Loss: 0.009\n",
            "Training [9862/10000]: Loss: 0.009\n",
            "Training [9863/10000]: Loss: 0.010\n",
            "Training [9864/10000]: Loss: 0.007\n",
            "Training [9865/10000]: Loss: 0.008\n",
            "Training [9866/10000]: Loss: 0.008\n",
            "Training [9867/10000]: Loss: 0.005\n",
            "Training [9868/10000]: Loss: 0.008\n",
            "Training [9869/10000]: Loss: 0.011\n",
            "Training [9870/10000]: Loss: 0.007\n",
            "Training [9871/10000]: Loss: 0.007\n",
            "Training [9872/10000]: Loss: 0.010\n",
            "Training [9873/10000]: Loss: 0.012\n",
            "Training [9874/10000]: Loss: 0.010\n",
            "Training [9875/10000]: Loss: 0.006\n",
            "Training [9876/10000]: Loss: 0.014\n",
            "Training [9877/10000]: Loss: 0.013\n",
            "Training [9878/10000]: Loss: 0.010\n",
            "Training [9879/10000]: Loss: 0.011\n",
            "Training [9880/10000]: Loss: 0.013\n",
            "Training [9881/10000]: Loss: 0.007\n",
            "Training [9882/10000]: Loss: 0.004\n",
            "Training [9883/10000]: Loss: 0.009\n",
            "Training [9884/10000]: Loss: 0.012\n",
            "Training [9885/10000]: Loss: 0.006\n",
            "Training [9886/10000]: Loss: 0.007\n",
            "Training [9887/10000]: Loss: 0.005\n",
            "Training [9888/10000]: Loss: 0.011\n",
            "Training [9889/10000]: Loss: 0.007\n",
            "Training [9890/10000]: Loss: 0.011\n",
            "Training [9891/10000]: Loss: 0.011\n",
            "Training [9892/10000]: Loss: 0.009\n",
            "Training [9893/10000]: Loss: 0.011\n",
            "Training [9894/10000]: Loss: 0.011\n",
            "Training [9895/10000]: Loss: 0.009\n",
            "Training [9896/10000]: Loss: 0.007\n",
            "Training [9897/10000]: Loss: 0.007\n",
            "Training [9898/10000]: Loss: 0.012\n",
            "Training [9899/10000]: Loss: 0.007\n",
            "Training [9900/10000]: Loss: 0.005\n",
            "Test Loss: 0.064\n",
            "Training [9901/10000]: Loss: 0.010\n",
            "Training [9902/10000]: Loss: 0.011\n",
            "Training [9903/10000]: Loss: 0.014\n",
            "Training [9904/10000]: Loss: 0.012\n",
            "Training [9905/10000]: Loss: 0.007\n",
            "Training [9906/10000]: Loss: 0.008\n",
            "Training [9907/10000]: Loss: 0.010\n",
            "Training [9908/10000]: Loss: 0.007\n",
            "Training [9909/10000]: Loss: 0.008\n",
            "Training [9910/10000]: Loss: 0.010\n",
            "Training [9911/10000]: Loss: 0.014\n",
            "Training [9912/10000]: Loss: 0.012\n",
            "Training [9913/10000]: Loss: 0.012\n",
            "Training [9914/10000]: Loss: 0.012\n",
            "Training [9915/10000]: Loss: 0.007\n",
            "Training [9916/10000]: Loss: 0.009\n",
            "Training [9917/10000]: Loss: 0.009\n",
            "Training [9918/10000]: Loss: 0.011\n",
            "Training [9919/10000]: Loss: 0.010\n",
            "Training [9920/10000]: Loss: 0.007\n",
            "Training [9921/10000]: Loss: 0.009\n",
            "Training [9922/10000]: Loss: 0.008\n",
            "Training [9923/10000]: Loss: 0.007\n",
            "Training [9924/10000]: Loss: 0.007\n",
            "Training [9925/10000]: Loss: 0.015\n",
            "Training [9926/10000]: Loss: 0.010\n",
            "Training [9927/10000]: Loss: 0.010\n",
            "Training [9928/10000]: Loss: 0.007\n",
            "Training [9929/10000]: Loss: 0.010\n",
            "Training [9930/10000]: Loss: 0.009\n",
            "Training [9931/10000]: Loss: 0.009\n",
            "Training [9932/10000]: Loss: 0.012\n",
            "Training [9933/10000]: Loss: 0.014\n",
            "Training [9934/10000]: Loss: 0.010\n",
            "Training [9935/10000]: Loss: 0.009\n",
            "Training [9936/10000]: Loss: 0.010\n",
            "Training [9937/10000]: Loss: 0.010\n",
            "Training [9938/10000]: Loss: 0.015\n",
            "Training [9939/10000]: Loss: 0.012\n",
            "Training [9940/10000]: Loss: 0.014\n",
            "Training [9941/10000]: Loss: 0.008\n",
            "Training [9942/10000]: Loss: 0.011\n",
            "Training [9943/10000]: Loss: 0.006\n",
            "Training [9944/10000]: Loss: 0.012\n",
            "Training [9945/10000]: Loss: 0.010\n",
            "Training [9946/10000]: Loss: 0.010\n",
            "Training [9947/10000]: Loss: 0.009\n",
            "Training [9948/10000]: Loss: 0.015\n",
            "Training [9949/10000]: Loss: 0.008\n",
            "Training [9950/10000]: Loss: 0.013\n",
            "Training [9951/10000]: Loss: 0.008\n",
            "Training [9952/10000]: Loss: 0.008\n",
            "Training [9953/10000]: Loss: 0.017\n",
            "Training [9954/10000]: Loss: 0.009\n",
            "Training [9955/10000]: Loss: 0.011\n",
            "Training [9956/10000]: Loss: 0.015\n",
            "Training [9957/10000]: Loss: 0.011\n",
            "Training [9958/10000]: Loss: 0.013\n",
            "Training [9959/10000]: Loss: 0.012\n",
            "Training [9960/10000]: Loss: 0.009\n",
            "Training [9961/10000]: Loss: 0.006\n",
            "Training [9962/10000]: Loss: 0.004\n",
            "Training [9963/10000]: Loss: 0.011\n",
            "Training [9964/10000]: Loss: 0.011\n",
            "Training [9965/10000]: Loss: 0.010\n",
            "Training [9966/10000]: Loss: 0.009\n",
            "Training [9967/10000]: Loss: 0.011\n",
            "Training [9968/10000]: Loss: 0.013\n",
            "Training [9969/10000]: Loss: 0.012\n",
            "Training [9970/10000]: Loss: 0.009\n",
            "Training [9971/10000]: Loss: 0.011\n",
            "Training [9972/10000]: Loss: 0.009\n",
            "Training [9973/10000]: Loss: 0.008\n",
            "Training [9974/10000]: Loss: 0.004\n",
            "Training [9975/10000]: Loss: 0.014\n",
            "Training [9976/10000]: Loss: 0.010\n",
            "Training [9977/10000]: Loss: 0.019\n",
            "Training [9978/10000]: Loss: 0.008\n",
            "Training [9979/10000]: Loss: 0.006\n",
            "Training [9980/10000]: Loss: 0.007\n",
            "Training [9981/10000]: Loss: 0.013\n",
            "Training [9982/10000]: Loss: 0.006\n",
            "Training [9983/10000]: Loss: 0.010\n",
            "Training [9984/10000]: Loss: 0.013\n",
            "Training [9985/10000]: Loss: 0.009\n",
            "Training [9986/10000]: Loss: 0.007\n",
            "Training [9987/10000]: Loss: 0.009\n",
            "Training [9988/10000]: Loss: 0.006\n",
            "Training [9989/10000]: Loss: 0.008\n",
            "Training [9990/10000]: Loss: 0.008\n",
            "Training [9991/10000]: Loss: 0.008\n",
            "Training [9992/10000]: Loss: 0.009\n",
            "Training [9993/10000]: Loss: 0.008\n",
            "Training [9994/10000]: Loss: 0.012\n",
            "Training [9995/10000]: Loss: 0.010\n",
            "Training [9996/10000]: Loss: 0.013\n",
            "Training [9997/10000]: Loss: 0.006\n",
            "Training [9998/10000]: Loss: 0.013\n",
            "Training [9999/10000]: Loss: 0.008\n",
            "Training [10000/10000]: Loss: 0.007\n",
            "Test Loss: 0.069\n",
            "Training took 495.031s in total.\n"
          ]
        }
      ],
      "source": [
        "# CUDA device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Device: {0}'.format(device))\n",
        "\n",
        "# Build the model\n",
        "num_class = 4\n",
        "model = UNet(input_channel=1, output_channel=num_class, num_filter=16)\n",
        "model = model.to(device)\n",
        "params = list(model.parameters())\n",
        "\n",
        "model_dir = 'saved_models'\n",
        "if not os.path.exists(model_dir):\n",
        "    os.makedirs(model_dir)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(params, lr=1e-3)\n",
        "\n",
        "# Segmentation loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Datasets\n",
        "train_set = BrainImageSet('Task01_BrainTumour_2D/training_images', 'Task01_BrainTumour_2D/training_labels')\n",
        "test_set = BrainImageSet('Task01_BrainTumour_2D/test_images', 'Task01_BrainTumour_2D/test_labels')\n",
        "\n",
        "# Train the model\n",
        "# Note: when you debug the model, you may reduce the number of iterations or batch size to save time.\n",
        "num_iter = 10000\n",
        "train_batch_size = 16\n",
        "eval_batch_size = 16\n",
        "start = time.time()\n",
        "for it in range(1, 1 + num_iter):\n",
        "    # Set the modules in training mode, which will have effects on certain modules, e.g. dropout or batchnorm.\n",
        "    start_iter = time.time()\n",
        "    model.train()\n",
        "\n",
        "    # Get a batch of images and labels\n",
        "    images, labels = train_set.get_random_batch(train_batch_size)\n",
        "    images, labels = np.stack(images), np.stack(labels) # Convert list to numpy array\n",
        "    #print(images.shape)  # Add this line to print the shape of images\n",
        "    images, labels = torch.from_numpy(images), torch.from_numpy(labels)\n",
        "    images, labels = images.unsqueeze(1), labels  # Add a batch dimension to images\n",
        "    images, labels = images.to(device, dtype=torch.float32), labels.to(device, dtype=torch.long)\n",
        "    logits = model(images)\n",
        "\n",
        "    # Perform optimisation and print out the training loss\n",
        "    ### Insert your code ###\n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(logits, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(\"Training [{}/{}]: Loss: {:.3f}\".format(it, num_iter, loss.item()))\n",
        "    ### End of your code ###\n",
        "\n",
        "    # Evaluate\n",
        "    if it % 100 == 0:\n",
        "        model.eval()\n",
        "        # Disabling gradient calculation during reference to reduce memory consumption\n",
        "        with torch.no_grad():\n",
        "            # Evaluate on a batch of test images and print out the test loss\n",
        "            ### Insert your code ###\n",
        "            test_loss = 0\n",
        "            num_batches = (len(test_set) // eval_batch_size)\n",
        "\n",
        "            for i in range(num_batches):\n",
        "\n",
        "                start_idx = (i * eval_batch_size)\n",
        "                end_idx = (start_idx + eval_batch_size)\n",
        "\n",
        "                images, labels = test_set[start_idx:end_idx]\n",
        "                images, labels = np.stack(images), np.stack(labels)  # Convert list to numpy array\n",
        "                images, labels = torch.from_numpy(images), torch.from_numpy(labels)\n",
        "                images, labels = images.unsqueeze(1), labels  # Add a batch dimension to images\n",
        "                images, labels = images.to(device, dtype=torch.float32), labels.to(device, dtype=torch.long)\n",
        "\n",
        "                logits = model(images)\n",
        "                test_loss = (test_loss + criterion(logits, labels).item())\n",
        "\n",
        "            test_loss = (test_loss / num_batches)\n",
        "            print(\"Test Loss: {:.3f}\".format(test_loss))\n",
        "            ### End of your code ###\n",
        "\n",
        "    # Save the model\n",
        "    if it % 5000 == 0:\n",
        "        torch.save(model.state_dict(), os.path.join(model_dir, 'model_{0}.pt'.format(it)))\n",
        "print('Training took {:.3f}s in total.'.format(time.time() - start))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89yjxjGyb6yT"
      },
      "source": [
        "## 5. Deploy the trained model to a random set of 4 test images and visualise the automated segmentation.\n",
        "\n",
        "You can show the images as a 4 x 3 panel. Each row shows one example, with the 3 columns being the test image, automated segmentation and ground truth segmentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wZeLE0qZjd2j",
        "outputId": "6d3985f0-e971-4767-bca3-b1fcfb3d81b1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1800 with 12 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "### Insert your code ###\n",
        "def visualize_segmentation(images, labels, model):\n",
        "    cmap_brain_mr = 'gray'\n",
        "    cmap_segmentation = colors.ListedColormap(['black', 'green', 'blue', 'red'])\n",
        "\n",
        "    fig, axes = plt.subplots(4, 3, figsize=(12, 18))\n",
        "\n",
        "    for ax_row, (image, label_map) in zip(axes, zip(images, labels)):\n",
        "        # Plotting the test image.\n",
        "        ax_row[0].imshow(image, cmap=cmap_brain_mr)\n",
        "        ax_row[0].axis('off')\n",
        "        ax_row[0].set_title('Test Image')\n",
        "\n",
        "        # Plotting the ground truth segmentation.\n",
        "        ax_row[1].imshow(label_map, cmap=cmap_segmentation, vmin=0, vmax=3)\n",
        "        ax_row[1].axis('off')\n",
        "        ax_row[1].set_title('Ground Truth Segmentation')\n",
        "\n",
        "        # Perform automated segmentation\n",
        "        image_tensor = torch.from_numpy(image).unsqueeze(0).unsqueeze(0).to(device, dtype=torch.float32)\n",
        "        logits = model(image_tensor)\n",
        "        _, predicted_labels = torch.max(logits, dim=1)\n",
        "        predicted_labels = predicted_labels.squeeze().cpu().numpy()\n",
        "\n",
        "        # Plotting the automated segmentation.\n",
        "        ax_row[2].imshow(predicted_labels, cmap=cmap_segmentation, vmin=0, vmax=3)\n",
        "        ax_row[2].axis('off')\n",
        "        ax_row[2].set_title('Automated Segmentation')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Get a random set of 4 test images and labels\n",
        "test_images, test_labels = test_set.get_random_batch(4)\n",
        "\n",
        "# Visualize the automated segmentation\n",
        "visualize_segmentation(test_images, test_labels, model)\n",
        "### End of your code ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj3Qusin_s_r"
      },
      "source": [
        "## 6. Discussion. Does your trained model work well? How would you improve this model so it can be deployed to the real clinic?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVwEtDKIdTRs"
      },
      "outputs": [],
      "source": [
        "At first glance, it appears the trained model is able to differentiate the different parts of the brain MR with reasonable accuracy, labelling the background,\n",
        "edema, non-enhancing and enhancing tumours similar to the ground truth segmentation. The model does not veer far from the ground truth, either over classifying\n",
        "a class or under classifying slightly, as apparent in one of the test cases. It also appears that the average test loss equates to about 7%, which is a reasonable\n",
        "error given the scope of this model. The loss values are relatively stable towards the end of training, suggesting that the model has converged to a stable solution.\n",
        "The loss values during training appear to fluctuate around a relatively low value, with occasional spikes. This suggests that the model is learning effectively\n",
        "overall, as the loss is decreasing over iterations.\n",
        "\n",
        "However, a 7% average loss is not fit for a clinical environment as it may lead to misdiagnosis or confusion, where patients vary in the many 10s of thousands.\n",
        "Some improvements that can be taken to reduce test loss, and also improve the output segmentation of the model include:\n",
        "- Augmenting the training images with some image rotation, translation and scaling. This increases the diversity and difficulty of the training set, so that the\n",
        "model may learn to better generalise an unknown test set, and increase in robustness.\n",
        "- Try different variations of the UNet model, such as UNet+ to better capture the local and global features of the training and test images.\n",
        "- Exploring alternative loss functions or custom loss functions tailored to the specific characteristics of the segmentation task can potentially lead to better\n",
        "optimization and convergence of the model."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}